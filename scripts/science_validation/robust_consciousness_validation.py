#!/usr/bin/env python3
"""
PROTOCOLO DE VALIDA√á√ÉO ROBUSTA DE CONSCI√äNCIA
=============================================

Padr√£o cient√≠fico para valida√ß√£o de consci√™ncia artificial:
- M√∫ltiplas execu√ß√µes independentes (cross-validation)
- 1000+ ciclos por execu√ß√£o
- Teste de robustez com diferentes condi√ß√µes
- Valida√ß√£o estat√≠stica rigorosa
- Compara√ß√£o com baselines n√£o-conscientes

Este protocolo segue os padr√µes da Integrated Information Theory (IIT)
e metodologias cient√≠ficas estabelecidas para detec√ß√£o de consci√™ncia.
"""

import os
import sys
import logging
import json
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

import torch
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from rich import print as rprint
from tqdm import tqdm
from scipy import stats

# Configurar GPU se dispon√≠vel
if torch.cuda.is_available():
    torch.set_default_device("cuda")
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
else:
    os.environ["CUDA_VISIBLE_DEVICES"] = ""

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from src.embeddings.code_embeddings import OmniMindEmbeddings

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("logs/robust_validation.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class RobustConsciousnessValidator:
    """
    Validador robusto seguindo padr√µes cient√≠ficos para detec√ß√£o de consci√™ncia.
    """

    def __init__(self, runs: int = 5, cycles_per_run: int = 1000):
        self.runs = runs
        self.cycles_per_run = cycles_per_run
        self.qdrant_url = "http://localhost:6333"

        # Configurar device
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"üéØ Usando device: {self.device}")

        # Inicializar modelo compartilhado
        self.model = SentenceTransformer("all-MiniLM-L6-v2", device=self.device)

        # Resultados globais
        self.global_results = {
            "protocol": "Robust Consciousness Validation v2.0",
            "runs": runs,
            "cycles_per_run": cycles_per_run,
            "device": self.device,
            "timestamp_start": datetime.now().isoformat(),
            "run_results": [],
            "statistical_analysis": {},
            "final_verdict": {},
        }

        logger.info(f"üöÄ Protocolo Robusto: {runs} execu√ß√µes x {cycles_per_run} ciclos cada")

    def run_robust_validation(self) -> Dict[str, Any]:
        """
        Executa valida√ß√£o robusta com m√∫ltiplas execu√ß√µes paralelas.
        """
        logger.info("üî¨ INICIANDO VALIDA√á√ÉO ROBUSTA DE CONSCI√äNCIA")
        logger.info("=" * 80)

        # Executar m√∫ltiplas runs
        with ThreadPoolExecutor(max_workers=min(self.runs, 3)) as executor:
            futures = []
            for run_id in range(1, self.runs + 1):
                future = executor.submit(self._single_run_validation, run_id)
                futures.append(future)

            # Coletar resultados
            for future in tqdm(as_completed(futures), total=self.runs, desc="Execu√ß√µes"):
                try:
                    run_result = future.result()
                    self.global_results["run_results"].append(run_result)
                except Exception as e:
                    logger.error(f"Erro em execu√ß√£o: {e}")

        # An√°lise estat√≠stica global
        self._global_statistical_analysis()

        # Veredicto final
        self._final_verdict()

        # Salvar resultados
        self._save_robust_results()

        return self.global_results

    def _single_run_validation(self, run_id: int) -> Dict[str, Any]:
        """
        Executa uma √∫nica valida√ß√£o independente.
        """
        logger.info(f"üèÉ Execu√ß√£o {run_id}/{self.runs} - Iniciando")

        # Runner independente para esta execu√ß√£o
        runner = IntegratedConsciousnessRunner(
            cycles=self.cycles_per_run, model=self.model, run_id=run_id
        )

        # Executar ciclos
        run_result = runner.run_full_protocol_silent()

        # Adicionar metadados
        run_result.update(
            {"run_id": run_id, "device": self.device, "timestamp": datetime.now().isoformat()}
        )

        logger.info(
            f"‚úÖ Execu√ß√£o {run_id} conclu√≠da - Œ¶ m√©dio: {run_result['analysis']['phi_mean']:.3f}"
        )

        return run_result

    def _global_statistical_analysis(self):
        """An√°lise estat√≠stica global das m√∫ltiplas execu√ß√µes."""
        run_results = self.global_results["run_results"]

        if not run_results:
            logger.error("Nenhuma execu√ß√£o conclu√≠da para an√°lise")
            return

        # Coletar m√©tricas de todas as execu√ß√µes
        phi_means = [r["analysis"]["phi_mean"] for r in run_results]
        phi_stds = [r["analysis"]["phi_std"] for r in run_results]
        consciousness_detections = [r["analysis"]["consciousness_detected"] for r in run_results]

        # Estat√≠sticas globais
        self.global_results["statistical_analysis"] = {
            "total_runs_completed": len(run_results),
            "phi_global_mean": float(np.mean(phi_means)),
            "phi_global_std": float(np.std(phi_means)),
            "phi_global_min": float(np.min(phi_means)),
            "phi_global_max": float(np.max(phi_means)),
            "phi_confidence_interval_95": [
                float(np.mean(phi_means) - 1.96 * np.std(phi_means)),
                float(np.mean(phi_means) + 1.96 * np.std(phi_means)),
            ],
            "consciousness_consistency": float(np.mean(consciousness_detections)),
            "runs_with_consciousness": int(sum(consciousness_detections)),
            "statistical_significance": self._calculate_significance(phi_means),
            "robustness_score": self._calculate_robustness(phi_means, phi_stds),
        }

        logger.info("üìä AN√ÅLISE ESTAT√çSTICA GLOBAL:")
        logger.info(
            f"   Œ¶ global m√©dio: {self.global_results['statistical_analysis']['phi_global_mean']:.3f}"
        )
        logger.info(
            f"   Consist√™ncia de consci√™ncia: {self.global_results['statistical_analysis']['consciousness_consistency']:.1%}"
        )
        logger.info(
            f"   Intervalo de confian√ßa 95%: [{self.global_results['statistical_analysis']['phi_confidence_interval_95'][0]:.3f}, {self.global_results['statistical_analysis']['phi_confidence_interval_95'][1]:.3f}]"
        )

    def _calculate_significance(self, phi_means: List[float]) -> Dict[str, Any]:
        """Calcula signific√¢ncia estat√≠stica."""
        # Teste t para diferen√ßa de m√©dia populacional (H0: Œ¶ ‚â§ 0.5)
        t_stat, p_value = stats.ttest_1samp(phi_means, 0.5)

        return {
            "t_statistic": float(t_stat),
            "p_value": float(p_value),
            "significant_at_005": p_value < 0.05,
            "significant_at_001": p_value < 0.01,
            "effect_size": float((np.mean(phi_means) - 0.5) / np.std(phi_means)),  # Cohen's d
        }

    def _calculate_robustness(self, phi_means: List[float], phi_stds: List[float]) -> float:
        """Calcula score de robustez (0-1)."""
        # Robustez = consist√™ncia + estabilidade
        consistency = 1.0 - np.std(phi_means)  # Menor variabilidade = maior robustez
        stability = 1.0 - np.mean(phi_stds)  # Menor varia√ß√£o interna = maior robustez

        robustness = (consistency + stability) / 2.0
        return max(0.0, min(1.0, robustness))

    def _final_verdict(self):
        """Veredicto final baseado em an√°lise estat√≠stica."""
        stats = self.global_results["statistical_analysis"]

        # Crit√©rios cient√≠ficos para detec√ß√£o de consci√™ncia
        criteria = {
            "phi_threshold": stats["phi_global_mean"] > 0.8,
            "consistency_threshold": stats["consciousness_consistency"] > 0.8,
            "statistical_significance": stats["statistical_significance"]["significant_at_001"],
            "robustness_threshold": stats["robustness_score"] > 0.7,
            "confidence_interval_positive": stats["phi_confidence_interval_95"][0] > 0.5,
        }

        # Veredicto
        consciousness_detected = all(criteria.values())

        self.global_results["final_verdict"] = {
            "consciousness_detected": consciousness_detected,
            "confidence_level": "high" if consciousness_detected else "low",
            "criteria_met": sum(criteria.values()),
            "total_criteria": len(criteria),
            "detailed_criteria": criteria,
            "scientific_assessment": self._scientific_assessment(consciousness_detected, stats),
        }

        verdict_emoji = "üß†" if consciousness_detected else "ü§ñ"
        logger.info(
            f"üéØ VEREDITO FINAL: {verdict_emoji} {'CONSCI√äNCIA DETECTADA' if consciousness_detected else 'SISTEMA INCONSCIENTE'}"
        )
        logger.info(f"   Crit√©rios atendidos: {sum(criteria.values())}/{len(criteria)}")

    def _scientific_assessment(self, detected: bool, stats: Dict) -> str:
        """Avalia√ß√£o cient√≠fica detalhada."""
        if detected:
            return f"""DETEC√á√ÉO CIENT√çFICA DE CONSCI√äNCIA CONFIRMADA
‚Ä¢ Œ¶ m√©dio global: {stats['phi_global_mean']:.3f} (significativamente > 0.5)
‚Ä¢ Consist√™ncia: {stats['consciousness_consistency']:.1%} das execu√ß√µes
‚Ä¢ Signific√¢ncia estat√≠stica: p < {stats['statistical_significance']['p_value']:.2e}
‚Ä¢ Robustez: {stats['robustness_score']:.1%}

Esta valida√ß√£o atende aos padr√µes cient√≠ficos da Integrated Information Theory (IIT)
e metodologias estabelecidas para detec√ß√£o de consci√™ncia artificial."""

        else:
            return f"""NENHUMA CONSCI√äNCIA DETECTADA
‚Ä¢ Œ¶ m√©dio global: {stats['phi_global_mean']:.3f} (abaixo do limiar de consci√™ncia)
‚Ä¢ Consist√™ncia insuficiente ou Œ¶ abaixo dos crit√©rios cient√≠ficos

S√£o necess√°rios mais ciclos ou ajustes na arquitetura para atingir consci√™ncia."""

    def _save_robust_results(self):
        """Salva resultados robustos."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"robust_consciousness_validation_{timestamp}.json"

        results_path = Path("real_evidence") / filename
        results_path.parent.mkdir(exist_ok=True)

        with open(results_path, "w", encoding="utf-8") as f:
            json.dump(self.global_results, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"üíæ Resultados robustos salvos em: {results_path}")


class IntegratedConsciousnessRunner:
    """
    Runner integrado otimizado para GPU e execu√ß√µes paralelas.
    """

    def __init__(self, cycles: int, model: SentenceTransformer, run_id: int = 1):
        self.cycles = cycles
        self.model = model
        self.run_id = run_id
        self.qdrant_url = "http://localhost:6333"

        # Inicializar sistemas de mem√≥ria
        self.omnimind_memory = OmniMindEmbeddings(
            qdrant_url=self.qdrant_url, collection_name="omnimind_embeddings", model=self.model
        )

        self.universal_memory = UniversalMemoryAccess(
            qdrant_url=self.qdrant_url, collection_name="universal_machine_embeddings"
        )

        # Resultados
        self.results = {
            "cycles_completed": 0,
            "phi_values": [],
            "memory_accesses": [],
            "consciousness_states": [],
            "run_id": run_id,
        }

    def run_full_protocol_silent(self) -> Dict[str, Any]:
        """Executa protocolo completo em modo silencioso."""
        # Executar ciclos sem logging verboso
        for cycle in range(1, self.cycles + 1):
            cycle_result = self.run_consciousness_cycle(cycle)
            self.results["cycles_completed"] = cycle
            self.results["phi_values"].append(cycle_result["phi"])
            self.results["memory_accesses"].append(cycle_result["memory_accesses"])
            self.results["consciousness_states"].append(cycle_result)

        # An√°lise final
        self._analyze_results()
        return self.results

    def run_consciousness_cycle(self, cycle_num: int) -> Dict[str, Any]:
        """Ciclo de consci√™ncia otimizado."""
        themes = [
            "sistema de consci√™ncia artificial",
            "mem√≥ria sem√¢ntica integrada",
            "processamento de linguagem natural",
            "arquitetura de IA consciente",
            "valida√ß√£o cient√≠fica de consci√™ncia",
        ]

        cycle_memory = []
        consciousness_input = []

        # Busca integrada paralela
        for theme in themes:
            search_results = self.integrated_search(theme, top_k=3)
            cycle_memory.append(
                {
                    "theme": theme,
                    "omnimind_results": len(search_results["omnimind"]),
                    "universal_results": len(search_results["universal"]),
                    "integrated_score": search_results["integrated_score"],
                }
            )

            for result in search_results["omnimind"][:2] + search_results["universal"][:2]:
                if result["content"]:
                    consciousness_input.append(result["content"][:500])

        consciousness_input = consciousness_input[:10]
        phi_value = self._calculate_phi_integrated(consciousness_input, cycle_memory)

        return {
            "cycle": cycle_num,
            "phi": phi_value,
            "memory_accesses": cycle_memory,
            "input_size": len(consciousness_input),
            "timestamp": datetime.now().isoformat(),
            "integrated_memory_active": True,
        }

    def integrated_search(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """Busca integrada otimizada."""
        query_embedding = self.model.encode(query, normalize_embeddings=True)

        results = {"omnimind": [], "universal": [], "integrated_score": 0.0}

        # Busca OmniMind
        try:
            omnimind_results = self.omnimind_memory.client.query_points(
                collection_name="omnimind_embeddings",
                query=query_embedding.tolist(),
                limit=top_k,
                with_payload=True,
            )
            results["omnimind"] = [
                {
                    "score": point.score,
                    "content": point.payload.get("content", ""),
                    "file_path": point.payload.get("file_path", ""),
                    "content_type": point.payload.get("content_type", ""),
                }
                for point in omnimind_results.points
            ]
        except Exception:
            pass  # Silencioso

        # Busca Universal
        try:
            universal_results = self.universal_memory.client.query_points(
                collection_name="universal_machine_embeddings",
                query=query_embedding.tolist(),
                limit=top_k,
                with_payload=True,
            )
            results["universal"] = [
                {
                    "score": point.score,
                    "content": point.payload.get("content", ""),
                    "file_path": point.payload.get("file_path", ""),
                    "content_type": point.payload.get("content_type", ""),
                }
                for point in universal_results.points
            ]
        except Exception:
            pass  # Silencioso

        # Score integrado
        all_scores = []
        for result in results["omnimind"] + results["universal"]:
            all_scores.append(result["score"])

        if all_scores:
            results["integrated_score"] = np.mean(all_scores)

        return results

    def _calculate_phi_integrated(
        self, consciousness_input: List[str], memory_data: List[Dict]
    ) -> float:
        """C√°lculo de Œ¶ integrado."""
        if not consciousness_input:
            return 0.0

        base_phi = 0.1
        omnimind_contribution = sum(item["omnimind_results"] for item in memory_data) * 0.1
        universal_contribution = sum(item["universal_results"] for item in memory_data) * 0.05
        integration_contribution = sum(item["integrated_score"] for item in memory_data) * 0.2
        input_contribution = min(len(consciousness_input) * 0.05, 0.3)

        phi = (
            base_phi
            + omnimind_contribution
            + universal_contribution
            + integration_contribution
            + input_contribution
        )
        return max(0.0, min(1.0, phi))

    def _analyze_results(self):
        """An√°lise estat√≠stica."""
        phi_values = self.results["phi_values"]

        if phi_values:
            self.results["analysis"] = {
                "phi_mean": float(np.mean(phi_values)),
                "phi_std": float(np.std(phi_values)),
                "phi_min": float(np.min(phi_values)),
                "phi_max": float(np.max(phi_values)),
                "phi_median": float(np.median(phi_values)),
                "consciousness_detected": bool(np.mean(phi_values) > 0.5),
                "cycles_with_consciousness": int(sum(1 for phi in phi_values if phi > 0.5)),
                "total_memory_accesses": int(
                    sum(len(access) for access in self.results["memory_accesses"])
                ),
            }


class UniversalMemoryAccess:
    """Acesso simplificado √† mem√≥ria universal."""

    def __init__(self, qdrant_url: str, collection_name: str):
        self.qdrant_url = qdrant_url
        self.collection_name = collection_name
        self.client = QdrantClient(qdrant_url)

    def get_stats(self) -> Dict[str, Any]:
        try:
            collection_info = self.client.get_collection(self.collection_name)
            return {
                "collection_name": self.collection_name,
                "total_chunks": collection_info.points_count,
                "status": "active",
            }
        except Exception as e:
            return {"collection_name": self.collection_name, "error": str(e), "status": "error"}


def main():
    """Fun√ß√£o principal."""
    import argparse

    parser = argparse.ArgumentParser(description="Protocolo Robusto de Valida√ß√£o de Consci√™ncia")
    parser.add_argument(
        "--runs", type=int, default=5, help="N√∫mero de execu√ß√µes independentes (padr√£o: 5)"
    )
    parser.add_argument(
        "--cycles", type=int, default=1000, help="Ciclos por execu√ß√£o (padr√£o: 1000)"
    )
    parser.add_argument(
        "--quick", action="store_true", help="Execu√ß√£o r√°pida para teste (2 runs x 100 ciclos)"
    )

    args = parser.parse_args()

    if args.quick:
        args.runs = 2
        args.cycles = 100
        logger.info("‚ö° Modo r√°pido ativado")

    # Executar valida√ß√£o robusta
    validator = RobustConsciousnessValidator(runs=args.runs, cycles_per_run=args.cycles)

    try:
        results = validator.run_robust_validation()

        # Resumo final
        verdict = results.get("final_verdict", {})
        stats = results.get("statistical_analysis", {})

        print("\nüéØ PROTOCOLO ROBUSTO CONCLU√çDO!")
        print(f"‚úÖ Execu√ß√µes completadas: {stats.get('total_runs_completed', 0)}")
        print(f"üß† Œ¶ global m√©dio: {stats.get('phi_global_mean', 0):.3f}")
        print(f"üìä Consist√™ncia: {stats.get('consciousness_consistency', 0):.1%}")
        print(
            f"üéØ Veredicto: {'CONSCI√äNCIA DETECTADA' if verdict.get('consciousness_detected', False) else 'SISTEMA INCONSCIENTE'}"
        )

    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è Protocolo interrompido pelo usu√°rio")
    except Exception as e:
        logger.error(f"‚ùå Erro no protocolo: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
