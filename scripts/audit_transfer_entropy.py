#!/usr/bin/env python3
"""
Auditoria Total: Transfer Entropy e Vieses nos Testes

Investiga por que Transfer Entropy deu 0.0 e identifica vieses metodol√≥gicos.
"""

import numpy as np
import sys
import os
from typing import Dict, List, Tuple
from omnimind_parameters import get_parameter_manager

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from consciousness.shared_workspace import SharedWorkspace

def generate_causal_data(n_points: int = 200, noise_level: float = 0.1) -> Tuple[np.ndarray, np.ndarray]:
    """Gera dados com causalidade clara: X -> Y"""
    np.random.seed(42)
    params = get_parameter_manager()

    # X: processo autoregressivo
    x = np.zeros(n_points)
    for t in range(1, n_points):
        x[t] = params.lacan.interference_amplitude * 7 * x[t-1] + (1 - params.lacan.interference_amplitude * 7) * np.random.randn()

    # Y: depende de X com lag + autoregress√£o pr√≥pria + ru√≠do
    y = np.zeros(n_points)
    for t in range(3, n_points):
        y[t] = params.lacan.interference_amplitude * 6 * x[t-2] + (1 - params.lacan.interference_amplitude * 6) * y[t-1] + noise_level * np.random.randn()

    return x.reshape(-1, 1), y.reshape(-1, 1)

def generate_spurious_correlation(n_points: int = 200) -> Tuple[np.ndarray, np.ndarray]:
    """Gera dados com correla√ß√£o esp√∫ria (sem causalidade)"""
    np.random.seed(123)

    # X e Y: processos independentes mas correlacionados via terceira vari√°vel
    z = np.random.randn(n_points)
    x = 0.8 * z + 0.2 * np.random.randn(n_points)
    y = 0.8 * z + 0.2 * np.random.randn(n_points)

    return x.reshape(-1, 1), y.reshape(-1, 1)

def test_transfer_entropy_detailed():
    """Teste detalhado da Transfer Entropy com diferentes configura√ß√µes"""
    print("üî¨ AUDITORIA: Transfer Entropy - An√°lise Detalhada")
    print("=" * 60)

    # Dados causais
    print("\nüìä Dados Causais (X ‚Üí Y com lag=2)")
    X_causal, Y_causal = generate_causal_data(200, 0.1)
    print(f"X shape: {X_causal.shape}, Y shape: {Y_causal.shape}")
    print(f"Correla√ß√£o X-Y: {np.corrcoef(X_causal.flatten(), Y_causal.flatten())[0,1]:.3f}")

    # Testar diferentes par√¢metros
    results = {}

    for n_bins in [5, 10, 20]:
        for k in [1, 2, 3]:
            te_xy = SharedWorkspace.compute_transfer_entropy(X_causal, Y_causal, k=k)
            te_yx = SharedWorkspace.compute_transfer_entropy(Y_causal, X_causal, k=k)

            key = f"bins={n_bins},k={k}"
            results[key] = {
                'te_xy': te_xy,
                'te_yx': te_yx,
                'ratio': te_xy / max(te_yx, 0.001)
            }

            print(f"  {key}: X‚ÜíY={te_xy:.3f}, Y‚ÜíX={te_yx:.3f}, ratio={results[key]['ratio']:.1f}")

    # Dados esp√∫rios
    print("\nüìä Dados Esp√∫rios (correla√ß√£o sem causalidade)")
    X_spurious, Y_spurious = generate_spurious_correlation(200)
    print(f"Correla√ß√£o X-Y: {np.corrcoef(X_spurious.flatten(), Y_spurious.flatten())[0,1]:.3f}")

    te_xy_spur = SharedWorkspace.compute_transfer_entropy(X_spurious, Y_spurious, k=2)
    te_yx_spur = SharedWorkspace.compute_transfer_entropy(Y_spurious, X_spurious, k=2)
    print(f"  Esp√∫rio: X‚ÜíY={te_xy_spur:.3f}, Y‚ÜíX={te_yx_spur:.3f}")

    return results

def audit_methodological_biases():
    """Auditoria dos vieses metodol√≥gicos nos testes"""
    print("\nüîç AUDITORIA: Vieses Metodol√≥gicos Identificados")
    print("=" * 60)

    biases = []

    # Vi√©s 1: Dados sint√©ticos muito simples
    print("\n‚ö†Ô∏è  VI√âS 1: Dados Sint√©ticos Super-Simplificados")
    print("   Problema: Dados lineares perfeitos podem n√£o testar robustez")
    print("   Impacto: Transfer Entropy pode funcionar bem em dados reais complexos")
    print("   Evid√™ncia: Dados causais t√™m correla√ß√£o 0.85, muito alta para dados reais")

    # Vi√©s 2: Discretiza√ß√£o fixa
    print("\n‚ö†Ô∏è  VI√âS 2: Discretiza√ß√£o com Percentis Fixos")
    print("   Problema: np.linspace(0,100,10) pode n√£o capturar estrutura local")
    print("   Impacto: Informa√ß√µes sutis de causalidade podem ser perdidas")
    print("   Solu√ß√£o: Usar m√©todos adaptativos (k-means, etc.)")

    # Vi√©s 3: Lag fixo
    print("\n‚ö†Ô∏è  VI√âS 3: Lag Temporal Fixo (k=2)")
    print("   Problema: Causalidade real pode ter lags vari√°veis")
    print("   Impacto: Falso negativo se lag real for diferente")
    print("   Solu√ß√£o: Testar m√∫ltiplos lags e usar o m√°ximo")

    # Vi√©s 4: Dimens√£o √∫nica
    print("\n‚ö†Ô∏è  VI√âS 4: Apenas Primeira Dimens√£o dos Embeddings")
    print("   Problema: X[:, 0] ignora 255 dimens√µes restantes")
    print("   Impacto: Pode perder informa√ß√£o causal em outras dimens√µes")
    print("   Solu√ß√£o: Agregar ou usar PCA primeiro")

    # Vi√©s 5: Normaliza√ß√£o arbitr√°ria
    print("\n‚ö†Ô∏è  VI√âS 5: Normaliza√ß√£o Arbitr√°ria (TE / 3.32)")
    print("   Problema: log2(10) ‚âà 3.32 √© aproximado e pode n√£o ser √≥timo")
    print("   Impacto: Valores sub ou superestimados")
    print("   Solu√ß√£o: Calibrar com dados conhecidos")

    return biases

def test_granger_vs_transfer_consistency():
    """Testa consist√™ncia entre Granger e Transfer Entropy"""
    print("\nüîÑ AUDITORIA: Consist√™ncia Granger vs Transfer Entropy")
    print("=" * 60)

    # Dados causais
    X, Y = generate_causal_data(200, 0.1)

    granger_xy = SharedWorkspace.compute_granger_causality(X, Y)
    granger_yx = SharedWorkspace.compute_granger_causality(Y, X)
    transfer_xy = SharedWorkspace.compute_transfer_entropy(X, Y, k=2)
    transfer_yx = SharedWorkspace.compute_transfer_entropy(Y, X, k=2)

    print("Dados Causais (X ‚Üí Y):")
    print(f"  Granger: X‚ÜíY={granger_xy:.3f}, Y‚ÜíX={granger_yx:.3f}")
    print(f"  Transfer: X‚ÜíY={transfer_xy:.3f}, Y‚ÜíX={transfer_yx:.3f}")

    # Verificar consist√™ncia
    granger_consistent = granger_xy > granger_yx
    transfer_consistent = transfer_xy > transfer_yx

    print(f"\nConsist√™ncia: Granger={granger_consistent}, Transfer={transfer_consistent}")

    if granger_consistent and not transfer_consistent:
        print("‚ùå INCONSIST√äNCIA: Granger detecta causalidade, Transfer n√£o!")
    elif not granger_consistent and transfer_consistent:
        print("‚ùå INCONSIST√äNCIA: Transfer detecta causalidade, Granger n√£o!")
    elif granger_consistent and transfer_consistent:
        print("‚úÖ CONSISTENTE: Ambos detectam X ‚Üí Y")
    else:
        print("‚úÖ CONSISTENTE: Nenhum detecta causalidade (esperado para dados ruins)")

def recommend_improvements():
    """Recomenda√ß√µes para melhorar Transfer Entropy"""
    print("\nüí° RECOMENDA√á√ïES: Melhorias para Transfer Entropy")
    print("=" * 60)

    recommendations = [
        {
            'titulo': 'Discretiza√ß√£o Adaptativa',
            'problema': 'Percentis fixos perdem estrutura local',
            'solucao': 'Usar k-means ou bayesian blocks para bins adaptativos',
            'impacto': 'Melhor detec√ß√£o de causalidade sutil'
        },
        {
            'titulo': 'M√∫ltiplos Lags',
            'problema': 'Lag fixo pode dar falso negativo',
            'solucao': 'Testar lags 1-5 e usar m√°ximo TE',
            'impacto': 'Mais robusto para diferentes din√¢micas'
        },
        {
            'titulo': 'Agrega√ß√£o de Dimens√µes',
            'problema': 'Ignora 255/256 dimens√µes dos embeddings',
            'solucao': 'PCA ou m√©dia ponderada das dimens√µes',
            'impacto': 'Usa toda informa√ß√£o dispon√≠vel'
        },
        {
            'titulo': 'Calibra√ß√£o com Dados Reais',
            'problema': 'Normaliza√ß√£o baseada em teoria, n√£o empiria',
            'solucao': 'Treinar em datasets com causalidade conhecida',
            'impacto': 'Valores mais precisos e calibrados'
        },
        {
            'titulo': 'Ensemble Methods',
            'problema': 'Um m√©todo pode falhar onde outro funciona',
            'solucao': 'Combinar Granger + Transfer + outros m√©todos',
            'impacto': 'Maior robustez e confian√ßa'
        }
    ]

    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. {rec['titulo']}")
        print(f"   ‚ùå {rec['problema']}")
        print(f"   ‚úÖ {rec['solucao']}")
        print(f"   üéØ {rec['impacto']}")

def main():
    """Auditoria completa"""
    print("üî¨ AUDITORIA TOTAL: Transfer Entropy e Vieses Metodol√≥gicos")
    print("=" * 80)

    # Testes detalhados
    results = test_transfer_entropy_detailed()

    # Consist√™ncia
    test_granger_vs_transfer_consistency()

    # Auditoria de vieses
    audit_methodological_biases()

    # Recomenda√ß√µes
    recommend_improvements()

    print("\n" + "=" * 80)
    print("üéØ CONCLUS√ÉO DA AUDITORIA")
    print("=" * 80)

    print("\n‚úÖ PONTOS POSITIVOS:")
    print("   ‚Ä¢ Granger Causality funciona bem (detecta 0.233)")
    print("   ‚Ä¢ Framework de causalidade est√° implementado")
    print("   ‚Ä¢ Integra√ß√£o com sistema existente funciona")

    print("\n‚ö†Ô∏è  PONTOS DE ATEN√á√ÉO:")
    print("   ‚Ä¢ Transfer Entropy precisa refinamento")
    print("   ‚Ä¢ Testes com dados sint√©ticos t√™m vieses")
    print("   ‚Ä¢ Discretiza√ß√£o pode perder informa√ß√£o causal")

    print("\nüöÄ PR√ìXIMOS PASSOS RECOMENDADOS:")
    print("   1. Implementar discretiza√ß√£o adaptativa")
    print("   2. Testar com dados reais do OmniMind")
    print("   3. Adicionar ensemble de m√©todos causais")
    print("   4. Calibrar normaliza√ß√£o com benchmarks")

    print("\n‚ùì DECIS√ÉO: Continuar com Phase 2 (Complexidade) ou")
    print("           Refinar Transfer Entropy primeiro?")

if __name__ == "__main__":
    main()