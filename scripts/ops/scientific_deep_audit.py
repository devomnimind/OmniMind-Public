#!/usr/bin/env python3
"""
AUDITORIA CIENT√çFICA PROFUNDA - OmniMind Codebase
An√°lise Est√°tica Recursiva de todos os m√≥dulos em src/

Qu√°drupla Te√≥rica:
1. MATEM√ÅTICA: Œ¶/IIT, MICS, œà normaliza√ß√µes
2. TOPOL√ìGICA: Simplicial complexes, manifolds, Borromean
3. ENTR√ìPICA: œÉ actions, entropy, quantum entropy
4. PSICANAL√çTICA: Freud/Deleuze/Lacan/Sinthome
"""
import ast
import re
from pathlib import Path
from collections import defaultdict
import json

PROJECT_ROOT = Path("/home/fahbrain/projects/omnimind")
SRC_DIR = PROJECT_ROOT / "src"

# Padr√µes de busca para cada dimens√£o
PATTERNS = {
    "MATEMATICA": [
        # IIT/Phi
        r"\bphi\b",
        r"\bPhi\b",
        r"Œ¶",
        r"IIT",
        r"integrated.information",
        r"MICS",
        r"mics",
        r"mutual.information",
        r"cause.effect",
        # Psi normalizations
        r"\bpsi\b",
        r"\bPsi\b",
        r"Œ®",
        r"normalization",
        r"normalize",
        # C√°lculos matem√°ticos
        r"np\.linalg",
        r"scipy\.",
        r"matrix",
        r"eigenval",
        r"svd",
    ],
    "TOPOLOGICA": [
        r"simplicial",
        r"complex",
        r"manifold",
        r"Borromean",
        r"knot",
        r"homology",
        r"cohomology",
        r"topology",
        r"topological",
        r"betti",
        r"persistent.homology",
        r"nerve",
    ],
    "ENTROPICA": [
        r"\bsigma\b",
        r"œÉ",
        r"entropy",
        r"entropy_of_actions",
        r"quantum.entropy",
        r"von.neumann",
        r"shannon",
        r"mutual_info",
        r"uncertainty",
        r"surprise",
    ],
    "PSICANALITICA": [
        r"freud",
        r"Freud",
        r"deleuze",
        r"Deleuze",
        r"lacan",
        r"Lacan",
        r"sinthome",
        r"Sinthome",
        r"unconscious",
        r"drive",
        r"desire",
        r"jouissance",
        r"objet.petit.a",
        r"Real.*Symbolic.*Imaginary",
        r"Oedip",
        r"repression",
        r"symptom",
    ],
    "QUANTICO": [
        r"cuQuantum",
        r"qiskit",
        r"quantum",
        r"qubit",
        r"VQC",
        r"QSVM",
        r"QuantumCircuit",
        r"EntanglementEntropy",
        r"QPU",
    ],
}


def extract_imports(file_path):
    """Extrai todos os imports de um arquivo."""
    try:
        with open(file_path) as f:
            tree = ast.parse(f.read(), filename=str(file_path))

        imports = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.add(alias.name.split(".")[0])
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.add(node.module.split(".")[0])

        return imports
    except:
        return set()


def extract_functions(file_path):
    """Extrai nomes de fun√ß√µes/classes."""
    try:
        with open(file_path) as f:
            tree = ast.parse(f.read(), filename=str(file_path))

        functions = []
        classes = []
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append(node.name)
            elif isinstance(node, ast.ClassDef):
                classes.append(node.name)

        return functions, classes
    except:
        return [], []


def scan_patterns(file_path, content=None):
    """Busca padr√µes da qu√°drupla te√≥rica."""
    if content is None:
        try:
            with open(file_path) as f:
                content = f.read()
        except:
            return {}

    results = {}
    for category, patterns in PATTERNS.items():
        matches = 0
        for pattern in patterns:
            matches += len(re.findall(pattern, content, re.IGNORECASE))
        results[category] = matches > 0

    return results


def analyze_module(py_file):
    """An√°lise completa de um m√≥dulo."""
    rel_path = py_file.relative_to(SRC_DIR)

    try:
        with open(py_file) as f:
            content = f.read()
    except:
        content = ""

    # Extrair informa√ß√µes
    imports = extract_imports(py_file)
    functions, classes = extract_functions(py_file)
    patterns = scan_patterns(py_file, content)

    # Contar linhas
    lines = len(content.splitlines())

    # Detectar f√≥rmulas matem√°ticas (coment√°rios com equa√ß√µes)
    formulas = re.findall(r"#.*?[=‚à´‚àë‚àèŒ¶œàœÉ]", content)

    return {
        "path": str(rel_path),
        "folder": str(rel_path.parent),
        "name": py_file.stem,
        "lines": lines,
        "imports": list(imports),
        "functions_count": len(functions),
        "classes_count": len(classes),
        "formulas_count": len(formulas),
        "patterns": patterns,
    }


def build_dependency_graph(modules_data):
    """Constr√≥i grafo de depend√™ncias."""
    graph = defaultdict(set)

    for module in modules_data:
        module_path = module["path"]
        module_folder = module["folder"]

        # Para cada import, verificar se aponta para src/
        for imp in module["imports"]:
            for other in modules_data:
                other_folder = other["folder"]
                if imp in other_folder or imp == other["name"]:
                    graph[module_path].add(other["path"])

    return graph


def find_orphans(modules_data, graph):
    """Encontra m√≥dulos √≥rf√£os (sem depend√™ncias bidirecionais)."""
    all_paths = {m["path"] for m in modules_data}
    orphans = []

    for module in modules_data:
        path = module["path"]
        outgoing = graph.get(path, set())

        # Verificar se algu√©m importa este m√≥dulo
        incoming = {k for k, v in graph.items() if path in v}

        if len(incoming) == 0 and len(outgoing) == 0:
            orphans.append({"path": path, "reason": "ISOLADO - Sem imports nem sendo importado"})
        elif len(incoming) == 0:
            orphans.append({"path": path, "reason": f"SEM INCOMING - {len(outgoing)} outgoing"})

    return orphans


def generate_quadruple_table(modules_data):
    """Gera tabela qu√°drupla."""
    rows = []

    for module in modules_data:
        pat = module["patterns"]
        rows.append(
            {
                "Pasta/Modulo": f"{module['folder']}/{module['name']}.py",
                "Œ¶/IIT": "‚úÖ" if pat.get("MATEMATICA") else "‚ùå",
                "Topo": "‚úÖ" if pat.get("TOPOLOGICA") else "‚ùå",
                "œÉ/Entropia": "‚úÖ" if pat.get("ENTROPICA") else "‚ùå",
                "Psican√°lise": "‚úÖ" if pat.get("PSICANALITICA") else "‚ùå",
                "Qu√¢ntico": "‚úÖ" if pat.get("QUANTICO") else "‚ùå",
                "Linhas": module["lines"],
                "Fun√ß√µes": module["functions_count"],
                "Classes": module["classes_count"],
            }
        )

    return rows


def main():
    print("üî¨ AUDITORIA CIENT√çFICA PROFUNDA - OMNIMIND")
    print("=" * 80)
    print(f"Raiz: {SRC_DIR}")
    print()

    # 1. Coletar todos os m√≥dulos Python
    py_files = list(SRC_DIR.rglob("*.py"))
    py_files = [f for f in py_files if "__pycache__" not in str(f)]

    print(f"üìÅ Total de m√≥dulos Python: {len(py_files)}")
    print()

    # 2. Analisar cada m√≥dulo
    print("üîç Analisando m√≥dulos...")
    modules_data = []
    for py_file in py_files:
        data = analyze_module(py_file)
        modules_data.append(data)

    print(f"‚úÖ {len(modules_data)} m√≥dulos analisados")
    print()

    # 3. Construir grafo de depend√™ncias
    print("üó∫Ô∏è  Construindo grafo de depend√™ncias...")
    graph = build_dependency_graph(modules_data)
    print(f"‚úÖ {len(graph)} m√≥dulos com depend√™ncias")
    print()

    # 4. Encontrar √≥rf√£os
    print("üö® Detectando m√≥dulos √≥rf√£os...")
    orphans = find_orphans(modules_data, graph)
    print(f"‚ö†Ô∏è  {len(orphans)} m√≥dulos desconectados")
    print()

    # 5. Gerar tabela qu√°drupla
    print("üìä Gerando tabela qu√°drupla...")
    table = generate_quadruple_table(modules_data)

    # 6. Estat√≠sticas
    stats = {
        "total_modules": len(modules_data),
        "total_lines": sum(m["lines"] for m in modules_data),
        "total_functions": sum(m["functions_count"] for m in modules_data),
        "total_classes": sum(m["classes_count"] for m in modules_data),
        "with_matematica": sum(1 for m in modules_data if m["patterns"].get("MATEMATICA")),
        "with_topologica": sum(1 for m in modules_data if m["patterns"].get("TOPOLOGICA")),
        "with_entropica": sum(1 for m in modules_data if m["patterns"].get("ENTROPICA")),
        "with_psicanalitica": sum(1 for m in modules_data if m["patterns"].get("PSICANALITICA")),
        "with_quantico": sum(1 for m in modules_data if m["patterns"].get("QUANTICO")),
        "orphans": len(orphans),
    }

    # 7. Salvar resultados
    output = {
        "timestamp": "2025-12-21T01:40:00-03:00",
        "stats": stats,
        "table": table,
        "orphans": orphans,
        "modules_detailed": modules_data,
    }

    output_path = PROJECT_ROOT / "data/audit/SCIENTIFIC_DEEP_AUDIT.json"
    with open(output_path, "w") as f:
        json.dump(output, f, indent=2)

    print(f"üíæ Relat√≥rio salvo: {output_path.relative_to(PROJECT_ROOT)}")

    # 8. Exibir resumo
    print("\n" + "=" * 80)
    print("üìä ESTAT√çSTICAS GLOBAIS")
    print("=" * 80)
    for key, value in stats.items():
        print(f"{key:.<40} {value}")

    print("\n" + "=" * 80)
    print("üö® TOP 10 M√ìDULOS √ìRF√ÉOS")
    print("=" * 80)
    for i, orphan in enumerate(orphans[:10], 1):
        print(f"{i}. {orphan['path']}")
        print(f"   Raz√£o: {orphan['reason']}")

    print("\n" + "=" * 80)
    print("üìã AMOSTRA TABELA QU√ÅDRUPLA (Primeiros 10)")
    print("=" * 80)
    for row in table[:10]:
        print(f"\n{row['Pasta/Modulo']}")
        print(
            f"  Œ¶/IIT: {row['Œ¶/IIT']} | Topo: {row['Topo']} | œÉ: {row['œÉ/Entropia']} | Psi: {row['Psican√°lise']} | Q: {row['Qu√¢ntico']}"
        )
        print(f"  {row['Linhas']} linhas, {row['Fun√ß√µes']} fun√ß√µes, {row['Classes']} classes")


if __name__ == "__main__":
    main()
