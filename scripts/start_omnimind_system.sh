#!/bin/bash

# Cores para output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}üöÄ Iniciando Sistema OmniMind Completo...${NC}"

# üîß CR√çTICO: Calcular PROJECT_ROOT de forma robusta
# O script pode ser chamado de v√°rios contextos:
# 1. Direto: ./scripts/canonical/system/start_omnimind_system.sh
# 2. Via wrapper: ./start_omnimind_system.sh (que chama canonical/system/)
# 3. Via chamada direta do diret√≥rio raiz

# Se OMNIMIND_PROJECT_ROOT est√° definido (wrapper), usar ele
if [ -n "${OMNIMIND_PROJECT_ROOT:-}" ]; then
    PROJECT_ROOT="$OMNIMIND_PROJECT_ROOT"
else
    # Calcular PROJECT_ROOT procurando pelo arquivo de identidade do projeto
    # Procurar por config/omnimind.yaml ou .env ou pyproject.toml (marcadores do projeto)
    SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"

    # Subir at√© encontrar a raiz do projeto
    while [ "$SCRIPT_DIR" != "/" ]; do
        if [ -f "$SCRIPT_DIR/.env" ] || [ -f "$SCRIPT_DIR/pyproject.toml" ] || [ -f "$SCRIPT_DIR/config/omnimind.yaml" ]; then
            PROJECT_ROOT="$SCRIPT_DIR"
            break
        fi
        SCRIPT_DIR="$(dirname "$SCRIPT_DIR")"
    done

    # Se n√£o encontrou, usar o padr√£o
    if [ -z "$PROJECT_ROOT" ]; then
        # Fallback: subir 3 n√≠veis de scripts/canonical/system/
        PROJECT_ROOT="$(cd "$(dirname "$0")/../../.." && pwd)"
    fi
fi

# Validar que encontrou a raiz do projeto
if [ ! -f "$PROJECT_ROOT/config/omnimind.yaml" ] && [ ! -f "$PROJECT_ROOT/.env" ]; then
    echo -e "${RED}‚ùå N√£o conseguiu encontrar raiz do projeto OmniMind${NC}"
    echo "   Procurou por: config/omnimind.yaml ou .env"
    echo "   PROJECT_ROOT calculado: $PROJECT_ROOT"
    exit 1
fi

echo "‚úÖ Raiz do projeto encontrada: $PROJECT_ROOT"

# üîß CR√çTICO: Ativar venv ANTES de qualquer import Python
if [ -f "$PROJECT_ROOT/.venv/bin/activate" ]; then
    source "$PROJECT_ROOT/.venv/bin/activate"
    echo "‚úÖ Venv ativado: $VIRTUAL_ENV"
else
    echo "‚ö†Ô∏è  Venv n√£o encontrado em $PROJECT_ROOT/.venv"
    echo "   Tentando usar Python do sistema..."
fi

# üîí SEGURAN√áA: Bloquear porta 4444 (comumente usada por malware)
# Documentado em: docs/SECURITY_PORT_4444_BLOCK.md
echo "üîí Aplicando bloqueio de seguran√ßa (porta 4444)..."
if command -v iptables &> /dev/null; then
    # Verificar se regras j√° existem
    if ! sudo iptables -C INPUT -p tcp --dport 4444 -j DROP 2>/dev/null; then
        sudo iptables -A INPUT -p tcp --dport 4444 -j DROP 2>/dev/null || true
        sudo iptables -A OUTPUT -p tcp --dport 4444 -j DROP 2>/dev/null || true
        sudo iptables -A INPUT -p udp --dport 4444 -j DROP 2>/dev/null || true
        sudo iptables -A OUTPUT -p udp --dport 4444 -j DROP 2>/dev/null || true
        echo "‚úÖ Porta 4444 bloqueada (seguran√ßa)"
    else
        echo "‚úÖ Porta 4444 j√° est√° bloqueada"
    fi
else
    echo "‚ö†Ô∏è  iptables n√£o dispon√≠vel - porta 4444 n√£o bloqueada"
fi

# üîß GPU Configuration - Kali Linux Native Paths
echo "üîß Configurando ambiente GPU (Kali Native)..."
# No Kali/Debian, CUDA √© integrado em /usr
export CUDA_HOME="/usr"
export CUDA_path="/usr"
# A libcuda.so.1 est√° em /usr/lib/x86_64-linux-gnu/
# Adicionar ao LD_LIBRARY_PATH explicitamente para garantir que PyTorch a encontre
export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}"
export CUDA_VISIBLE_DEVICES="0"
export PYTORCH_CUDA_ALLOC_CONF="backend:cudaMallocAsync"
# export CUDA_LAUNCH_BLOCKING="1" # Descomente se precisar debugar inicializa√ß√£o s√≠ncrona

# Garantir permiss√£o de execu√ß√£o no run_cluster
chmod +x "$PROJECT_ROOT/scripts/canonical/system/run_cluster.sh" 2>/dev/null || true

# L√≥gica de Autentica√ß√£o Din√¢mica (Soberania Local) - UNIFICADA PARA CLUSTER
# Gera credenciais UMA VEZ e exporta para todos os subprocessos
DASH_USER=""
DASH_PASS=""
AUTH_FILE="$PROJECT_ROOT/config/dashboard_auth.json"

# 1. Tentar ler do arquivo gerado anteriormente ou preservar sess√£o
if [ -f "$AUTH_FILE" ]; then
    # Extra√ß√£o segura
    DASH_USER=$(python3 -c "import json; print(json.load(open('$AUTH_FILE')).get('user', ''))" 2>/dev/null)
    DASH_PASS=$(python3 -c "import json; print(json.load(open('$AUTH_FILE')).get('pass', ''))" 2>/dev/null)
fi

# 2. Fallback para .env
if [ -z "$DASH_USER" ] && [ -f "$PROJECT_ROOT/.env" ]; then
    DASH_USER=$(grep "^OMNIMIND_DASHBOARD_USER=" "$PROJECT_ROOT/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
    DASH_PASS=$(grep "^OMNIMIND_DASHBOARD_PASS=" "$PROJECT_ROOT/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
fi

# 3. Gerar novas se n√£o existirem (e salvar no arquivo para o backend usar a mesma)
if [ -z "$DASH_USER" ]; then
    # SOBERANIA LOCAL REAL: Gerar credenciais aleat√≥rias fortes a cada sess√£o
    # Isso garante seguran√ßa e obriga o uso correto do fluxo de autentica√ß√£o
    DASH_USER="admin"
    DASH_PASS=$(openssl rand -base64 12)

    # Salvar no JSON para persist√™ncia e leitura pelo backend
    echo "{\"user\": \"$DASH_USER\", \"pass\": \"$DASH_PASS\"}" > "$AUTH_FILE"
    echo "üîë Novas credenciais SOBERANAS geradas em $AUTH_FILE"
fi

# EXPORTAR PARA O AMBIENTE - ISSO GARANTE QUE TODOS OS BACKENDS USEM A MESMA SENHA
export OMNIMIND_DASHBOARD_USER="$DASH_USER"
export OMNIMIND_DASHBOARD_PASS="$DASH_PASS"
export OMNIMIND_DASHBOARD_AUTH_FILE="$AUTH_FILE"

echo -e "${GREEN}üîê Credenciais Unificadas do Cluster:${NC}"
echo "   User: $DASH_USER"
echo "   Pass: $DASH_PASS"

# 1. Verifica√ß√£o Inteligente de Servi√ßos Existentes
echo "üîç Verificando servi√ßos existentes..."
# CORRE√á√ÉO (2025-12-10): Verificar se backends j√° est√£o saud√°veis antes de matar
# Se backends est√£o respondendo corretamente, n√£o reiniciar desnecessariamente
BACKEND_8000_HEALTHY=false
BACKEND_8080_HEALTHY=false
BACKEND_3001_HEALTHY=false

if curl -s --max-time 3 http://localhost:8000/health/ > /dev/null 2>&1; then
    # Verificar tempo de resposta para garantir que est√° realmente saud√°vel
    RESPONSE_TIME=$(curl -s -w "%{time_total}" -o /dev/null "http://localhost:8000/health/" 2>/dev/null || echo "10.0")
    if (( $(echo "$RESPONSE_TIME < 2.0" | bc -l 2>/dev/null || echo "1") )); then
        echo -e "${GREEN}‚úÖ Backend na porta 8000 j√° est√° saud√°vel (${RESPONSE_TIME}s)${NC}"
        BACKEND_8000_HEALTHY=true
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Backend na porta 8000 responde mas est√° lento (${RESPONSE_TIME}s)${NC}"
    fi
fi

if curl -s --max-time 3 http://localhost:8080/health/ > /dev/null 2>&1; then
    RESPONSE_TIME=$(curl -s -w "%{time_total}" -o /dev/null "http://localhost:8080/health/" 2>/dev/null || echo "10.0")
    if (( $(echo "$RESPONSE_TIME < 2.0" | bc -l 2>/dev/null || echo "1") )); then
        echo -e "${GREEN}‚úÖ Backend na porta 8080 j√° est√° saud√°vel (${RESPONSE_TIME}s)${NC}"
        BACKEND_8080_HEALTHY=true
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Backend na porta 8080 responde mas est√° lento (${RESPONSE_TIME}s)${NC}"
    fi
fi

if curl -s --max-time 3 http://localhost:3001/health/ > /dev/null 2>&1; then
    RESPONSE_TIME=$(curl -s -w "%{time_total}" -o /dev/null "http://localhost:3001/health/" 2>/dev/null || echo "10.0")
    if (( $(echo "$RESPONSE_TIME < 2.0" | bc -l 2>/dev/null || echo "1") )); then
        echo -e "${GREEN}‚úÖ Backend na porta 3001 j√° est√° saud√°vel (${RESPONSE_TIME}s)${NC}"
        BACKEND_3001_HEALTHY=true
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Backend na porta 3001 responde mas est√° lento (${RESPONSE_TIME}s)${NC}"
    fi
fi

# Se TODOS os backends est√£o saud√°veis, n√£o reiniciar
if [ "$BACKEND_8000_HEALTHY" = true ] && [ "$BACKEND_8080_HEALTHY" = true ] && [ "$BACKEND_3001_HEALTHY" = true ]; then
    echo -e "${GREEN}‚úÖ Todos os backends j√° est√£o saud√°veis - pulando reinicializa√ß√£o${NC}"
    echo "   (Para for√ßar reinicializa√ß√£o, pare os servi√ßos manualmente primeiro)"
    SKIP_BACKEND_RESTART=true
else
    echo "üõë Alguns backends n√£o est√£o saud√°veis ou n√£o est√£o rodando. Reiniciando..."
    SKIP_BACKEND_RESTART=false

    # Limpeza apenas se necess√°rio
    pkill -9 -f "python web/backend/main.py" 2>/dev/null || true
    pkill -9 -f "uvicorn web.backend.main:app" 2>/dev/null || true
    pkill -9 -f "python -m src.main" 2>/dev/null || true
    pkill -f "vite" 2>/dev/null || true
    pkill -f "bpftrace.*monitor_mcp_bpf" 2>/dev/null || true
    sleep 3
fi

# ============================================================================
# INICIALIZA√á√ÉO SEQUENCIAL ROBUSTA
# ============================================================================
# Usa script sequencial dedicado para garantir inicializa√ß√£o ordenada
# com verifica√ß√£o de sa√∫de de cada servi√ßo antes de prosseguir
# ============================================================================

echo -e "${GREEN}üîå Iniciando Backend Cluster (Fase 1: Essenciais)...${NC}"

# CORRE√á√ÉO (2025-12-10): N√£o reiniciar se backends j√° est√£o saud√°veis
if [ "${SKIP_BACKEND_RESTART:-false}" = true ]; then
    echo -e "${GREEN}‚úÖ Backends j√° est√£o rodando e saud√°veis - pulando inicializa√ß√£o${NC}"
    echo "   Usando backends existentes"
else
    # Iniciar Backend Cluster apenas se necess√°rio
    echo "üîÑ Iniciando Backend Cluster..."
    "$PROJECT_ROOT/scripts/canonical/system/run_cluster.sh"
fi

# Fun√ß√£o de health check com retry
check_backend_health() {
    local port=$1
    local max_retries=${2:-30}
    local retry_interval=${3:-3}
    local stable_checks=${4:-3}

    local stable_count=0

    for i in $(seq 1 $max_retries); do
        if curl -s --max-time 5 "http://localhost:${port}/health/" > /dev/null 2>&1; then
            # Verificar tempo de resposta (proxy para CPU)
            local response_time=$(curl -s -w "%{time_total}" -o /dev/null "http://localhost:${port}/health/" 2>/dev/null || echo "10.0")
            if (( $(echo "$response_time < 2.0" | bc -l 2>/dev/null || echo "1") )); then
                stable_count=$((stable_count + 1))
                if [ $stable_count -ge $stable_checks ]; then
                    echo "‚úÖ Backend ${port} est√°vel ap√≥s ${i} tentativas (~$((i*retry_interval))s)"
                    return 0
                fi
            else
                stable_count=0  # Reset se resposta lenta
            fi
        else
            stable_count=0  # Reset se n√£o responde
        fi

        [ $i -lt $max_retries ] && sleep $retry_interval
    done

    return 1
}

# Aguardar Backend Primary (CR√çTICO - deve estar saud√°vel)
# CORRE√á√ÉO (2025-12-10): Aumentar tempo de espera para carregamento de modelos/transformers
# max_retries=100, retry_interval=3 ‚Üí 100*3=300s (5 minutos)
# CORRE√á√ÉO (2025-12-10): N√£o falhar imediatamente - backend pode demorar mais em sistemas lentos
echo "‚è≥ Aguardando Backend Primary (8000) inicializar..."
echo "   (Carregamento de modelos pode levar at√© 5 minutos...)"
echo "   (Aguardando at√© 300s antes de considerar falha...)"

BACKEND_READY=false
if check_backend_health 8000 100 3 3; then
    echo -e "${GREEN}‚úÖ Backend Primary est√°vel e pronto${NC}"
    BACKEND_READY=true
else
    echo -e "${YELLOW}‚ö†Ô∏è  Backend Primary n√£o respondeu ap√≥s 300s${NC}"
    echo "üìä Diagn√≥stico:"
    ps aux | grep -E "(uvicorn|python.*main)" | grep -v grep || echo "   Nenhum processo backend encontrado"
    tail -n 20 logs/backend_8000.log 2>/dev/null || echo "   Log 8000 n√£o encontrado"

    # Verificar se processo est√° rodando mesmo sem responder
    if pgrep -f "uvicorn.*main:app.*8000" > /dev/null 2>&1; then
        echo -e "${YELLOW}‚ö†Ô∏è  Backend est√° rodando mas n√£o respondeu a tempo${NC}"
        echo "   Processo encontrado - pode estar ainda inicializando modelos"
        echo "   Continuando... (backend pode ficar pronto em breve)"
        BACKEND_READY=true  # Assumir que est√° OK se processo existe
    else
        echo -e "${RED}‚ùå Backend n√£o est√° rodando - falha cr√≠tica${NC}"
        echo "   Tentando reiniciar backend..."
        "$PROJECT_ROOT/scripts/canonical/system/run_cluster.sh"
        sleep 10

        # Tentar mais uma vez
        if check_backend_health 8000 30 3 2; then
            echo -e "${GREEN}‚úÖ Backend Primary reiniciado e pronto${NC}"
            BACKEND_READY=true
        else
            echo -e "${RED}‚ùå Falha cr√≠tica: Backend n√£o inicializou ap√≥s rein√≠cio${NC}"
            echo "   Verifique logs/backend_8000.log para detalhes"
            # N√ÉO SAIR COM ERRO - deixar systemd decidir se deve reiniciar
            # exit 1
        fi
    fi
fi

# Verificar Backends secund√°rios (n√£o cr√≠ticos, mas desej√°veis)
# CORRE√á√ÉO (2025-12-10): Aumentar tempo de espera tamb√©m para secund√°rios
echo "‚è≥ Verificando Backends secund√°rios..."
check_backend_health 8080 30 3 2 && echo "‚úÖ Backend Secondary (8080) est√°vel" || echo -e "${YELLOW}‚ö†Ô∏è  Backend Secondary (8080) n√£o est√°vel (continuando...)${NC}"
check_backend_health 3001 30 3 2 && echo "‚úÖ Backend Fallback (3001) est√°vel" || echo -e "${YELLOW}‚ö†Ô∏è  Backend Fallback (3001) n√£o est√°vel (continuando...)${NC}"

# FASE 2: SECUND√ÅRIOS (ap√≥s 60s dos essenciais)
# CORRE√á√ÉO (2025-12-10): Aumentar tempo de espera para garantir inicializa√ß√£o completa
echo -e "${GREEN}‚è∞ Aguardando 60s antes de iniciar servi√ßos secund√°rios...${NC}"
echo "   (Garantindo que servi√ßos essenciais estejam totalmente inicializados)"
echo "   (Carregamento de modelos pode levar tempo adicional...)"
sleep 60

# Verifica√ß√£o de CPU antes de prosseguir (evita bloqueio)
echo "üîç Verificando estabilidade de CPU antes de servi√ßos secund√°rios..."
check_cpu_stable() {
    local max_cpu=${1:-30}
    local max_wait=${2:-30}
    local wait_interval=${3:-3}

    # CORRE√á√ÉO (2025-12-10): Usar top com delay para medi√ß√£o precisa de CPU
    # ps aux mostra CPU acumulada desde in√≠cio do processo, n√£o uso atual
    get_cpu_usage() {
        # Usar top com delay de 1s para obter uso atual de CPU
        top -bn1 -d 1 | grep -E "^\s*[0-9]+.*python" | awk '{sum+=$9} END {print sum+0}' 2>/dev/null || \
        # Fallback: usar ps com c√°lculo mais preciso
        ps aux --no-headers | grep -E "[p]ython.*uvicorn\|[p]ython.*main" | awk '{sum+=$3} END {print sum+0}' 2>/dev/null || \
        echo "0"
    }

    for i in $(seq 1 $((max_wait / wait_interval))); do
        # Aguardar um pouco antes da primeira medi√ß√£o para estabilizar
        [ $i -eq 1 ] && sleep 2

        local cpu=$(get_cpu_usage)

        if (( $(echo "$cpu < $max_cpu" | bc -l 2>/dev/null || echo "0") )); then
            echo "‚úÖ CPU est√°vel ($cpu% < ${max_cpu}%)"
            return 0
        fi

        echo "   CPU: ${cpu}% (aguardando estabiliza√ß√£o... $i/$((max_wait / wait_interval)))"
        sleep $wait_interval
    done

    # Se ainda alta ap√≥s espera, verificar se √© cr√≠tica
    local cpu=$(get_cpu_usage)
    if (( $(echo "$cpu > 80.0" | bc -l 2>/dev/null || echo "0") )); then
        echo -e "${YELLOW}‚ö†Ô∏è  CPU alta ($cpu%) - pode ser normal durante inicializa√ß√£o${NC}"
        echo "   Backend pode estar carregando modelos. Continuando com cuidado..."
        echo "   Se persistir, verifique logs/backend_*.log"
        # CORRE√á√ÉO (2025-12-10): N√£o abortar - apenas avisar
        # exit 1
    fi

    echo -e "${YELLOW}‚ö†Ô∏è  CPU ainda alta ($cpu%), mas n√£o cr√≠tica. Prosseguindo com cuidado...${NC}"
    return 0
}

check_cpu_stable 30 30 3
echo "‚úÖ Sistema est√°vel. Prosseguindo com servi√ßos secund√°rios..."

# ============================================================================
# FASE 2: SERVI√áOS SECUND√ÅRIOS (Sequencial com Health Checks)
# ============================================================================

# 2.1. Iniciar MCP Orchestrator (depende de Backend Primary)
echo -e "${GREEN}üåê Iniciando MCP Orchestrator...${NC}"
cd "$PROJECT_ROOT"

if pgrep -f "run_mcp_orchestrator.py" > /dev/null; then
    MCP_ORCHESTRATOR_PID=$(pgrep -f "run_mcp_orchestrator.py" | head -1)
    echo -e "${YELLOW}‚ö†Ô∏è  MCP Orchestrator j√° est√° rodando (PID $MCP_ORCHESTRATOR_PID)${NC}"
else
    # Verificar que Backend est√° saud√°vel antes de iniciar
    if ! curl -s --max-time 3 http://localhost:8000/health/ > /dev/null 2>&1; then
        echo -e "${RED}‚ùå Backend n√£o est√° saud√°vel. Aguardando...${NC}"
        sleep 5
    fi

    chmod +x "$PROJECT_ROOT/scripts/canonical/system/run_mcp_orchestrator.py" 2>/dev/null || true
    nohup python "$PROJECT_ROOT/scripts/canonical/system/run_mcp_orchestrator.py" > "$PROJECT_ROOT/logs/mcp_orchestrator.log" 2>&1 &
    MCP_ORCHESTRATOR_PID=$!
    echo $MCP_ORCHESTRATOR_PID > "$PROJECT_ROOT/logs/mcp_orchestrator.pid"
    echo "‚úì MCP Orchestrator iniciado (PID $MCP_ORCHESTRATOR_PID)"

    # Verificar se iniciou corretamente
    sleep 3
    if ps -p $MCP_ORCHESTRATOR_PID > /dev/null 2>&1; then
        echo -e "${GREEN}‚úÖ MCP Orchestrator rodando${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  MCP Orchestrator pode ter falhado (verifique logs)${NC}"
    fi
fi

# 2.2. Iniciar Ciclo Principal (depende de Backend Primary)
echo -e "${GREEN}üîÑ Iniciando Ciclo Principal OmniMind (Fase 23: Autopoiese + Integra√ß√£o Real-time)...${NC}"
cd "$PROJECT_ROOT"
mkdir -p "$PROJECT_ROOT/logs" "$PROJECT_ROOT/data/autopoietic/synthesized_code" "$PROJECT_ROOT/data/monitor"

if [ -f "$PROJECT_ROOT/logs/main_cycle.pid" ]; then
    OLD_PID=$(cat "$PROJECT_ROOT/logs/main_cycle.pid" 2>/dev/null || echo "")
    if [ -n "$OLD_PID" ] && ps -p "$OLD_PID" > /dev/null 2>&1; then
        echo -e "${YELLOW}‚ö†Ô∏è  Ciclo Principal j√° est√° rodando (PID $OLD_PID)${NC}"
        MAIN_CYCLE_PID=$OLD_PID
    else
        # Verificar Backend antes de iniciar
        if curl -s --max-time 3 http://localhost:8000/health/ > /dev/null 2>&1; then
            nohup python -m src.main > "$PROJECT_ROOT/logs/main_cycle.log" 2>&1 &
            MAIN_CYCLE_PID=$!
            echo $MAIN_CYCLE_PID > "$PROJECT_ROOT/logs/main_cycle.pid"
            echo "‚úì Ciclo Principal iniciado (PID $MAIN_CYCLE_PID)"
            sleep 3
            if ps -p $MAIN_CYCLE_PID > /dev/null 2>&1; then
                echo -e "${GREEN}‚úÖ Ciclo Principal rodando${NC}"
            else
                echo -e "${YELLOW}‚ö†Ô∏è  Ciclo Principal pode ter falhado (verifique logs)${NC}"
            fi
        else
            echo -e "${RED}‚ùå Backend n√£o est√° saud√°vel. Pulando Ciclo Principal.${NC}"
        fi
    fi
else
    if curl -s --max-time 3 http://localhost:8000/health/ > /dev/null 2>&1; then
        nohup python -m src.main > "$PROJECT_ROOT/logs/main_cycle.log" 2>&1 &
        MAIN_CYCLE_PID=$!
        echo $MAIN_CYCLE_PID > "$PROJECT_ROOT/logs/main_cycle.pid"
        echo "‚úì Ciclo Principal iniciado (PID $MAIN_CYCLE_PID)"
        sleep 3
        if ps -p $MAIN_CYCLE_PID > /dev/null 2>&1; then
            echo -e "${GREEN}‚úÖ Ciclo Principal rodando${NC}"
        fi
    else
        echo -e "${RED}‚ùå Backend n√£o est√° saud√°vel. Pulando Ciclo Principal.${NC}"
    fi
fi
echo "   Log: tail -f logs/main_cycle.log"

# 2.3. Iniciar Daemon (depende de Backend Primary)
echo -e "${GREEN}ü§ñ Inicializando OmniMind Daemon...${NC}"
cd "$PROJECT_ROOT"

# Verificar Backend antes de iniciar Daemon
if curl -s --max-time 3 http://localhost:8000/health/ > /dev/null 2>&1; then
    if [ -n "$OMNIMIND_DASHBOARD_PASS" ]; then
        curl -X POST http://localhost:8000/daemon/start \
          -u "${OMNIMIND_DASHBOARD_USER}:${OMNIMIND_DASHBOARD_PASS}" \
          > "$PROJECT_ROOT/logs/daemon_start.log" 2>&1 &
        DAEMON_START_PID=$!
        echo "‚úì Daemon start request enviado (PID $DAEMON_START_PID)"
        sleep 2

        # Verificar se daemon iniciou
        if curl -s --max-time 3 -u "${OMNIMIND_DASHBOARD_USER}:${OMNIMIND_DASHBOARD_PASS}" http://localhost:8000/daemon/status > /dev/null 2>&1; then
            echo -e "${GREEN}‚úÖ Daemon iniciado${NC}"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  Daemon pode estar iniciando (verifique logs)${NC}"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Senha n√£o encontrada, pulando inicializa√ß√£o do daemon via API${NC}"
    fi
else
    echo -e "${RED}‚ùå Backend n√£o est√° saud√°vel. Pulando Daemon.${NC}"
fi

# 5. Iniciar Frontend
echo -e "${GREEN}üé® Iniciando Frontend...${NC}"
echo "   (Aguardando backend estar pronto na porta 8000...)"

MAX_ATTEMPTS=30
ATTEMPT=1
while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
    if curl -s --max-time 2 http://localhost:8000/health/ > /dev/null 2>&1; then
        echo -e "${GREEN}‚úÖ Backend pronto!${NC}"
        break
    fi
    echo -n "."
    sleep 2
    ATTEMPT=$((ATTEMPT+1))
done

if [ $ATTEMPT -gt $MAX_ATTEMPTS ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  Backend demorando para responder, iniciando Frontend mesmo assim...${NC}"
fi

cd "$PROJECT_ROOT"

# Verificar se diret√≥rio frontend existe
if [ ! -d "web/frontend" ]; then
    echo -e "${RED}‚ùå Diret√≥rio web/frontend n√£o encontrado!${NC}"
    echo "   Verificando estrutura do projeto..."
    ls -la web/ 2>&1 | head -10
    FRONTEND_PID=""
else
    cd web/frontend

    # Verificar se node_modules existe, se n√£o, instalar
    if [ ! -d "node_modules" ]; then
        echo "üì¶ Instalando depend√™ncias do Frontend..."
        npm install
    fi

    # Verificar se j√° est√° rodando
    if [ -f "$PROJECT_ROOT/logs/frontend.pid" ]; then
        OLD_PID=$(cat "$PROJECT_ROOT/logs/frontend.pid" 2>/dev/null || echo "")
        if [ -n "$OLD_PID" ] && ps -p "$OLD_PID" > /dev/null 2>&1; then
            echo -e "${YELLOW}‚ö†Ô∏è  Frontend j√° est√° rodando (PID $OLD_PID)${NC}"
            FRONTEND_PID=$OLD_PID
        else
            nohup npm run dev > "$PROJECT_ROOT/logs/frontend.log" 2>&1 &
            FRONTEND_PID=$!
            echo $FRONTEND_PID > "$PROJECT_ROOT/logs/frontend.pid"
            echo "‚úì Frontend iniciado (PID $FRONTEND_PID)"
        fi
    else
        nohup npm run dev > "$PROJECT_ROOT/logs/frontend.log" 2>&1 &
        FRONTEND_PID=$!
        echo $FRONTEND_PID > "$PROJECT_ROOT/logs/frontend.pid"
        echo "‚úì Frontend iniciado (PID $FRONTEND_PID)"
    fi
fi

# Voltar para raiz do projeto
cd "$PROJECT_ROOT"

# 6. Verifica√ß√£o Final
echo -e "${GREEN}üîç Verificando status do sistema...${NC}"
sleep 5

if [ -n "$FRONTEND_PID" ] && ps -p $FRONTEND_PID > /dev/null 2>&1; then
    echo -e "${GREEN}‚úÖ Frontend rodando (PID $FRONTEND_PID)${NC}"
    echo "   Acesse: http://localhost:3000"
else
    echo -e "${RED}‚ùå Frontend falhou ao iniciar. Verifique logs/frontend.log${NC}"
    if [ -f "$PROJECT_ROOT/logs/frontend.log" ]; then
        tail -n 20 "$PROJECT_ROOT/logs/frontend.log"
    else
        echo "   Arquivo de log n√£o encontrado"
    fi
fi

# FASE 3: MONITORAMENTO (ap√≥s 15s dos servi√ßos principais)
# Aguardar estabiliza√ß√£o completa antes de iniciar servi√ßos de monitoramento
echo -e "${GREEN}‚è∞ Aguardando 15s antes de iniciar servi√ßos de monitoramento...${NC}"
echo "   (Garantindo que todos os servi√ßos principais estejam totalmente est√°veis)"
sleep 15

# 7. Iniciar Observer Service (FASE 3: MONITORAMENTO - ap√≥s servi√ßos principais)
echo -e "${GREEN}üìä Iniciando Observer Service (M√©tricas de Longo Prazo)...${NC}"
cd "$PROJECT_ROOT"

# Verificar se j√° est√° rodando
if [ -f "$PROJECT_ROOT/logs/observer_service.pid" ]; then
    OLD_PID=$(cat "$PROJECT_ROOT/logs/observer_service.pid" 2>/dev/null || echo "")
    if [ -n "$OLD_PID" ] && ps -p "$OLD_PID" > /dev/null 2>&1; then
        echo -e "${YELLOW}‚ö†Ô∏è  Observer Service j√° est√° rodando (PID $OLD_PID)${NC}"
        OBSERVER_PID=$OLD_PID
    else
        # Criar diret√≥rio de logs se n√£o existir
        mkdir -p "$PROJECT_ROOT/data/long_term_logs" "$PROJECT_ROOT/logs"

        # Garantir permiss√£o de execu√ß√£o no script
        chmod +x "$PROJECT_ROOT/scripts/canonical/system/run_observer_service.py" 2>/dev/null || true

        # Iniciar Observer Service em background usando script wrapper
        nohup python "$PROJECT_ROOT/scripts/canonical/system/run_observer_service.py" > "$PROJECT_ROOT/logs/observer_service.log" 2>&1 &
        OBSERVER_PID=$!
        echo $OBSERVER_PID > "$PROJECT_ROOT/logs/observer_service.pid"
        echo "‚úì Observer Service iniciado (PID $OBSERVER_PID)"
        echo "   Log: tail -f logs/observer_service.log"
        echo "   M√©tricas: data/long_term_logs/omnimind_metrics.jsonl"
        sleep 3  # Aguardar inicializa√ß√£o
    fi
else
    # Criar diret√≥rio de logs se n√£o existir
    mkdir -p "$PROJECT_ROOT/data/long_term_logs" "$PROJECT_ROOT/logs"

    # Garantir permiss√£o de execu√ß√£o no script
    chmod +x "$PROJECT_ROOT/scripts/canonical/system/run_observer_service.py" 2>/dev/null || true

    # Iniciar Observer Service em background usando script wrapper
    nohup python "$PROJECT_ROOT/scripts/canonical/system/run_observer_service.py" > "$PROJECT_ROOT/logs/observer_service.log" 2>&1 &
    OBSERVER_PID=$!
    echo $OBSERVER_PID > "$PROJECT_ROOT/logs/observer_service.pid"
    echo "‚úì Observer Service iniciado (PID $OBSERVER_PID)"
    echo "   Log: tail -f logs/observer_service.log"
    echo "   M√©tricas: data/long_term_logs/omnimind_metrics.jsonl"
    sleep 3  # Aguardar inicializa√ß√£o
fi

# 8. Iniciar eBPF Monitor Cont√≠nuo (FASE 3: MONITORAMENTO AVAN√áADO)
echo -e "${GREEN}üìä Iniciando eBPF Monitor Cont√≠nuo...${NC}"

# Voltar para a raiz do projeto para encontrar scripts/canonical/system/secure_run.py
cd "$PROJECT_ROOT"

if command -v bpftrace &> /dev/null; then
    EBPF_LOG="$PROJECT_ROOT/logs/ebpf_monitor.log"
    mkdir -p "$PROJECT_ROOT/logs"

    # Garantir permiss√µes no arquivo de log se ele existir
    if [ -f "$EBPF_LOG" ]; then
        # Tentar mudar dono para usu√°rio atual se poss√≠vel, ou remover se falhar
        if ! touch "$EBPF_LOG" 2>/dev/null; then
            echo "‚ö†Ô∏è  Sem permiss√£o de escrita em $EBPF_LOG. Tentando remover com sudo..."
            sudo rm -f "$EBPF_LOG"
        fi
    fi

    # Parar eBPF anterior
    python3 "$PROJECT_ROOT/scripts/canonical/system/secure_run.py" pkill -f "bpftrace.*monitor_mcp_bpf" || true
    sleep 1
    # Iniciar em background
    # Nota: secure_run.py j√° lida com sudo -n
    python3 "$PROJECT_ROOT/scripts/canonical/system/secure_run.py" bpftrace "$PROJECT_ROOT/scripts/canonical/system/monitor_mcp_bpf.bt" > "${EBPF_LOG}" 2>&1 &
    sleep 2
    echo -e "${GREEN}‚úÖ eBPF Monitor ativo${NC}"
    echo "   Log: tail -f ${EBPF_LOG}"
else
    echo -e "${RED}‚ö†Ô∏è  bpftrace n√£o encontrado. Instale com: sudo apt install bpftrace${NC}"
fi

echo -e "${GREEN}‚ú® Sistema OmniMind Reiniciado!${NC}"
echo ""
echo -e "${GREEN}üìã SERVI√áOS ATIVOS:${NC}"
echo "   Backend Cluster: Ports 8000, 8080, 3001"
if [ -n "${MCP_ORCHESTRATOR_PID:-}" ]; then
    echo "   MCP Orchestrator: PID ${MCP_ORCHESTRATOR_PID}"
fi
echo "   Ciclo Principal (Autopoiese Phase 23): PID $MAIN_CYCLE_PID"
if [ -n "${OBSERVER_PID:-}" ]; then
    echo "   Observer Service: PID ${OBSERVER_PID}"
fi
echo "   Frontend: http://localhost:3000"
echo ""
echo -e "${GREEN}üîê CREDENCIAIS DA SESS√ÉO ATUAL (CLUSTER UNIFICADO):${NC}"
echo -e "   User: ${GREEN}${OMNIMIND_DASHBOARD_USER}${NC}"
echo -e "   Pass: ${GREEN}${OMNIMIND_DASHBOARD_PASS}${NC}"
echo "   (Use estas credenciais para logar no Dashboard)"
echo ""
echo -e "${GREEN}üìä MONITORAMENTO:${NC}"
echo "   eBPF Monitor: logs/ebpf_monitor.log"
if [ -n "${OBSERVER_PID:-}" ]; then
    echo "   Observer Service: logs/observer_service.log"
    echo "   M√©tricas Longo Prazo: data/long_term_logs/omnimind_metrics.jsonl"
    echo "   Heartbeat: data/long_term_logs/heartbeat.status"
fi
echo "   Logs Directory: logs/"
echo ""
echo "üìä Autopoiese Phase 23 (Active):"
echo "   - Componentes sintetizados: data/autopoietic/synthesized_code/"
echo "   - Hist√≥rico de ciclos: data/autopoietic/cycle_history.jsonl"
echo "   - Log do ciclo: logs/main_cycle.log"
