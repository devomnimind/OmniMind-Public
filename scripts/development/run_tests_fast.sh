#!/bin/bash

# ============================================================================
# âš¡ OMNIMIND FAST TEST SUITE
# ============================================================================
# Executa suite rÃ¡pida para validaÃ§Ã£o de cÃ³digo (DIÃRIA):
# - GPU FORÃ‡ADA (com fallback device_count detection)
# - Logs detalhados e timestamped com DEBUG verboso
# - Coverage completo com relatÃ³rios JSON, HTML e XML
# - MÃ©tricas JSON de execuÃ§Ã£o (via MetricsCollector)
# - ExportaÃ§Ã£o completa de todos os dados
# - Pula testes lentos/chaos/destrutivos
# - Foco em lÃ³gica, mocks e integridade
#
# ğŸš« EXCLUÃDOS:
#   - Testes @pytest.mark.chaos (destroem servidor - WEEKLY ONLY)
#
# âœ… INCLUÃDOS:
#   - Testes @pytest.mark.slow (cÃ¡lculos, estatÃ­sticas, GPU - DEVEM rodar no modo rÃ¡pido)
#   - Testes @pytest.mark.real SEM @pytest.mark.chaos (GPU+LLM+Network, nÃ£o destroem servidor)
#
# â³ DURAÃ‡ÃƒO: ~15-20 min
# ğŸ¯ RODAS: DiÃ¡rias (CI/CD automÃ¡tico)
#
# Para suite SEMANAL com todos os testes, use:
#   ./scripts/run_tests_with_defense.sh
# ============================================================================

set -e

cd /home/fahbrain/projects/omnimind

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_DIR="data/test_reports"
mkdir -p "$LOG_DIR"

# Arquivos de saÃ­da
OUTPUT_LOG="$LOG_DIR/output_fast_${TIMESTAMP}.log"
PYTEST_LOG="$LOG_DIR/pytest_fast_${TIMESTAMP}.log"
JUNIT_XML="$LOG_DIR/junit_fast_${TIMESTAMP}.xml"
HTML_REPORT="$LOG_DIR/report_fast_${TIMESTAMP}.html"
COVERAGE_JSON="$LOG_DIR/coverage_fast_${TIMESTAMP}.json"
COVERAGE_HTML="$LOG_DIR/coverage_fast_${TIMESTAMP}_html"
COVERAGE_XML="$LOG_DIR/coverage_fast_${TIMESTAMP}.xml"
METRICS_JSON="$LOG_DIR/metrics_report_fast_${TIMESTAMP}.json"
CONSOLIDATED_OUTPUT="$LOG_DIR/consolidated_fast_${TIMESTAMP}.log"

echo "âš¡ OMNIMIND FAST TEST SUITE"
echo "======================================"
echo "â±ï¸  Timestamp: $TIMESTAMP"
echo "ğŸ›¡ï¸  Modo: RÃ¡pido (Sem Chaos, COM Slow - GPU/CÃ¡lculos)"
echo "ğŸš€ GPU: FORÃ‡ADA (com fallback)"
echo "ğŸ“ˆ Coverage: ATIVADO (JSON, HTML, XML)"
echo "ğŸ› Debug: VERBOSO (DEBUG level)"
echo "ğŸ“‹ ExportaÃ§Ã£o: COMPLETA (todos os dados)"
echo "======================================"
echo ""

# Contar testes dinamicamente (SEM PRÃ‰-VALIDAÃ‡ÃƒO - REMOVER BLOQUEIO)
echo "ğŸ“Š Contando testes disponÃ­veis..."
EXPECTED_TESTS=$(pytest --collect-only -q tests/ -m "not chaos" 2>/dev/null | tail -1 || echo "calculando...")
if [ "$EXPECTED_TESTS" != "calculando..." ] && [ -n "$EXPECTED_TESTS" ]; then
    echo "ğŸ“Š Testes encontrados: $EXPECTED_TESTS"
else
    echo "ğŸ“Š Testes: calculando durante execuÃ§Ã£o..."
fi
echo ""

# Verificar GPU status ANTES dos testes (OTIMIZADO)
echo "ğŸ” Verificando GPU/CUDA status..."
python3 << 'GPUCHECK'
import torch
print(f"  âœ… torch.cuda.is_available(): {torch.cuda.is_available()}")
print(f"  âœ… torch.cuda.device_count(): {torch.cuda.device_count()}")
if torch.cuda.device_count() > 0:
    try:
        print(f"  âœ… torch.cuda.get_device_name(0): {torch.cuda.get_device_name(0)}")
    except:
        print(f"  âš ï¸  Device detectado mas nome indisponÃ­vel")
print("")
GPUCHECK

# Executa pytest com GPU FORÃ‡ADA, logs verbosos, coverage e mÃ©tricas
# CRITICAL: CUDA_VISIBLE_DEVICES=0 forÃ§a dispositivo 0
# OMNIMIND_FORCE_GPU=true forÃ§a detecÃ§Ã£o com device_count fallback
# --cov: Ativa coverage
# --cov-report: Gera relatÃ³rios em mÃºltiplos formatos
# --log-cli-level=DEBUG: Logs verbosos no console
# --log-cli-format: Formato detalhado dos logs
# -vv: Verbose mÃ¡ximo
# -s: NÃ£o captura output (mostra prints)
# --tb=long: Traceback longo para debug
# --cache-clear: Remove cache pytest (fix permissions sudo)
CUDA_VISIBLE_DEVICES=0 \
OMNIMIND_GPU=true \
OMNIMIND_FORCE_GPU=true \
OMNIMIND_DEV=true \
OMNIMIND_DEBUG=true \
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \
python3 -m pytest tests/ \
  -vv \
  --tb=long \
  -m "not chaos" \
  --cache-clear \
  --log-cli-level=DEBUG \
  --log-cli-format="%(asctime)s [%(levelname)8s] %(name)s:%(funcName)s:%(lineno)d - %(message)s" \
  --log-cli-date-format="%Y-%m-%d %H:%M:%S" \
  --log-file="$PYTEST_LOG" \
  --log-file-level=DEBUG \
  --junit-xml="$JUNIT_XML" \
  --html="$HTML_REPORT" \
  --self-contained-html \
  --cov=src \
  --cov-report=json:"$COVERAGE_JSON" \
  --cov-report=html:"$COVERAGE_HTML" \
  --cov-report=xml:"$COVERAGE_XML" \
  --cov-report=term-missing \
  --durations=10 \
  -s \
  2>&1 | tee "$OUTPUT_LOG"

EXIT_CODE=$?

# Aguardar um momento para garantir que todos os arquivos foram escritos
sleep 2

# Consolidar mÃ©tricas JSON se existir (gerado pelo MetricsCollector)
if [ -f "data/test_reports/metrics_report.json" ]; then
    echo ""
    echo "ğŸ“Š Copiando mÃ©tricas JSON com timestamp..."
    cp "data/test_reports/metrics_report.json" "$METRICS_JSON"
    echo "   âœ… MÃ©tricas salvas em: $METRICS_JSON"
fi

# Criar arquivo consolidado com todos os dados
echo ""
echo "ğŸ“¦ Consolidando todos os dados em arquivo Ãºnico..."
{
    echo "=========================================="
    echo "OMNIMIND FAST TEST SUITE - RELATÃ“RIO CONSOLIDADO"
    echo "=========================================="
    echo "Timestamp: $TIMESTAMP"
    echo "Exit Code: $EXIT_CODE"
    echo ""
    echo "=========================================="
    echo "1. OUTPUT COMPLETO (stdout/stderr)"
    echo "=========================================="
    cat "$OUTPUT_LOG"
    echo ""
    echo "=========================================="
    echo "2. PYTEST LOGS (DEBUG VERBOSO)"
    echo "=========================================="
    if [ -f "$PYTEST_LOG" ]; then
        cat "$PYTEST_LOG"
    else
        echo "âš ï¸  Arquivo de log pytest nÃ£o encontrado"
    fi
    echo ""
    echo "=========================================="
    echo "3. MÃ‰TRICAS DE EXECUÃ‡ÃƒO (JSON)"
    echo "=========================================="
    if [ -f "$METRICS_JSON" ]; then
        cat "$METRICS_JSON"
    else
        echo "âš ï¸  Arquivo de mÃ©tricas nÃ£o encontrado"
    fi
    echo ""
    echo "=========================================="
    echo "4. COVERAGE SUMMARY (JSON)"
    echo "=========================================="
    if [ -f "$COVERAGE_JSON" ]; then
        cat "$COVERAGE_JSON"
    else
        echo "âš ï¸  Arquivo de coverage JSON nÃ£o encontrado"
    fi
    echo ""
    echo "=========================================="
    echo "5. JUNIT XML (CI/CD) - Primeiras 50 linhas"
    echo "=========================================="
    if [ -f "$JUNIT_XML" ]; then
        head -50 "$JUNIT_XML"
        echo "... (arquivo completo em: $JUNIT_XML)"
    else
        echo "âš ï¸  Arquivo JUnit XML nÃ£o encontrado"
    fi
} > "$CONSOLIDATED_OUTPUT"

echo "   âœ… Arquivo consolidado salvo em: $CONSOLIDATED_OUTPUT"

echo ""
echo "======================================"
echo "âœ… TESTES RÃPIDOS FINALIZADOS"
echo "======================================"
echo "ğŸ“‹ Logs e RelatÃ³rios salvos em: $LOG_DIR"
echo ""
echo "ğŸ“„ Arquivos Gerados:"
echo "   ğŸ“ output_fast_${TIMESTAMP}.log (stdout/stderr completo)"
echo "   ğŸ› pytest_fast_${TIMESTAMP}.log (pytest logs DEBUG verboso)"
echo "   ğŸ“Š metrics_report_fast_${TIMESTAMP}.json (mÃ©tricas de execuÃ§Ã£o JSON)"
echo "   ğŸ“ˆ coverage_fast_${TIMESTAMP}.json (coverage JSON)"
echo "   ğŸ“ˆ coverage_fast_${TIMESTAMP}_html/ (coverage HTML - abra index.html)"
echo "   ğŸ“ˆ coverage_fast_${TIMESTAMP}.xml (coverage XML)"
echo "   ğŸ“‹ junit_fast_${TIMESTAMP}.xml (CI/CD report)"
echo "   ğŸŒ report_fast_${TIMESTAMP}.html (dashboard HTML)"
echo "   ğŸ“¦ consolidated_fast_${TIMESTAMP}.log (TUDO consolidado)"
echo ""
echo "ğŸ’¡ Dicas:"
echo "   â€¢ Ver mÃ©tricas: cat $METRICS_JSON | jq"
echo "   â€¢ Ver coverage: cat $COVERAGE_JSON | jq"
echo "   â€¢ Ver tudo: less $CONSOLIDATED_OUTPUT"
echo "   â€¢ Abrir coverage HTML: xdg-open $COVERAGE_HTML/index.html"
echo ""

exit $EXIT_CODE
