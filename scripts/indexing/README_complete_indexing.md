# Script Completo de IndexaÃ§Ã£o - OmniMind

Este script executa a **indexaÃ§Ã£o completa de mÃ¡quina e cÃ³digo** para o sistema OmniMind, criando embeddings semÃ¢nticos de todo o codebase e configuraÃ§Ãµes.

## ğŸš€ Uso RÃ¡pido

```bash
# Do diretÃ³rio raiz do projeto
./scripts/indexing/complete_machine_code_indexing.sh
```

## ğŸ“‹ O que o Script Faz

### 1. **ConfiguraÃ§Ã£o Inicial**
- âœ… Ativa ambiente virtual Python
- âœ… Configura CUDA para GPU (GTX 1650 otimizado)
- âœ… Verifica disponibilidade de GPU

### 2. **VerificaÃ§Ã£o de DependÃªncias**
- âœ… Verifica se Qdrant estÃ¡ rodando
- âœ… Inicia Qdrant via Docker se necessÃ¡rio
- âœ… Inicializa coleÃ§Ãµes necessÃ¡rias

### 3. **IndexaÃ§Ã£o Completa**
- âœ… Indexa **todas as etapas** do sistema:
  - `core_code`: CÃ³digo principal (src/)
  - `tests`: Testes (tests/)
  - `scripts`: Scripts (scripts/)
  - `configs`: ConfiguraÃ§Ãµes (config/)
  - `datasets`: Datasets (datasets/)
  - `deploy`: Deploy (deploy/)
  - `docs`: DocumentaÃ§Ã£o (docs/)
  - `archive`: Arquivo (archive/)
  - `logs_main`: Logs principais
  - `data_core`: Dados core
  - `data_reports`: RelatÃ³rios
  - `kernel_files`: Arquivos kernel
  - `system_metadata`: Metadados do sistema
  - `data_modules`: MÃ³dulos de dados
  - `exports`: Exports
  - `tmp`: TemporÃ¡rios

### 4. **OtimizaÃ§Ã£o de Performance**
- ğŸ¯ **GPU Acelerada**: Usa CUDA 13.0 com GTX 1650
- âš¡ **Processamento Paralelo**: 2 workers simultÃ¢neos
- ğŸ“¦ **Batch Otimizado**: 64 embeddings por batch
- ğŸ’¾ **GestÃ£o de MemÃ³ria**: Threshold de 1000MB GPU

### 5. **Monitoramento e VerificaÃ§Ã£o**
- ğŸ“Š **Progresso em Tempo Real**: Mostra progresso da indexaÃ§Ã£o
- ğŸ” **Testes de Busca**: Valida funcionamento com queries de teste
- ğŸ“ˆ **EstatÃ­sticas Completas**: Total de chunks, dimensÃµes, modelo usado
- ğŸ“ **Logs Detalhados**: Arquivo de log timestamped

## ğŸ“Š Resultados Esperados

ApÃ³s execuÃ§Ã£o bem-sucedida, vocÃª terÃ¡:

```
ğŸ“ˆ Total de chunks: ~2,000-3,000 (dependendo do projeto)
ğŸ¯ DimensÃ£o: 384 (all-MiniLM-L6-v2)
ğŸ¤– Modelo: sentence-transformers/all-MiniLM-L6-v2
ğŸ’¾ Status: Ativo
```

## ğŸ” Funcionalidades Desbloqueadas

Com a indexaÃ§Ã£o completa, o OmniMind ganha:

- **ğŸ” Busca SemÃ¢ntica AvanÃ§ada**: Encontre cÃ³digo por significado, nÃ£o apenas texto
- **ğŸ¤– Processamento de Linguagem Natural**: Entenda contexto e intenÃ§Ãµes
- **ğŸ“š Contexto Completo**: MemÃ³ria de todo o sistema
- **ğŸ§  Sistema AutopoÃ©tico**: Capacidade de auto-reflexÃ£o e evoluÃ§Ã£o

## ğŸ“ Arquivos Gerados

```
logs/indexing/
â”œâ”€â”€ complete_indexing_YYYYMMDD_HHMMSS.log    # Log completo da execuÃ§Ã£o
â””â”€â”€ stats_YYYYMMDD_HHMMSS.json              # EstatÃ­sticas finais

data/context/
â””â”€â”€ *.json                                  # Arquivos de contexto indexados
```

## âš™ï¸ PersonalizaÃ§Ã£o

Para modificar parÃ¢metros, edite o script:

```bash
# NÃºmero de workers (padrÃ£o: 2)
--max-workers 4

# Tamanho do batch (padrÃ£o: 64)
--batch-size 32

# Threshold de memÃ³ria GPU (padrÃ£o: 1000MB)
--gpu-memory-threshold 500
```

## ğŸ› Troubleshooting

### Problema: CUDA nÃ£o disponÃ­vel
```bash
# Verifique instalaÃ§Ã£o CUDA
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"
```

### Problema: Qdrant nÃ£o inicia
```bash
# Inicie manualmente
docker-compose -f deploy/docker-compose.yml up -d qdrant
```

### Problema: MemÃ³ria GPU insuficiente
```bash
# Reduza batch size
--batch-size 32 --gpu-memory-threshold 500
```

## ğŸ“ˆ Monitoramento

Durante execuÃ§Ã£o:
```bash
# Monitore GPU
watch -n 5 nvidia-smi

# Monitore progresso
tail -f logs/indexing/complete_indexing_*.log
```

## ğŸ¯ PrÃ³ximos Passos

ApÃ³s indexaÃ§Ã£o completa:

1. **Teste Consultas**: `python scripts/indexing/test_semantic_search.py`
2. **Verifique Logs**: `tail -f logs/embedding_indexing.log`
3. **Inicie Sistema**: `./scripts/canonical/system/start_omnimind_system.sh`

---

**ğŸš€ OmniMind Indexado e Pronto para OperaÃ§Ã£o!**
