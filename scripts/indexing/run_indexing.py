#!/usr/bin/env python3
"""
Script para executar a indexa√ß√£o de embeddings do OmniMind.

Uso:
    python run_indexing.py                    # Indexa√ß√£o completa
    python run_indexing.py --incremental      # Indexa√ß√£o incremental
    python run_indexing.py --help             # Ajuda

Funcionalidades:
- Indexa√ß√£o completa: processa todos os arquivos
- Indexa√ß√£o incremental: s√≥ processa arquivos modificados
- Suporte a paraleliza√ß√£o
- Logging detalhado
"""

import argparse
import logging
import sys
from pathlib import Path

from embeddings.code_embeddings import OmniMindEmbeddings

# Adicionar src ao path
project_root = Path(__file__).parent.parent.parent  # scripts/indexing/ -> scripts/ -> project_root
src_path = project_root / "src"
sys.path.insert(0, str(src_path))
sys.path.insert(0, str(project_root))

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(project_root / "logs" / "embedding_indexing.log", mode="a"),
    ],
)

logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description="Indexa√ß√£o de embeddings OmniMind")
    parser.add_argument(
        "--incremental",
        action="store_true",
        help="Executar indexa√ß√£o incremental (s√≥ arquivos modificados)",
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=4,
        help="N√∫mero m√°ximo de workers para paraleliza√ß√£o (padr√£o: 4)",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=64,
        help="Tamanho do batch para gera√ß√£o de embeddings (padr√£o: 64)",
    )
    parser.add_argument(
        "--skip-node-modules",
        action="store_true",
        help="Pular diret√≥rios node_modules (padr√£o: False)",
    )
    parser.add_argument(
        "--min-file-size",
        type=int,
        default=50,
        help="Tamanho m√≠nimo de arquivo em bytes (padr√£o: 50)",
    )
    parser.add_argument(
        "--qdrant-url",
        default="http://localhost:6333",
        help="URL do Qdrant (padr√£o: http://localhost:6333)",
    )
    parser.add_argument(
        "--collection",
        default="omnimind_embeddings",
        help="Nome da cole√ß√£o Qdrant (padr√£o: omnimind_embeddings)",
    )
    parser.add_argument(
        "--gpu-memory-threshold",
        type=float,
        default=1000.0,
        help="Threshold de mem√≥ria GPU em MB para for√ßar uso (padr√£o: 1000.0)",
    )
    parser.add_argument(
        "--force-gpu",
        action="store_true",
        help="For√ßar uso de GPU mesmo com pouca mem√≥ria (usa OMNIMIND_FORCE_GPU_EMBEDDINGS=true)",
    )
    parser.add_argument(
        "--disable-async",
        action="store_true",
        help="Desabilitar execu√ß√£o ass√≠ncrona de embeddings",
    )
    parser.add_argument(
        "--stages",
        nargs="*",
        help="""Etapas espec√≠ficas para executar (ex: core_code tests docs).
Se n√£o especificado, executa todas""",
    )
    parser.add_argument(
        "--checkpoint-file",
        default=".omnimind_embedding_checkpoint.json",
        help="""Arquivo de checkpoint para salvar progresso
(padr√£o: .omnimind_embedding_checkpoint.json)""",
    )
    parser.add_argument(
        "--reset-checkpoint",
        action="store_true",
        help="Resetar checkpoint e come√ßar do in√≠cio",
    )
    parser.add_argument(
        "--list-stages",
        action="store_true",
        help="Listar todas as etapas dispon√≠veis e sair",
    )
    parser.add_argument(
        "--cycle-min",
        type=int,
        help="N√∫mero m√≠nimo do ciclo para filtrar arquivos integration_loop_cycle_*.json",
    )
    parser.add_argument(
        "--cycle-max",
        type=int,
        help="N√∫mero m√°ximo do ciclo para filtrar arquivos integration_loop_cycle_*.json",
    )
    parser.add_argument(
        "--no-mark-complete",
        action="store_true",
        help="N√£o marcar a etapa como conclu√≠da (para processamento em lotes)",
    )

    args = parser.parse_args()

    # Listar etapas se solicitado
    if args.list_stages:
        print("üìã Etapas dispon√≠veis para indexa√ß√£o:")
        stages_info = {
            "core_code": "C√≥digo Principal (src/)",
            "tests": "Testes (tests/)",
            "scripts": "Scripts (scripts/)",
            "configs": "Configura√ß√µes (config/)",
            "datasets": "Datasets (datasets/)",
            "deploy": "Deploy (deploy/)",
            "docs": "Documenta√ß√£o (docs/)",
            "archive": "Arquivo (archive/)",
            "logs_main": "Logs Principais (logs/)",
            "node_modules_main": "Node Modules Principais (limitado)",
            "data_core": "Dados Core (data/, exceto m√≥dulos massivos)",
            "data_reports": "Relat√≥rios (reports/)",
            "kernel_files": "Arquivos Kernel (kernel_ai/, quantum_ai/, etc.)",
            "system_metadata": "Metadados do Sistema",
            "data_modules": "M√≥dulos de Dados (data/reports/modules/ - massivo)",
            "exports": "Exports (exports/)",
            "tmp": "Tempor√°rios (tmp/)",
        }
        for stage, desc in stages_info.items():
            print(f"  {stage}: {desc}")
        print(
            "\nüí° Ordem recomendada: core_code tests scripts configs datasets deploy "
            "docs archive logs_main node_modules_main data_core data_reports "
            "kernel_files system_metadata data_modules exports tmp"
        )
        return

    # Resetar checkpoint se solicitado
    if args.reset_checkpoint:
        checkpoint_path = project_root / args.checkpoint_file
        if checkpoint_path.exists():
            checkpoint_path.unlink()
            logger.info(f"üóëÔ∏è Checkpoint resetado: {checkpoint_path}")
        else:
            logger.info("‚ÑπÔ∏è Nenhum checkpoint encontrado para resetar")

    # Configurar filtros de arquivo
    skip_patterns = []
    if args.skip_node_modules:
        skip_patterns.append("node_modules")
        logger.info("üö´ Pulando diret√≥rios node_modules")

    # Configurar vari√°vel de ambiente se for√ßado
    if args.force_gpu:
        import os

        os.environ["OMNIMIND_FORCE_GPU_EMBEDDINGS"] = "true"
        logger.info("üîß GPU for√ßado via OMNIMIND_FORCE_GPU_EMBEDDINGS=true")

    try:
        logger.info("üöÄ Iniciando sistema de embeddings OmniMind")
        logger.info(f"Modo: {'Incremental' if args.incremental else 'Completo'}")
        logger.info(f"Workers: {args.max_workers}")
        logger.info(f"Batch size: {args.batch_size}")
        logger.info(f"GPU threshold: {args.gpu_memory_threshold}MB")
        logger.info(f"Min file size: {args.min_file_size} bytes")
        logger.info(f"Qdrant: {args.qdrant_url}")
        logger.info(f"Cole√ß√£o: {args.collection}")
        logger.info(f"Checkpoint: {args.checkpoint_file}")

        if args.stages:
            logger.info(f"Etapas: {', '.join(args.stages)}")
        else:
            logger.info("Etapas: Todas (com checkpointing)")

        # Verificar se Qdrant est√° rodando
        import requests

        try:
            # Tentar endpoint de sa√∫de do Qdrant (pode ser /healthz ou /)
            health_endpoints = [f"{args.qdrant_url}/healthz", f"{args.qdrant_url}/"]
            qdrant_ok = False

            for endpoint in health_endpoints:
                try:
                    response = requests.get(endpoint, timeout=5)
                    if response.status_code in [200, 404]:  # 404 √© aceit√°vel para alguns endpoints
                        qdrant_ok = True
                        break
                except Exception:
                    continue

            if not qdrant_ok:
                logger.error("Qdrant n√£o est√° respondendo em nenhum endpoint de sa√∫de")
                logger.error("Certifique-se de que o Qdrant est√° rodando:")
                logger.error("  docker-compose -f deploy/docker-compose.yml up -d qdrant")
                sys.exit(1)

        except Exception as e:
            logger.error(f"Erro ao conectar com Qdrant: {e}")
            logger.error("Certifique-se de que o Qdrant est√° rodando:")
            logger.error("  docker-compose -f deploy/docker-compose.yml up -d qdrant")
            sys.exit(1)

        # Inicializar sistema de embeddings
        embeddings = OmniMindEmbeddings(
            qdrant_url=args.qdrant_url,
            collection_name=args.collection,
            gpu_memory_threshold_mb=args.gpu_memory_threshold,
            batch_size_embeddings=args.batch_size,
            enable_async_execution=not args.disable_async,
        )

        # Executar indexa√ß√£o
        logger.info(f"üìÅ Indexando projeto: {project_root}")
        results = embeddings.index_omnimind_project(
            str(project_root),
            max_workers=args.max_workers,
            incremental=args.incremental,
            skip_patterns=skip_patterns,
            min_file_size=args.min_file_size,
            stages=args.stages,
            checkpoint_file=args.checkpoint_file,
            cycle_min=args.cycle_min,
            cycle_max=args.cycle_max,
            no_mark_complete=args.no_mark_complete,
        )

        # Calcular estat√≠sticas
        total_chunks = 0
        total_files = 0
        for stage_name, stage_results in results.items():
            if isinstance(stage_results, dict):
                stage_chunks = sum(stage_results.values())
                stage_files = len(stage_results)
                total_chunks += stage_chunks
                total_files += stage_files
                logger.info(f"üìä {stage_name}: {stage_files} arquivos, {stage_chunks} chunks")

        logger.info("‚úÖ Indexa√ß√£o conclu√≠da!")
        logger.info(f"üìà Total: {total_files} arquivos processados, {total_chunks} chunks criados")

        # Mostrar estat√≠sticas da cole√ß√£o
        stats = embeddings.get_stats()
        logger.info(f"üìä Estat√≠sticas da cole√ß√£o: {stats}")

        # Exemplo de busca
        logger.info("üîç Testando busca sem√¢ntica...")
        test_queries = [
            "fun√ß√£o principal do sistema",
            "configura√ß√£o do kernel",
            "processamento de dados",
        ]

        for query in test_queries:
            results = embeddings.search(query, top_k=2)
            if results:
                logger.info(
                    f"  Query: '{query}' -> Top result: {results[0]['file_path']} "
                    f"(score: {results[0]['score']:.3f})"
                )

    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Indexa√ß√£o interrompida pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Erro durante indexa√ß√£o: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
