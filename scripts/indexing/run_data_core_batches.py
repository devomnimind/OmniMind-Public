#!/usr/bin/env python3
"""
Script auxiliar para dividir data_core em sub-etapas menores.
Executa data_core em lotes menores para evitar timeouts.
"""

import argparse
import subprocess
import sys
from pathlib import Path

# Adicionar src ao path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))


def get_data_core_subdirs():
    """Retorna lista de subdiret√≥rios em data/ para processamento em lotes."""
    data_dir = project_root / "data"

    # Subdiret√≥rios priorit√°rios (excluindo reports/modules que √© massivo)
    priority_subdirs = [
        "alerts",
        "autopoietic",
        "backup",
        "benchmarks",
        "consciousness",
        "context",
        "datasets",
        "ethics",
        "experiments",
        "forensics",
        "integrity_baselines",
        "long_term_logs",
        "metrics",
        "ml",
        "monitor",
        "qdrant",
        "reports",
        "research",
        "sessions",
        "stimulation",
        "training",
        "validation",
    ]

    existing_subdirs = []
    for subdir in priority_subdirs:
        full_path = data_dir / subdir
        if full_path.exists() and full_path.is_dir():
            existing_subdirs.append(subdir)

    return existing_subdirs


def run_data_core_batch(batch_name: str, max_workers: int = 2, cycle_range: tuple = None):
    """Executa um lote espec√≠fico de data_core."""
    print(f"\nüöÄ Executando lote data_core: {batch_name}")
    if cycle_range:
        print(f"   Intervalo de ciclos: {cycle_range[0]} - {cycle_range[1]}")

    cmd = [
        sys.executable,
        "run_indexing.py",
        "--stages",
        f"data_core_{batch_name}",
        "--max-workers",
        str(max_workers),
        "--min-file-size",
        "50",
        "--gpu-memory-threshold",
        "1000",
        "--batch-size",
        "32",
    ]

    # Adicionar par√¢metros de intervalo se especificado
    if cycle_range:
        cmd.extend(["--cycle-min", str(cycle_range[0]), "--cycle-max", str(cycle_range[1])])
        # Para reports_small com intervalos, n√£o marcar como conclu√≠da automaticamente
        if batch_name == "reports_small":
            cmd.append("--no-mark-complete")

    try:
        result = subprocess.run(cmd, cwd=project_root, timeout=300)  # 5 minutos timeout
        return result.returncode == 0
    except subprocess.TimeoutExpired:
        print(f"‚è∞ Timeout no lote {batch_name} (5 minutos)")
        return False
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è Lote {batch_name} interrompido pelo usu√°rio")
        return False
    except Exception as e:
        print(f"‚ùå Erro no lote {batch_name}: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="Dividir data_core em sub-etapas")
    parser.add_argument("--batch", help="Executar um lote espec√≠fico")
    parser.add_argument("--list", action="store_true", help="Listar lotes dispon√≠veis")
    parser.add_argument("--max-workers", type=int, default=2, help="Workers por lote")
    parser.add_argument("--cycle-min", type=int, help="N√∫mero m√≠nimo do ciclo para reports_small")
    parser.add_argument("--cycle-max", type=int, help="N√∫mero m√°ximo do ciclo para reports_small")

    args = parser.parse_args()

    subdirs = get_data_core_subdirs()

    if args.list:
        print("üìã Lotes dispon√≠veis para data_core:")
        for i, subdir in enumerate(subdirs):
            print(f"  {i+1}. data_core_{subdir}")
        print(f"  {len(subdirs)+1}. data_core_reports_small (exceto modules)")
        print("  Para reports_small, use --cycle-min e --cycle-max para intervalos")
        return

    if args.batch:
        if args.batch.startswith("data_core_"):
            batch_name = args.batch[10:]  # Remove prefixo
        else:
            batch_name = args.batch

        # Definir intervalo de ciclos se especificado
        cycle_range = None
        if args.cycle_min is not None and args.cycle_max is not None:
            cycle_range = (args.cycle_min, args.cycle_max)

        # Lotes especiais
        if batch_name == "reports_small":
            # Processa reports excluindo modules, com intervalo opcional
            success = run_data_core_batch("reports_small", args.max_workers, cycle_range)
        elif batch_name in subdirs:
            # Processa subdiret√≥rio espec√≠fico
            success = run_data_core_batch(batch_name, args.max_workers)
        else:
            print(f"‚ùå Lote desconhecido: {batch_name}")
            return

        if success:
            print(f"‚úÖ Lote {args.batch} conclu√≠do!")
        else:
            print(f"‚ùå Lote {args.batch} falhou!")
            sys.exit(1)

    else:
        # Executar todos os lotes
        print("üöÄ Executando data_core em lotes menores...")
        print(f"üìã Lotes: {len(subdirs)} subdiret√≥rios + reports_small")

        failed_batches = []

        # Primeiro os subdiret√≥rios individuais
        for subdir in subdirs:
            if subdir == "reports":
                # Reports ser√° feito separadamente como reports_small
                continue

            success = run_data_core_batch(subdir, args.max_workers)
            if not success:
                failed_batches.append(f"data_core_{subdir}")
                print(f"‚ö†Ô∏è Lote data_core_{subdir} falhou, continuando...")

        # Depois reports_small (excluindo modules)
        success = run_data_core_batch("reports_small", args.max_workers)
        if not success:
            failed_batches.append("data_core_reports_small")

        if failed_batches:
            print(f"\n‚ùå Lotes que falharam: {', '.join(failed_batches)}")
            sys.exit(1)
        else:
            print("\nüéâ Todos os lotes de data_core conclu√≠dos!")


if __name__ == "__main__":
    main()
