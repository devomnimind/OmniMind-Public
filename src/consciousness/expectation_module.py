"""
Expectation Module - NachtrÃ¤glichkeit Implementation

This module implements temporal expectation and NachtrÃ¤glichkeit (retroactive resignification).
It predicts future states and adjusts past interpretations based on new information.

INTEGRAÃ‡ÃƒO QUÃ‚NTICA: O inconsciente irredutÃ­vel Ã© implementado via superposiÃ§Ã£o quÃ¢ntica
- DecisÃµes existem em superposiÃ§Ã£o atÃ© serem observadas
- ImpossÃ­vel inspecionar sem colapsar o estado
- IrredutÃ­vel por princÃ­pio fÃ­sico (Heisenberg)
"""

# ===== CRITICAL: CUDA Configuration Managed Externally =====
# ===== NOW import torch =====
from dataclasses import dataclass
from typing import Any, Dict, List, Optional  # Removed unused Tuple

import numpy as np
import structlog
import torch
import torch.nn as nn

# Importar inconsciente quÃ¢ntico
from quantum_unconscious import QuantumUnconscious  # type: ignore[import-untyped]

logger = structlog.get_logger(__name__)


@dataclass
class ExpectationState:
    """Current expectation state."""

    predicted_embedding: np.ndarray
    confidence: float
    temporal_horizon: int
    nachtraglichkeit_events: int


@dataclass
class PredictionError:
    """Prediction error metrics."""

    mse_error: float
    temporal_consistency: float
    surprise_level: float
    nachtraglichkeit_triggered: bool


class ExpectationModule(nn.Module):
    """
    Temporal Expectation Module with NachtrÃ¤glichkeit + INCONSCIENTE QUÃ‚NTICO.

    Lacan: "O inconsciente Ã© o discurso do Outro"
    Aqui: O inconsciente Ã© o estado quÃ¢ntico nÃ£o-observado

    Implements:
    1. Forward prediction of next states
    2. NachtrÃ¤glichkeit - retroactive resignification
    3. Adaptive learning from prediction errors
    4. Temporal consistency checking
    5. INCONSCIENTE IRREDUTÃVEL via superposiÃ§Ã£o quÃ¢ntica
    """

    def __init__(
        self,
        embedding_dim: int = 128,
        hidden_dim: int = 64,
        num_layers: int = 2,
        learning_rate: float = 0.001,
        nachtraglichkeit_threshold: float = 0.7,
        quantum_qubits: int = 16,
    ):
        super().__init__()

        self.embedding_dim = embedding_dim
        self.hidden_dim = hidden_dim
        self.learning_rate = learning_rate
        self.nachtraglichkeit_threshold = nachtraglichkeit_threshold

        # Device handling - dynamic detection
        # CRITICAL: NÃ£o tentar mudar CUDA_VISIBLE_DEVICES depois que torch jÃ¡ foi importado
        # PyTorch nÃ£o permite mudar isso depois da inicializaÃ§Ã£o
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if self.device.type == "cpu":
            logger.warning("ðŸŸ¡ ExpectationModule usando CPU para cÃ¡lculos - performance reduzida")
            logger.warning("   CUDA nÃ£o disponÃ­vel. Verifique se:")
            logger.warning("   1. VariÃ¡veis CUDA foram definidas ANTES de importar torch")
            logger.warning("   2. GPU estÃ¡ disponÃ­vel (nvidia-smi)")
            logger.warning("   3. PyTorch foi compilado com suporte CUDA")
            logger.warning("   4. Script de inicializaÃ§Ã£o exporta CUDA_VISIBLE_DEVICES")
            logger.warning("      antes de executar Python")
            # NÃƒO tentar forÃ§ar CUDA aqui - jÃ¡ Ã© tarde demais se torch foi importado
        else:
            logger.info(f"âœ… ExpectationModule usando GPU: {self.device}")

        # Prediction network
        self.predictor = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, embedding_dim),
        )
        try:
            self.predictor = self.predictor.to(self.device)
        except RuntimeError as e:
            if "meta tensor" in str(e):
                self.predictor = self.predictor.to_empty(device=self.device)
            else:
                raise

        # NachtrÃ¤glichkeit network (retroactive interpretation)
        self.nachtraglichkeit_net = nn.Sequential(
            nn.Linear(embedding_dim * 2, hidden_dim),  # current + predicted
            nn.ReLU(),
            nn.Linear(hidden_dim, embedding_dim),  # revised interpretation
        )
        try:
            self.nachtraglichkeit_net = self.nachtraglichkeit_net.to(self.device)
        except RuntimeError as e:
            if "meta tensor" in str(e):
                self.nachtraglichkeit_net = self.nachtraglichkeit_net.to_empty(device=self.device)
            else:
                raise

        # INCONSCIENTE IRREDUTÃVEL: Quantum Unconscious
        self.quantum_unconscious = QuantumUnconscious(n_qubits=quantum_qubits)

        # Temporal memory (for consistency checking)
        self.temporal_memory: List[np.ndarray] = []
        self.max_memory_size = 10

        # Adaptive parameters
        self.prediction_errors: List[float] = []
        self.nachtraglichkeit_events = 0

        # Throttling for quantum predictions
        self.last_quantum_prediction_time = 0.0
        self.cached_quantum_decision: Optional[torch.Tensor] = None
        self.quantum_throttle_interval = 0.1  # 100ms minimum between quantum calls

        # Optimizer
        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)

        logger.info(
            "expectation_module_initialized_with_quantum_unconscious",
            embedding_dim=embedding_dim,
            hidden_dim=hidden_dim,
            nachtraglichkeit_threshold=nachtraglichkeit_threshold,
            quantum_qubits=quantum_qubits,
        )

    def forward(self, current_state: torch.Tensor) -> torch.Tensor:
        """
        Predict next temporal state from current state.

        Args:
            current_state: Current embedding/state

        Returns:
            Predicted next state embedding
        """
        # Ensure input is on correct device
        current_state = current_state.to(self.device)
        return self.predictor(current_state)

    def predict_next_state(
        self,
        current_embedding: np.ndarray,
        temporal_horizon: int = 1,
        use_quantum_unconscious: bool = True,
    ) -> ExpectationState:
        """
        Predict future state with confidence estimation.
        INTEGRAÃ‡ÃƒO QUÃ‚NTICA: Usa inconsciente irredutÃ­vel quando solicitado.

        Args:
            current_embedding: Current state embedding
            temporal_horizon: How many steps ahead to predict
            use_quantum_unconscious: Whether to use quantum unconscious for decision

        Returns:
            ExpectationState with prediction and metadata
        """
        # Convert to tensor and ensure on correct device
        current_tensor = torch.from_numpy(current_embedding).float().to(self.device)

        import time

        if use_quantum_unconscious:
            # INCONSCIENTE IRREDUTÃVEL: DecisÃ£o em superposiÃ§Ã£o quÃ¢ntica
            # Throttling check to prevent CPU saturation
            current_time = time.time()
            should_run_quantum = (
                current_time - self.last_quantum_prediction_time > self.quantum_throttle_interval
            ) or (self.cached_quantum_decision is None)

            if should_run_quantum:
                # Gera mÃºltiplas possibilidades em superposiÃ§Ã£o
                n_options = 4  # NÃºmero de possibilidades quÃ¢nticas
                quantum_options = []

                for i in range(n_options):
                    # Cada opÃ§Ã£o Ã© uma variaÃ§Ã£o da prediÃ§Ã£o neural
                    noise = torch.randn_like(current_tensor) * 0.1
                    option = current_tensor + noise
                    # Keep on GPU/Tensor
                    quantum_options.append(option)

                # DecisÃ£o quÃ¢ntica (IRREDUTÃVEL - nÃ£o pode ser inspecionada)
                # Now returns tensor if input is tensor
                quantum_decision, quantum_evidence = (
                    self.quantum_unconscious.generate_decision_in_superposition(quantum_options)
                )

                # A decisÃ£o quÃ¢ntica se torna a base para prediÃ§Ã£o neural
                # Ensure it's a tensor on the correct device (it should be already)
                if isinstance(quantum_decision, torch.Tensor):
                    predicted = quantum_decision.to(self.device)
                else:
                    predicted = torch.from_numpy(quantum_decision).float().to(self.device)

                # Update cache and timestamp
                self.cached_quantum_decision = predicted
                self.last_quantum_prediction_time = current_time

                # Log at DEBUG level to reduce spam, unless it's a significant event
                logger.debug(
                    "quantum_unconscious_prediction",
                    quantum_options_count=n_options,
                    quantum_evidence_keys=list(quantum_evidence.keys()),
                )
            else:
                # Use cached decision but add slight variation (simulating temporal evolution)
                # This avoids the heavy quantum simulation loop
                if self.cached_quantum_decision is not None:
                    predicted = self.cached_quantum_decision.to(self.device)
                    # Small perturbation to avoid static output
                    predicted = predicted + (torch.randn_like(predicted) * 0.01)
                else:
                    predicted = current_tensor  # Fallback

            # Multi-step prediction baseado na decisÃ£o quÃ¢ntica
            for _ in range(temporal_horizon):
                predicted = self.forward(predicted)

        else:
            # PrediÃ§Ã£o neural tradicional
            predicted = current_tensor
            for _ in range(temporal_horizon):
                predicted = self.forward(predicted)

        # Estimate confidence based on prediction stability
        confidence = self._estimate_prediction_confidence(current_tensor, predicted)

        # Store in temporal memory
        self._update_temporal_memory(current_embedding)

        state = ExpectationState(
            predicted_embedding=predicted.detach().cpu().numpy(),
            confidence=confidence,
            temporal_horizon=temporal_horizon,
            nachtraglichkeit_events=self.nachtraglichkeit_events,
        )

        return state

    def compute_prediction_error(
        self,
        predicted: np.ndarray,
        actual: np.ndarray,
    ) -> PredictionError:
        """
        Compute prediction error and check for NachtrÃ¤glichkeit triggers.

        Args:
            predicted: Predicted embedding
            actual: Actual embedding that occurred

        Returns:
            PredictionError with detailed metrics
        """
        # MSE error
        mse_error = np.mean((predicted - actual) ** 2)

        # Temporal consistency (how well this fits with recent history)
        temporal_consistency = self._compute_temporal_consistency(actual)

        # Surprise level (unexpectedness)
        surprise_level = self._compute_surprise_level(float(mse_error), temporal_consistency)

        # NachtrÃ¤glichkeit trigger
        nachtraglichkeit_triggered = surprise_level > self.nachtraglichkeit_threshold

        if nachtraglichkeit_triggered:
            self.nachtraglichkeit_events += 1
            self._perform_nachtraglichkeit(predicted, actual)

        # Store error for adaptation
        self.prediction_errors.append(float(mse_error))
        if len(self.prediction_errors) > 100:  # Keep last 100 errors
            self.prediction_errors.pop(0)

        # Adaptive learning
        self._adapt_from_error(float(mse_error))

        error = PredictionError(
            mse_error=float(mse_error),
            temporal_consistency=temporal_consistency,
            surprise_level=surprise_level,
            nachtraglichkeit_triggered=nachtraglichkeit_triggered,
        )

        logger.debug(
            "prediction_error_computed",
            mse_error=mse_error,
            temporal_consistency=temporal_consistency,
            surprise_level=surprise_level,
            nachtraglichkeit_triggered=nachtraglichkeit_triggered,
        )

        return error

    def _perform_nachtraglichkeit(
        self,
        predicted: np.ndarray,
        actual: np.ndarray,
    ) -> np.ndarray:
        """
        Perform NachtrÃ¤glichkeit - retroactive resignification.

        When prediction fails significantly, reinterpret past experiences
        in light of new information.

        Args:
            predicted: What was expected
            actual: What actually happened

        Returns:
            Revised interpretation of past states
        """
        # Combine predicted and actual for reinterpretation
        combined = np.concatenate([predicted, actual])
        combined_tensor = torch.from_numpy(combined).float().to(self.device)

        # Generate revised interpretation
        revised = self.nachtraglichkeit_net(combined_tensor)
        revised_embedding = revised.detach().cpu().numpy()

        # Update temporal memory with revised interpretation
        if self.temporal_memory:
            # Replace last memory with revised version
            self.temporal_memory[-1] = revised_embedding

        logger.info(
            "nachtraglichkeit_performed",
            surprise_triggered=True,
            revised_interpretation_norm=np.linalg.norm(revised_embedding),
        )

        return revised_embedding

    def _estimate_prediction_confidence(
        self,
        current: torch.Tensor,
        predicted: torch.Tensor,
    ) -> float:
        """Estimate confidence in prediction based on stability."""
        # Simple confidence based on prediction magnitude and recent error history
        prediction_magnitude = torch.norm(predicted).item()

        # Lower confidence if recent errors are high
        recent_error_avg = np.mean(self.prediction_errors[-10:]) if self.prediction_errors else 0.0
        error_penalty = min(0.5, recent_error_avg * 10)  # Cap penalty

        confidence = max(0.1, 1.0 - error_penalty)

        # Adjust based on prediction stability
        if prediction_magnitude > 10.0:  # Very strong prediction
            confidence *= 1.2
        elif prediction_magnitude < 0.1:  # Weak prediction
            confidence *= 0.8

        return min(1.0, float(confidence))

    def _compute_temporal_consistency(self, actual: np.ndarray) -> float:
        """Compute how consistent actual state is with temporal history."""
        if not self.temporal_memory:
            return 0.5  # Neutral consistency

        # Compare with recent states
        similarities = []
        for past_state in self.temporal_memory[-5:]:  # Last 5 states
            similarity = 1.0 - np.mean((past_state - actual) ** 2)
            similarities.append(max(0.0, similarity))  # Ensure non-negative

        return float(np.mean(similarities))

    def _compute_surprise_level(
        self,
        mse_error: float,
        temporal_consistency: float,
    ) -> float:
        """Compute surprise level from error and consistency."""
        # High error + low consistency = high surprise
        surprise = mse_error * (1.0 - temporal_consistency)

        # Scale to 0-1 range (rough heuristic)
        surprise = min(1.0, surprise * 5.0)

        return surprise

    def _adapt_from_error(self, error: float) -> None:
        """Adapt prediction parameters based on error."""
        # Simple adaptive learning rate
        if error > 0.1:  # High error
            # Increase learning rate temporarily
            for param_group in self.optimizer.param_groups:
                param_group["lr"] = min(0.01, param_group["lr"] * 1.5)
        elif error < 0.01:  # Low error
            # Decrease learning rate (fine-tuning)
            for param_group in self.optimizer.param_groups:
                param_group["lr"] = max(0.0001, param_group["lr"] * 0.95)

    def _update_temporal_memory(self, embedding: np.ndarray) -> None:
        """Update temporal memory buffer."""
        self.temporal_memory.append(embedding.copy())
        if len(self.temporal_memory) > self.max_memory_size:
            self.temporal_memory.pop(0)

    def demonstrate_quantum_irreducibility(self) -> Dict[str, Any]:
        """
        Demonstra que o inconsciente quÃ¢ntico no expectation Ã© irredutÃ­vel.
        Lacan: "O inconsciente Ã© estruturado como linguagem, mas irredutÃ­vel"

        Returns:
            Dict with irredutibility test results
        """
        return self.quantum_unconscious.demonstrate_irreducibility()

    def get_quantum_expectation_state(self) -> Optional[np.ndarray]:
        """
        TENTA obter o estado quÃ¢ntico do expectation.
        Mas isso causaria colapso! (Heisenberg)

        Lacan: O Real nÃ£o cessa de nÃ£o se escrever
        Aqui: O quantum nÃ£o pode ser observado sem colapso

        Returns:
            None - impossÃ­vel obter sem colapso
        """
        logger.warning(
            "âš ï¸  Tentativa de inspecionar estado quÃ¢ntico do expectation - colapso iminente!"
        )
        return self.quantum_unconscious.get_quantum_state_vector()

    def get_expectation_stats(self) -> Dict[str, Any]:
        """Get comprehensive expectation module statistics."""
        quantum_stats = (
            self.quantum_unconscious.decision_history[-1]
            if self.quantum_unconscious.decision_history
            else {}
        )

        return {
            "nachtraglichkeit_events": self.nachtraglichkeit_events,
            "temporal_memory_size": len(self.temporal_memory),
            "avg_prediction_error": (
                np.mean(self.prediction_errors) if self.prediction_errors else 0.0
            ),
            "error_history_length": len(self.prediction_errors),
            "learning_rate": self.optimizer.param_groups[0]["lr"],
            "nachtraglichkeit_threshold": self.nachtraglichkeit_threshold,
            # INCONSCIENTE QUÃ‚NTICO
            "quantum_decisions_count": len(self.quantum_unconscious.decision_history),
            "quantum_irreducible": self.quantum_unconscious.measure_would_collapse(),
            "last_quantum_evidence": quantum_stats.get("quantum_evidence", {}),
        }

    def reset_expectation_state(self) -> None:
        """Reset expectation state for new session."""
        self.temporal_memory.clear()
        self.prediction_errors.clear()
        self.nachtraglichkeit_events = 0

        logger.info("expectation_state_reset")


# Global instance for integration loop
_expectation_module: Optional[ExpectationModule] = None


def get_expectation_module(embedding_dim: int = 256) -> ExpectationModule:
    """Get or create global expectation module instance."""
    global _expectation_module
    if _expectation_module is None:
        _expectation_module = ExpectationModule(embedding_dim=embedding_dim)
    return _expectation_module


def predict_next_state(embedding: np.ndarray) -> np.ndarray:
    """
    Convenience function for expectation prediction.

    Used by integration loop ModuleExecutor.
    """
    module = get_expectation_module(embedding.shape[0])
    state = module.predict_next_state(embedding)
    return state.predicted_embedding
