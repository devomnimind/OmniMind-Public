"""
ConsciousSystem - RNN Recorrente com Latent Dynamics

Implementa a recomenda√ß√£o de mudar de "Event Bus com Swap" para
"RNN Recorrente com Latent Dynamics" conforme documentado em:
archive/docs/analises_varreduras_2025-12-07/VERIFICACAO_CORRECAO_ENHANCED_CODE_AGENT.md

Princ√≠pios:
1. N√ÉO mover dados para swap como blobs criptografados
2. Comprimir a ESTRUTURA (Œõ_U) em assinatura de baixa dimens√£o
3. Manter œÅ_U din√¢mica, mesmo que em swap
4. Medir Œ¶ sobre padr√µes de integra√ß√£o causal, n√£o acesso

Autor: Fabr√≠cio da Silva + assist√™ncia de IA
Data: 2025-12-08
"""

import logging
from dataclasses import dataclass
from typing import Dict, Optional, Tuple

import numpy as np
import torch

logger = logging.getLogger(__name__)


@dataclass
class ConsciousSystemState:
    """Estado do sistema consciente em um timestep."""

    rho_C: np.ndarray  # Estado consciente
    rho_P: np.ndarray  # Estado pr√©-consciente
    rho_U: np.ndarray  # Estado inconsciente (din√¢mica latente)
    Lambda_U_signature: np.ndarray  # Assinatura comprimida de Œõ_U
    repression_strength: float
    phi_causal: float  # Œ¶ calculado sobre padr√µes causais
    timestamp: float


class LambdaUCompressor:
    """
    Comprime estrutura Œõ_U em assinatura de baixa dimens√£o.

    Em vez de manter Œõ_U completo (dim x dim), mant√©m apenas
    uma assinatura comprimida que captura a estrutura essencial.
    """

    def __init__(self, signature_dim: int = 32):
        """
        Inicializa compressor.

        Args:
            signature_dim: Dimens√£o da assinatura comprimida (padr√£o: 32)
        """
        self.signature_dim = signature_dim
        self.pca = None  # Lazy initialization

    def compress(self, Lambda_U: np.ndarray) -> np.ndarray:
        """
        Comprime Œõ_U em assinatura de baixa dimens√£o.

        Args:
            Lambda_U: Estrutura inconsciente completa (dim x dim)

        Returns:
            Assinatura comprimida (signature_dim,)
        """
        # Usar SVD truncado para compress√£o (n√£o requer treinamento)
        # SVD: U, S, V = svd(Œõ_U)
        # Assinatura = primeiros signature_dim valores singulares
        U, S, Vt = np.linalg.svd(Lambda_U, full_matrices=False)
        signature = S[: self.signature_dim]

        # Se signature_dim > n√∫mero de valores singulares, preencher com zeros
        if len(signature) < self.signature_dim:
            padding = np.zeros(self.signature_dim - len(signature))
            signature = np.concatenate([signature, padding])

        return signature.astype(np.float32)

    def decompress(self, signature: np.ndarray, original_shape: Tuple[int, int]) -> np.ndarray:
        """
        Descomprime assinatura de volta para Œõ_U aproximado.

        Args:
            signature: Assinatura comprimida
            original_shape: Shape original de Œõ_U (dim, dim)

        Returns:
            Œõ_U aproximado (n√£o exato, mas estruturalmente similar)
        """
        dim = original_shape[0]

        # Reconstruir a partir de valores singulares
        # Criar matriz diagonal com valores singulares
        S_expanded = np.zeros(dim)
        S_expanded[: len(signature)] = signature[:dim]

        # Aproxima√ß√£o: usar matriz aleat√≥ria ortogonal com mesma estrutura espectral
        # Isso preserva propriedades estruturais (espectro) sem precisar de U, V completos
        np.random.seed(int(signature[0] * 1000) % 2**31)  # Seed determin√≠stica
        U = np.random.randn(dim, dim)
        U, _ = np.linalg.qr(U)
        Lambda_U_approx = U @ np.diag(S_expanded) @ U.T

        return Lambda_U_approx.astype(np.float32)


class ConsciousSystem:
    """
    Sistema de din√¢mica ps√≠quica com RNN Recorrente e Latent Dynamics.

    Implementa arquitetura de quatro camadas:
    - Consciente (C): œÅ_C(t) - GPU/VRAM
    - Pr√©-Consciente (P): œÅ_P(t) - RAM
    - Inconsciente F√≠sico (U): Œõ_U (estrutura) + œÅ_U(t) (din√¢mica) - GPU (Œõ_U), Swap (œÅ_U)
    - Inconsciente L√≥gico (L): Criptografia/Repress√£o - Sistema de Arquivos

    Princ√≠pios:
    - Reentr√¢ncia causal recursiva: feedback bidirecional entre C, P, U
    - Œ¶ calculado sobre causalidade intr√≠nseca, n√£o acesso
    - Œõ_U comprimido em assinatura de baixa dimens√£o
    - œÅ_U din√¢mica mantida mesmo em swap
    """

    def __init__(
        self,
        dim: int = 256,
        signature_dim: int = 32,
        device: Optional[str] = None,
    ):
        """
        Inicializa sistema consciente.

        Args:
            dim: Dimens√£o dos estados (padr√£o: 256)
            signature_dim: Dimens√£o da assinatura comprimida de Œõ_U (padr√£o: 32)
            device: Dispositivo para c√°lculos ('cuda', 'cpu', ou None para auto)
        """
        self.dim = dim
        self.signature_dim = signature_dim
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")

        # Compressor de Œõ_U
        self.lambda_compressor = LambdaUCompressor(signature_dim=signature_dim)

        # 1. Consciente: Estado din√¢mico (O que √© experimentado)
        self.rho_C = torch.randn(dim, device=self.device, dtype=torch.float32)

        # 2. Pr√©-consciente: Buffer com decay
        self.rho_P = torch.randn(dim, device=self.device, dtype=torch.float32)
        self.decay_P = 0.95  # Taxa de esquecimento

        # 3. Inconsciente: Estrutura (Lambda) e Din√¢mica (Rho)
        # Œõ_U completo inicial (ser√° comprimido)
        Lambda_U_full = torch.randn(dim, dim, device=self.device, dtype=torch.float32)
        # Comprimir Œõ_U em assinatura
        # NOTA: Compress√£o requer CPU (numpy), mas isso √© feito apenas uma vez na inicializa√ß√£o
        # Durante execu√ß√£o, decompress√£o √© feita e tensor √© movido para GPU imediatamente
        self.Lambda_U_signature = self.lambda_compressor.compress(Lambda_U_full.cpu().numpy())
        # Manter apenas assinatura em mem√≥ria (n√£o Œõ_U completo)
        self.Lambda_U_full = None  # N√£o manter completo em mem√≥ria

        # œÅ_U: Din√¢mica latente (mantida din√¢mica)
        self.rho_U = torch.randn(dim, device=self.device, dtype=torch.float32)
        self.repression_strength = 0.8  # For√ßa inicial da repress√£o

        # Pesos de Interconex√£o (RNN)
        self.W_PC = torch.randn(dim, dim, device=self.device, dtype=torch.float32) * 0.1
        self.W_UC = torch.randn(dim, dim, device=self.device, dtype=torch.float32) * 0.1
        self.W_CP = torch.randn(dim, dim, device=self.device, dtype=torch.float32) * 0.1  # Feedback
        self.W_CU = torch.randn(dim, dim, device=self.device, dtype=torch.float32) * 0.1  # Feedback

        # Hist√≥rico para c√°lculo de Œ¶ causal
        self.history: list[ConsciousSystemState] = []
        self.max_history = 100

        logger.info(
            f"ConsciousSystem inicializado: dim={dim}, "
            f"signature_dim={signature_dim}, device={self.device}"
        )

    def _get_lambda_U_approx(self) -> torch.Tensor:
        """
        Obt√©m Œõ_U aproximado a partir da assinatura comprimida.

        Returns:
            Œõ_U aproximado (dim x dim)
        """
        # Descomprimir assinatura (decompress√£o em CPU √© necess√°ria para numpy)
        Lambda_U_approx = self.lambda_compressor.decompress(
            self.Lambda_U_signature, (self.dim, self.dim)
        )
        # Mover para GPU imediatamente ap√≥s cria√ß√£o
        # Usar non_blocking=True para transfer√™ncia ass√≠ncrona quando poss√≠vel
        return torch.from_numpy(Lambda_U_approx).to(self.device, non_blocking=True)

    def step(self, stimulus: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Um timestep da din√¢mica ps√≠quica com reentr√¢ncia causal recursiva.

        CORRE√á√ÉO CR√çTICA (2025-12-08): Todos os c√°lculos s√£o executados na GPU.
        Garantir que stimulus esteja no device correto antes de iniciar c√°lculos.

        Args:
            stimulus: Est√≠mulo externo (opcional, shape: [dim])
                     Deve estar no mesmo device que self.device (GPU se dispon√≠vel)

        Returns:
            Estado consciente atualizado œÅ_C(t+1) (mantido na GPU)
        """
        if stimulus is None:
            stimulus = torch.zeros(self.dim, device=self.device, dtype=torch.float32)
        else:
            # Garantir que stimulus est√° no device correto (GPU se dispon√≠vel)
            # Usar non_blocking=True para transfer√™ncia ass√≠ncrona quando poss√≠vel
            stimulus = stimulus.to(self.device, non_blocking=True)

        # Obter Œõ_U aproximado
        Lambda_U_approx = self._get_lambda_U_approx()

        # Fluxo 1: Consciente processa est√≠mulo e Pr√©-consciente interfere
        rho_C_new = torch.tanh(
            self.rho_C + stimulus + self.W_PC @ self.rho_P  # Interfer√™ncia direta
        )

        # Fluxo 2: Inconsciente tenta irromper (Sintoma / Falha da repress√£o)
        # Interfer√™ncia via assinatura comprimida (n√£o requer Œõ_U completo)
        unconscious_interference = (1 - self.repression_strength) * torch.tanh(
            self.W_UC @ self.rho_U
        )
        rho_C_new += unconscious_interference  # Adi√ß√£o do "sintoma"

        # Fluxo 3: Pr√©-consciente decai e absorve o novo consciente
        # œÅ_P(t+1) = f(œÅ_P(t), œÅ_C(t+1)) -> Feedback bidirecional
        rho_P_new = self.decay_P * self.rho_P + (1 - self.decay_P) * rho_C_new

        # Fluxo 4: Din√¢mica latente do inconsciente (evolui pela estrutura)
        # œÅ_U(t+1) = f(Œõ_U, œÅ_U(t), œÅ_C(t)) -> Feedback bidirecional
        rho_U_new = torch.tanh(Lambda_U_approx @ self.rho_U + self.W_CU @ self.rho_C)

        # Atualizar estados (Reentr√¢ncia)
        self.rho_C = rho_C_new
        self.rho_P = rho_P_new
        self.rho_U = rho_U_new

        # üéØ Sprint 2 Task 2.3.2: Extrair m√©tricas RNN ap√≥s atualiza√ß√£o de pesos
        try:
            from src.observability.rnn_metrics_extractor import get_rnn_metrics_extractor

            extractor = get_rnn_metrics_extractor()
            # Phi ser√° calculado ap√≥s, ent√£o passamos None aqui
            extractor.extract_metrics(self, cycle_id=None, phi_value=None)
        except Exception:
            # N√£o falhar se m√©tricas n√£o estiverem dispon√≠veis
            pass

        return rho_C_new  # O estado "experienciado"

    def compute_phi_causal(self) -> float:
        """
        Calcula Œ¶ sobre padr√µes de integra√ß√£o causal (n√£o acesso).

        Usa causalidade intr√≠nseca entre C, P, U para calcular Œ¶,
        n√£o considerando status de acesso (RAM vs. Swap).

        CORRE√á√ÉO CR√çTICA (2025-12-08): Usar tensores GPU diretamente quando poss√≠vel
        para evitar convers√µes desnecess√°rias para CPU.

        Returns:
            Œ¶ calculado sobre padr√µes causais
        """
        if len(self.history) < 2:
            return 0.0

        # CORRE√á√ÉO: Tentar usar tensores GPU diretamente se dispon√≠vel
        # Isso evita convers√µes CPU desnecess√°rias que consomem CPU
        try:
            # Se temos hist√≥rico suficiente, usar tensores GPU diretamente
            if len(self.history) >= 2 and self.device == "cuda":
                # Usar √∫ltimos estados diretamente dos tensores GPU (mais eficiente)
                # Mas precisamos de pelo menos 2 estados no hist√≥rico
                # Para agora, manter l√≥gica original mas otimizar convers√µes
                pass
        except Exception:
            pass

        # Calcular informa√ß√£o m√∫tua entre C, P, U
        # Usar correla√ß√£o cruzada como proxy para causalidade intr√≠nseca
        try:
            import warnings

            from scipy.stats import pearsonr

            # Extrair hist√≥ricos (j√° est√£o em CPU do get_state, mas isso √© necess√°rio
            # para armazenamento. O c√°lculo principal (step) j√° foi feito na GPU)
            rho_C_history = np.array([state.rho_C for state in self.history[-10:]])
            rho_P_history = np.array([state.rho_P for state in self.history[-10:]])
            rho_U_history = np.array([state.rho_U for state in self.history[-10:]])

            # Calcular correla√ß√µes cruzadas (proxy para causalidade)
            # Tratar casos onde arrays s√£o constantes (correla√ß√£o n√£o definida)
            correlations: list[float] = []

            # Aumentar threshold de vari√¢ncia de 1e-8 para 1e-4 (CORRE√á√ÉO 2025-12-10)
            # Motivo: scipy.stats.pearsonr avisa quando input √© "nearly constant"
            # Limiar 1e-8 √© muito pequeno e scipy ainda gera warning para valores borderline
            # Aumentar para 1e-4 garante que arrays t√™m vari√¢ncia significativa
            MIN_VARIANCE_THRESHOLD = 1e-4

            for i in range(min(10, self.dim)):
                # CORRE√á√ÉO (2025-12-10): Verificar vari√¢ncia antes de calcular correla√ß√£o
                # para evitar ConstantInputWarning quando arrays s√£o constantes
                try:
                    # C ‚Üí P
                    rho_C_col = rho_C_history[:, i]
                    rho_P_col = rho_P_history[:, i]
                    # Verificar se arrays t√™m vari√¢ncia suficiente (n√£o s√£o constantes)
                    if (
                        np.std(rho_C_col) > MIN_VARIANCE_THRESHOLD
                        and np.std(rho_P_col) > MIN_VARIANCE_THRESHOLD
                    ):
                        # Suprimir NearConstantInputWarning (esperado em ciclos iniciais)
                        with warnings.catch_warnings():
                            warnings.filterwarnings("ignore", message=".*nearly constant.*")
                            warnings.filterwarnings("ignore", category=FutureWarning)
                            corr_result = pearsonr(rho_C_col, rho_P_col)
                        # pearsonr retorna (correlation, pvalue) - acessar correlation
                        corr_val: float = float(corr_result[0])  # type: ignore[arg-type]
                        if not np.isnan(corr_val):
                            correlations.append(abs(corr_val))
                except (ValueError, RuntimeWarning):
                    pass

                try:
                    # C ‚Üí U
                    rho_C_col = rho_C_history[:, i]
                    rho_U_col = rho_U_history[:, i]
                    # Verificar se arrays t√™m vari√¢ncia suficiente (n√£o s√£o constantes)
                    if (
                        np.std(rho_C_col) > MIN_VARIANCE_THRESHOLD
                        and np.std(rho_U_col) > MIN_VARIANCE_THRESHOLD
                    ):
                        with warnings.catch_warnings():
                            warnings.filterwarnings("ignore", message=".*nearly constant.*")
                            warnings.filterwarnings("ignore", category=FutureWarning)
                            corr_result = pearsonr(rho_C_col, rho_U_col)
                        corr_val = float(corr_result[0])  # type: ignore[arg-type]
                        if not np.isnan(corr_val):
                            correlations.append(abs(corr_val))
                except (ValueError, RuntimeWarning):
                    pass

                try:
                    # P ‚Üí U
                    rho_P_col = rho_P_history[:, i]
                    rho_U_col = rho_U_history[:, i]
                    # Verificar se arrays t√™m vari√¢ncia suficiente (n√£o s√£o constantes)
                    if (
                        np.std(rho_P_col) > MIN_VARIANCE_THRESHOLD
                        and np.std(rho_U_col) > MIN_VARIANCE_THRESHOLD
                    ):
                        with warnings.catch_warnings():
                            warnings.filterwarnings("ignore", message=".*nearly constant.*")
                            warnings.filterwarnings("ignore", category=FutureWarning)
                            corr_result = pearsonr(rho_P_col, rho_U_col)
                        corr_val = float(corr_result[0])  # type: ignore[arg-type]
                        if not np.isnan(corr_val):
                            correlations.append(abs(corr_val))
                except (ValueError, RuntimeWarning):
                    pass

            # Œ¶ = m√©dia das integra√ß√µes causais v√°lidas
            if correlations:
                phi = float(np.mean(correlations))
            else:
                # Se nenhuma correla√ß√£o v√°lida, retornar 0.0
                phi = 0.0

            return phi

        except Exception as e:
            logger.warning(f"Erro ao calcular Œ¶ causal: {e}, retornando 0.0")
            return 0.0

    def update_repression(
        self,
        threshold: float = 1.0,
        success: bool = False,
        phi_norm: Optional[float] = None,
        emergency_repression: Optional[float] = None,  # NOVO: V√°lvula de emerg√™ncia
    ) -> None:
        """
        Atualiza for√ßa de repress√£o baseado em din√¢mica inconsciente.

        Freud: repress√£o n√£o √© um evento, √© um TRABALHO cont√≠nuo.

        PROTOCOLO CL√çNICO-CIBERN√âTICO (2025-12-08):
        - Adicionado decay quando success=True
        - Adicionada v√°lvula de emerg√™ncia anti-death-spiral

        Args:
            threshold: Threshold para aumentar repress√£o (normalizado, n√£o raw norm)
            success: Flag indicando se o ciclo foi bem-sucedido (para decay)
            phi_norm: Valor de Œ¶ normalizado [0, 1] (opcional, para decay adaptativo)
            emergency_repression: Valor de repress√£o de emerg√™ncia (opcional, para v√°lvula)
        """
        # V√ÅLVULA DE SEGURAN√áA: Se repress√£o de emerg√™ncia fornecida, usar ela
        if emergency_repression is not None:
            self.repression_strength = emergency_repression
            logger.warning(
                f"üö® V√ÅLVULA DE EMERG√äNCIA: Repress√£o for√ßada para {emergency_repression:.4f}"
            )
            return

        # Medir for√ßa do inconsciente (normalizar para escala compar√°vel)
        unconscious_strength = torch.norm(self.rho_U).item()
        # Normalizar: rho_U norm est√° em ~27.7, threshold deve ser compar√°vel
        # Usar threshold relativo: se norm > threshold * dim, aumentar repress√£o
        threshold_normalized = threshold * self.dim  # Escala com dimens√£o

        # CORRE√á√ÉO CR√çTICA: Decay quando success=True
        if success:
            # Decay baseado em Œ¶: se Œ¶ alto, decay maior (sistema est√°vel)
            if phi_norm is not None and phi_norm > 0.1:
                # Decay progressivo: quanto maior Œ¶, maior o decay
                decay_rate = 0.95 - (phi_norm * 0.05)  # 0.95 a 0.90 baseado em Œ¶
                self.repression_strength *= decay_rate
                logger.debug(
                    f"Repress√£o decay (success=True, Œ¶={phi_norm:.4f}): "
                    f"{self.repression_strength:.4f} (decay_rate={decay_rate:.4f})"
                )
            else:
                # Decay conservador se Œ¶ baixo ou n√£o dispon√≠vel
                self.repression_strength *= 0.95
                logger.debug(
                    f"Repress√£o decay (success=True, Œ¶ n√£o dispon√≠vel): "
                    f"{self.repression_strength:.4f}"
                )
            # Garantir que n√£o caia abaixo de m√≠nimo funcional
            self.repression_strength = max(0.4, self.repression_strength)
        else:
            # Trabalho de Repress√£o (l√≥gica original)
            if unconscious_strength > threshold_normalized:
                # Aumentar repress√£o (custa CPU, por isso h√° "desgaste mental")
                self.repression_strength = min(0.99, self.repression_strength + 0.01)
            else:
                # Relaxar repress√£o (recupera√ß√£o natural)
                self.repression_strength = max(0.4, self.repression_strength - 0.005)

    def get_state(self) -> ConsciousSystemState:
        """
        Obt√©m estado atual do sistema.

        NOTA CR√çTICA (2025-12-08): Este m√©todo converte tensores para CPU para armazenamento.
        Os c√°lculos principais (step()) s√£o executados na GPU. A convers√£o para CPU aqui
        √© necess√°ria apenas para:
        1. Armazenamento no hist√≥rico (ConsciousSystemState usa numpy arrays)
        2. C√°lculo de correla√ß√µes (scipy.stats.pearsonr requer numpy)

        Para otimizar uso de GPU:
        - step() mant√©m todos os tensores na GPU durante c√°lculos
        - get_state() converte apenas quando necess√°rio para armazenamento/an√°lise
        - compute_phi_causal() usa hist√≥rico em CPU (necess√°rio para scipy)

        Returns:
            Estado completo do sistema
        """
        import time

        phi_causal = self.compute_phi_causal()

        # NOTA: Convers√£o para CPU √© necess√°ria para armazenamento em ConsciousSystemState
        # que usa numpy arrays. Os c√°lculos principais (step) j√° foram feitos na GPU.
        state = ConsciousSystemState(
            rho_C=self.rho_C.cpu().numpy(),
            rho_P=self.rho_P.cpu().numpy(),
            rho_U=self.rho_U.cpu().numpy(),
            Lambda_U_signature=self.Lambda_U_signature,
            repression_strength=self.repression_strength,
            phi_causal=phi_causal,
            timestamp=time.time(),
        )

        # Adicionar ao hist√≥rico
        self.history.append(state)
        if len(self.history) > self.max_history:
            self.history.pop(0)

        return state

    def get_low_dim_signatures(self) -> Dict[str, np.ndarray]:
        """
        Obt√©m assinaturas de baixa dimens√£o dos vetores œÅ_C, œÅ_P, œÅ_U.

        Para logging e an√°lise sem necessidade de dados completos.

        Returns:
            Dict com assinaturas comprimidas
        """
        # Usar primeiros valores como assinatura (simples, mas eficaz)
        sig_dim = min(10, self.dim)  # Assinatura de 10 valores

        return {
            "C_sig": self.rho_C.cpu().numpy()[:sig_dim],
            "P_sig": self.rho_P.cpu().numpy()[:sig_dim],
            "U_sig": self.rho_U.cpu().numpy()[:sig_dim],
            "Lambda_U_sig": self.Lambda_U_signature[: min(sig_dim, len(self.Lambda_U_signature))],
        }
