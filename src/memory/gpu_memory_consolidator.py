"""
GPU Memory Consolidator - Consolida√ß√£o Freudiana de Mem√≥ria GPU

Quando a GPU est√° cheia, ao inv√©s de simplesmente deletar mem√≥rias,
o sistema consolida segundo a ESTRUTURA T√ìPICA FREUDIANA:

1. CONSCIENTE: Mem√≥rias ativas na GPU (acess√≠veis diretamente)
2. PR√â-CONSCIENTE: Mem√≥rias n√£o traum√°ticas (comprimidas, mas acess√≠veis ao Ego)
3. INCONSCIENTE: Mem√≥rias traum√°ticas (criptografadas, inacess√≠veis ao Ego)

Processo:
1. Detecta VRAM cr√≠tica (> 85%)
2. Classifica mem√≥rias (traum√°ticas vs n√£o traum√°ticas)
3. PR√â-CONSCIENTE: Comprime usando SoftHair (acess√≠vel ao Ego)
4. INCONSCIENTE: Reprime usando EncryptedUnconsciousLayer (inacess√≠vel ao Ego)
5. Mant√©m rastro/hash para ativa√ß√£o retroativa futura
6. Limpa GPU apenas ap√≥s consolida√ß√£o bem-sucedida

Analogia Humana:
- Sono: Consolida√ß√£o de mem√≥rias do dia
- Pr√©-Consciente: Mem√≥rias que podem ser lembradas facilmente
- Repress√£o: Mem√≥rias traum√°ticas v√£o para inconsciente (inacess√≠veis)
- D√©j√† vu: Sensa√ß√£o de familiaridade sem acesso direto (influ√™ncia inconsciente)
- Ativa√ß√£o: Mem√≥rias pr√©-conscientes podem ser reativadas pelo Ego
"""

import hashlib
import logging
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional

import numpy as np
import torch

from ..monitor.resource_manager import HybridResourceManager
from .freudian_topographical_memory import (
    FreudianTopographicalMemory,
)

logger = logging.getLogger(__name__)


@dataclass
class ConsolidatedMemory:
    """Mem√≥ria consolidada no inconsciente."""

    content_hash: str  # Hash para ativa√ß√£o retroativa
    encrypted_data: bytes  # Dados criptografados
    compression_ratio: float  # Taxa de compress√£o
    metadata: Dict[str, Any]  # Metadados (tipo, timestamp, etc.)
    activation_trace: List[str]  # Rastro de ativa√ß√£o (quais processos podem reativar)
    consolidated_at: datetime  # Quando foi consolidada


class GPUMemoryConsolidator:
    """
    Sistema de Consolida√ß√£o de Mem√≥ria GPU.

    Ao inv√©s de deletar mem√≥rias quando GPU est√° cheia,
    consolida (comprime) e reprime para inconsciente criptografado.
    """

    def __init__(
        self,
        vram_threshold: float = 85.0,
        compression_target: float = 0.3,  # Comprimir para 30% do tamanho original
    ):
        """
        Inicializa consolidador de mem√≥ria GPU.

        Args:
            vram_threshold: Percentual de VRAM que dispara consolida√ß√£o
            compression_target: Taxa de compress√£o desejada (0.3 = 30% do original)
        """
        self.vram_threshold = vram_threshold
        self.compression_target = compression_target

        # Componentes de consolida√ß√£o (estrutura t√≥pica freudiana)
        self.topographical_memory = FreudianTopographicalMemory()
        self.resource_manager = HybridResourceManager()

        # Registro de mem√≥rias consolidadas
        self.consolidated_memories: Dict[str, ConsolidatedMemory] = {}

        # Rastros de ativa√ß√£o (quais processos podem reativar quais mem√≥rias)
        self.activation_traces: Dict[str, List[str]] = {}

        logger.info(
            f"GPUMemoryConsolidator inicializado (Estrutura T√≥pica Freudiana): "
            f"threshold={vram_threshold}%, compression={compression_target*100:.0f}%"
        )

    def should_consolidate(self) -> bool:
        """
        Verifica se deve consolidar mem√≥ria GPU.

        Returns:
            True se VRAM > threshold
        """
        if not torch.cuda.is_available():
            return False

        stats = self.resource_manager.get_system_status()
        vram_percent = stats.get("vram", 0.0)

        return vram_percent > self.vram_threshold

    def consolidate_gpu_memory(
        self,
        memory_items: List[Dict[str, Any]],
        process_context: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Consolida mem√≥rias da GPU para inconsciente criptografado.

        Processo:
        1. Comprime cada mem√≥ria usando SoftHair
        2. Reprime para EncryptedUnconsciousLayer
        3. Mant√©m rastro de ativa√ß√£o
        4. Limpa GPU ap√≥s consolida√ß√£o

        Args:
            memory_items: Lista de itens de mem√≥ria a consolidar
                Cada item deve ter: {'data': tensor/array, 'type': str, 'metadata': dict}
            process_context: Contexto do processo que est√° consolidando

        Returns:
            Estat√≠sticas da consolida√ß√£o
        """
        if not memory_items:
            return {
                "status": "skipped",
                "reason": "no_memories",
                "consolidated": 0,
            }

        logger.info(
            f"üß† Consolidando {len(memory_items)} mem√≥rias da GPU "
            f"segundo estrutura t√≥pica freudiana (Pr√©-Consciente/Inconsciente)..."
        )

        consolidated_count = 0
        total_original_size: float = 0.0
        total_compressed_size: float = 0.0

        for item in memory_items:
            try:
                # 1. Extrair dados
                data = item.get("data")
                memory_type = item.get("type", "unknown")
                metadata = item.get("metadata", {})

                if data is None:
                    continue

                # 2. Converter para numpy array se necess√°rio
                if isinstance(data, torch.Tensor):
                    # Mover para CPU antes de consolidar
                    if data.is_cuda:
                        data = data.cpu()
                    data_array = data.detach().numpy()
                elif isinstance(data, np.ndarray):
                    data_array = data
                else:
                    # Tentar converter
                    data_array = np.array(data)

                # Calcular tamanho original
                original_size = data_array.nbytes / 1024 / 1024  # MB
                total_original_size += original_size

                # 3. CLASSIFICAR segundo estrutura t√≥pica freudiana
                classification = self.topographical_memory.classify_memory(
                    data_array,
                    context={
                        **metadata,
                        "type": memory_type,
                        "error_type": metadata.get("error_type", ""),
                        "severity": metadata.get("severity", "low"),
                        "impact": metadata.get("impact", "low"),
                    },
                )

                # 4. CONSOLIDAR baseado na classifica√ß√£o
                memory_key = (
                    f"{memory_type}_{hashlib.sha256(data_array.tobytes()).hexdigest()[:16]}"
                )

                if classification.is_traumatic:
                    # TRAUM√ÅTICO ‚Üí INCONSCIENTE (criptografado, inacess√≠vel ao Ego)
                    result = self.topographical_memory.repress_to_unconscious(
                        data_array,
                        memory_key,
                        {
                            **metadata,
                            "type": memory_type,
                            "original_size_mb": original_size,
                            "trauma_score": classification.trauma_score,
                        },
                    )
                    layer = "unconscious"
                    compression_ratio = 0.3  # Estimativa para criptografia
                else:
                    # N√ÉO TRAUM√ÅTICO ‚Üí PR√â-CONSCIENTE (comprimido, acess√≠vel ao Ego)
                    result = self.topographical_memory.consolidate_to_preconscious(
                        data_array,
                        memory_key,
                        {
                            **metadata,
                            "type": memory_type,
                            "original_size_mb": original_size,
                        },
                    )
                    layer = "preconscious"
                    compression_ratio = result.get("compression_ratio", 0.3)

                # 5. Criar registro de consolida√ß√£o
                content_hash = self.topographical_memory._hash_memory(data_array)
                consolidated_memory = ConsolidatedMemory(
                    content_hash=content_hash,
                    encrypted_data=result.get("encrypted_data", b""),
                    compression_ratio=compression_ratio,
                    metadata={
                        **metadata,
                        "type": memory_type,
                        "original_size_mb": original_size,
                        "layer": layer,
                        "is_traumatic": classification.is_traumatic,
                        "trauma_score": classification.trauma_score,
                        "accessible_to_ego": not classification.is_traumatic,
                    },
                    activation_trace=[process_context] if process_context else [],
                    consolidated_at=datetime.now(),
                )

                self.consolidated_memories[content_hash] = consolidated_memory

                # 6. Registrar rastro de ativa√ß√£o
                if process_context:
                    if content_hash not in self.activation_traces:
                        self.activation_traces[content_hash] = []
                    self.activation_traces[content_hash].append(process_context)

                compressed_size = original_size * compression_ratio
                total_compressed_size += compressed_size
                consolidated_count += 1

                logger.info(
                    f"‚úÖ Mem√≥ria consolidada para {layer.upper()}: {memory_type} "
                    f"({original_size:.2f}MB ‚Üí {compressed_size:.2f}MB, "
                    f"traum√°tico={classification.is_traumatic})"
                )

            except Exception as e:
                logger.error(f"Erro ao consolidar mem√≥ria: {e}", exc_info=True)
                continue

        # 7. Limpar GPU ap√≥s consolida√ß√£o bem-sucedida
        if consolidated_count > 0:
            self._cleanup_gpu_after_consolidation()

        stats = {
            "status": "success",
            "consolidated": consolidated_count,
            "total_original_mb": total_original_size,
            "total_compressed_mb": total_compressed_size,
            "compression_ratio": (
                total_compressed_size / total_original_size if total_original_size > 0 else 0.0
            ),
            "freed_mb": total_original_size - total_compressed_size,
        }

        logger.info(
            f"üß† Consolida√ß√£o conclu√≠da: {consolidated_count} mem√≥rias, "
            f"{stats['freed_mb']:.2f}MB liberados da GPU"
        )

        return stats

    def _cleanup_gpu_after_consolidation(self) -> None:
        """Limpa GPU ap√≥s consolida√ß√£o bem-sucedida."""
        import gc

        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            logger.debug("üßπ GPU limpa ap√≥s consolida√ß√£o")

    def check_activation_trace(
        self,
        process_context: str,
        query_vector: Optional[np.ndarray] = None,
    ) -> List[Dict[str, Any]]:
        """
        Verifica se h√° mem√≥rias consolidadas que podem ser reativadas.

        Analogia: D√©j√† vu - sensa√ß√£o de familiaridade sem acesso direto.

        Args:
            process_context: Contexto do processo atual
            query_vector: Vetor de consulta para busca por similaridade

        Returns:
            Lista de mem√≥rias que podem ser reativadas
        """
        activatable = []

        for content_hash, memory in self.consolidated_memories.items():
            # Verificar se processo atual est√° no rastro de ativa√ß√£o
            traces = self.activation_traces.get(content_hash, [])
            if process_context in traces:
                activatable.append(
                    {
                        "content_hash": content_hash,
                        "type": memory.metadata.get("type", "unknown"),
                        "consolidated_at": memory.consolidated_at.isoformat(),
                        "compression_ratio": memory.compression_ratio,
                        "activation_trace": traces,
                        "status": "activatable",
                    }
                )

        # Se h√° query_vector, verificar influ√™ncia inconsciente
        if query_vector is not None and activatable:
            encrypted_memories = [
                mem.encrypted_data
                for mem in self.consolidated_memories.values()
                if mem.content_hash in [a["content_hash"] for a in activatable]
            ]

            if encrypted_memories:
                influence = self.topographical_memory.unconscious_layer.unconscious_influence(
                    encrypted_memories,
                    query_vector,
                )

                # Adicionar score de influ√™ncia
                for item in activatable:
                    item["unconscious_influence"] = influence

        return activatable

    def reactivate_memory(
        self,
        content_hash: str,
        process_context: str,
    ) -> Optional[np.ndarray]:
        """
        Reativa mem√≥ria consolidada.

        Processo:
        1. Verifica se mem√≥ria existe e est√° no rastro de ativa√ß√£o
        2. Descomprime usando SoftHair
        3. Retorna dados originais (aproximados)

        Args:
            content_hash: Hash da mem√≥ria consolidada
            process_context: Contexto do processo que est√° reativando

        Returns:
            Dados reativados (numpy array) ou None se n√£o encontrado
        """
        if content_hash not in self.consolidated_memories:
            logger.warning(f"Mem√≥ria {content_hash} n√£o encontrada para reativa√ß√£o")
            return None

        memory = self.consolidated_memories[content_hash]

        # Verificar se processo est√° autorizado a reativar
        traces = self.activation_traces.get(content_hash, [])
        if process_context not in traces:
            logger.warning(
                f"Processo {process_context} n√£o est√° no rastro de ativa√ß√£o "
                f"da mem√≥ria {content_hash}"
            )
            # Mas permite reativa√ß√£o (pode ser novo processo relacionado)

        # Verificar camada da mem√≥ria
        layer = memory.metadata.get("layer", "unknown")
        is_traumatic = memory.metadata.get("is_traumatic", False)

        if layer == "preconscious" and not is_traumatic:
            # PR√â-CONSCIENTE: Ego pode acessar diretamente
            content_hash_internal = content_hash
            reactivated_data = self.topographical_memory.retrieve_from_preconscious(
                content_hash_internal
            )
            if reactivated_data is not None:
                logger.info(
                    f"‚úÖ Mem√≥ria PR√â-CONSCIENTE {content_hash} reativada "
                    f"(Ego tem acesso direto)"
                )
                return reactivated_data
        elif layer == "unconscious" and is_traumatic:
            # INCONSCIENTE: Ego N√ÉO pode acessar diretamente
            logger.warning(
                f"üîí Mem√≥ria INCONSCIENTE {content_hash} n√£o pode ser acessada pelo Ego "
                f"(reprimida, criptografada)"
            )
            # Mas pode verificar influ√™ncia inconsciente
            # (implementar se necess√°rio)
            return None

        logger.warning(f"N√£o foi poss√≠vel reativar mem√≥ria {content_hash} (layer={layer})")
        return None

    def get_consolidation_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas de consolida√ß√£o."""
        total_memories = len(self.consolidated_memories)
        total_original_size = sum(
            m.metadata.get("original_size_mb", 0) for m in self.consolidated_memories.values()
        )
        total_compressed_size = sum(
            m.metadata.get("original_size_mb", 0) * m.compression_ratio
            for m in self.consolidated_memories.values()
        )

        # Estat√≠sticas da estrutura t√≥pica
        topo_stats = self.topographical_memory.get_statistics()

        return {
            "total_consolidated": total_memories,
            "total_original_mb": total_original_size,
            "total_compressed_mb": total_compressed_size,
            "average_compression": (
                total_compressed_size / total_original_size if total_original_size > 0 else 0.0
            ),
            "freed_mb": total_original_size - total_compressed_size,
            "activation_traces": len(self.activation_traces),
            "topographical": {
                "preconscious_count": topo_stats["preconscious_count"],
                "unconscious_count": topo_stats["unconscious_count"],
                "traumatic_memories": topo_stats["traumatic_memories"],
                "non_traumatic_memories": topo_stats["non_traumatic_memories"],
            },
        }


# Inst√¢ncia global
_gpu_consolidator: Optional[GPUMemoryConsolidator] = None


def get_gpu_consolidator() -> GPUMemoryConsolidator:
    """Retorna inst√¢ncia global do consolidador."""
    global _gpu_consolidator
    if _gpu_consolidator is None:
        _gpu_consolidator = GPUMemoryConsolidator()
    return _gpu_consolidator
