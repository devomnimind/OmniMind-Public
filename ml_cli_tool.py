#!/usr/bin/env python3
"""
ML CLI Tool - Interface de linha de comando para otimizaÃ§Ã£o hÃ­brida
Uso: python ml_cli_tool.py <comando> [opÃ§Ãµes]
"""

import argparse
import json
import sys
from pathlib import Path
from hybrid_ml_optimizer import HybridMLOptimizer

class MLCLI:
    def __init__(self):
        self.optimizer = HybridMLOptimizer()
        
    def cmd_limits(self, args):
        """Verifica limites atuais"""
        print("ğŸ“Š Verificando limites...")
        
        gh_limits = self.optimizer.check_github_limits()
        hf_limits = self.optimizer.check_hf_limits()
        
        print("GitHub Models:")
        print(f"  ğŸ“ˆ Requests restantes: {gh_limits.get('remaining', 'N/A')}/5000")
        print(f"  â° Reset em: {gh_limits.get('reset', 'N/A')}")
        
        print("\\nHugging Face:")
        print(f"  ğŸ“¥ Downloads restantes: ~{hf_limits.get('downloads_remaining', 'N/A')}")
        print(f"  ğŸ“¤ Uploads restantes: ~{hf_limits.get('uploads_remaining', 'N/A')} MB")
    
    def cmd_optimize(self, args):
        """Otimiza escolha de modelo para tarefa"""
        if not args.task:
            print("âŒ Especifique uma tarefa: --task <tarefa>")
            return
        
        choice = self.optimizer.optimize_model_choice(args.task)
        
        print(f"ğŸ¯ Tarefa: {args.task}")
        print(f"ğŸ¤– Modelo escolhido: {choice['chosen_model']}")
        print(f"ğŸ¢ Provedor: {choice['provider']}")
        print(f"ğŸ’¡ RazÃ£o: {choice['reason']}")
    
    def cmd_call(self, args):
        """Chama modelo otimizado"""
        if not args.task or not args.prompt:
            print("âŒ Especifique --task e --prompt")
            return
        
        print(f"ğŸš€ Chamando modelo para tarefa: {args.task}")
        print(f"ğŸ’¬ Prompt: {args.prompt[:50]}...")
        
        result = self.optimizer.call_optimized_model(
            args.task, 
            args.prompt,
            max_tokens=args.max_tokens,
            temperature=args.temperature
        )
        
        if result["success"]:
            print("âœ… Sucesso!")
            print(f"ğŸ“ Resposta: {result['response']}")
            print(f"ğŸ’° Custo estimado: ${result['cost_estimate']:.4f}")
        else:
            print(f"âŒ Erro: {result.get('error', 'Desconhecido')}")
    
    def cmd_report(self, args):
        """Gera relatÃ³rio de uso"""
        report = self.optimizer.get_usage_report()
        
        print("ğŸ“Š RELATÃ“RIO DE USO - ML HÃBRIDO")
        print("=" * 40)
        
        print("\\nGitHub Models:")
        print(f"  ğŸ“ˆ Requests restantes: {report['github_usage']['requests_remaining']}")
        print(f"  ğŸ’° Custo acumulado: ${report['github_usage']['estimated_cost']:.3f}")
        
        print("\\nHugging Face:")
        print(f"  ğŸ“¥ Downloads restantes: {report['hf_usage']['downloads_remaining']}")
        print(f"  ğŸ“¤ Uploads restantes: {report['hf_usage']['uploads_remaining']} MB")
        
        print("\\nğŸ’¡ SugestÃµes de otimizaÃ§Ã£o:")
        for suggestion in report['optimization_suggestions']:
            print(f"  â€¢ {suggestion}")
    
    def cmd_train(self, args):
        """Inicia treinamento hÃ­brido (simulado)"""
        print("ğŸ“ Iniciando treinamento hÃ­brido...")
        print("ğŸ“‹ Carregando dados de treinamento...")
        
        # Carrega plano de treinamento
        plan_path = Path("training_data_collection/comprehensive_training_plan.json")
        if plan_path.exists():
            with open(plan_path) as f:
                plan = json.load(f)
            
            print(f"ğŸ“š Plano carregado: {plan.get('strategy', 'N/A')}")
            print(f"ğŸ¯ Fases: {len(plan.get('phased_approach', []))}")
            
            # Simula treinamento
            for phase in plan.get('phased_approach', [])[:3]:  # primeiras 3 fases
                print(f"\\nğŸƒ Fase: {phase.get('phase', 'N/A')}")
                print(f"   ğŸ“ Objetivo: {phase.get('objective', 'N/A')[:50]}...")
                print("   âœ… ConcluÃ­da (simulado)")
        else:
            print("âŒ Arquivo de plano nÃ£o encontrado")

def main():
    parser = argparse.ArgumentParser(
        description="ML CLI Tool - OtimizaÃ§Ã£o hÃ­brida GitHub + HF",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python ml_cli_tool.py limits
  python ml_cli_tool.py optimize --task code_generation
  python ml_cli_tool.py call --task text_classification --prompt "Classifique este texto: ..."
  python ml_cli_tool.py report
  python ml_cli_tool.py train
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Comandos disponÃ­veis')
    
    # Comando limits
    subparsers.add_parser('limits', help='Verifica limites atuais')
    
    # Comando optimize
    optimize_parser = subparsers.add_parser('optimize', help='Otimiza escolha de modelo')
    optimize_parser.add_argument('--task', required=True, 
                                choices=['text_classification', 'text_generation', 
                                       'code_generation', 'sentiment_analysis'],
                                help='Tipo de tarefa')
    
    # Comando call
    call_parser = subparsers.add_parser('call', help='Chama modelo otimizado')
    call_parser.add_argument('--task', required=True,
                            choices=['text_classification', 'text_generation',
                                   'code_generation', 'sentiment_analysis'],
                            help='Tipo de tarefa')
    call_parser.add_argument('--prompt', required=True, help='Prompt para o modelo')
    call_parser.add_argument('--max-tokens', type=int, default=100, 
                            help='MÃ¡ximo de tokens (padrÃ£o: 100)')
    call_parser.add_argument('--temperature', type=float, default=0.7,
                            help='Temperatura (padrÃ£o: 0.7)')
    
    # Comando report
    subparsers.add_parser('report', help='Gera relatÃ³rio de uso')
    
    # Comando train
    subparsers.add_parser('train', help='Inicia treinamento hÃ­brido')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    cli = MLCLI()
    
    # Executa comando
    if args.command == 'limits':
        cli.cmd_limits(args)
    elif args.command == 'optimize':
        cli.cmd_optimize(args)
    elif args.command == 'call':
        cli.cmd_call(args)
    elif args.command == 'report':
        cli.cmd_report(args)
    elif args.command == 'train':
        cli.cmd_train(args)

if __name__ == "__main__":
    main()
