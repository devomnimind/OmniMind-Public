"""
Pytest plugin para monitorar e auto-recuperar servidor durante testes.

Se servidor cair durante execu√ß√£o:
1. Detecta queda
2. Registra qual teste derrubou
3. Reinicia servidor automaticamente
4. Testes E2E subsequentes usam servidor novo

OTIMIZA√á√ïES ROBUSTAS PARA PROD+DEV H√çBRIDO:
- Timeouts progressivos (n√£o hardcoded)
- Debug logging para troubleshooting
- Health checks inteligentes
- M√©tricas de startup
- Recupera√ß√£o graceful
- Respeita ServerStateManager para evitar conflitos com fixture omnimind_server

RESPEITO AO ESTADO DO SERVIDOR:
- Se fixture omnimind_server controla servidor ‚Üí plugin N√ÉO reinicia
- Plugin s√≥ reinicia se √© propriet√°rio ou se ningu√©m controla
- Evita race conditions e m√∫ltiplas reinicializa√ß√µes
"""

import logging
import os
import subprocess
import sys
import time

import pytest
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from tests.server_state_manager import get_server_state_manager

# Setup logging para debug
logger = logging.getLogger("omnimind.server_monitor")
logger.setLevel(logging.DEBUG)

# Criar session com RETRY STRATEGY PERSONALIZADO
# Desabilita retries autom√°ticos (causava "Max retries exceeded")
session = requests.Session()
retry_strategy = Retry(
    total=0,  # ‚ùå N√ÉO fazer retry autom√°tico - deixa pytest_server_monitor gerenciar
    backoff_factor=0,
    status_forcelist=[],  # N√£o retry em nenhum status
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session.mount("http://", adapter)
session.mount("https://", adapter)

# Alert system (optional - pode n√£o estar dispon√≠vel em todos os ambientes)
_alert_system = None


async def _get_alert_system():
    """Obter sistema de alertas se dispon√≠vel."""
    global _alert_system
    if _alert_system is None:
        try:
            # Lazy import para evitar circular dependency
            sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "src"))
            from src.monitor import get_alert_system

            _alert_system = await get_alert_system()
        except Exception as e:
            logger.debug(f"Sistema de alertas n√£o dispon√≠vel: {e}")
    return _alert_system


class ServerMonitorPlugin:
    """
    Monitora sa√∫de do servidor durante testes PERIGOSOS (chaos, stress, ddos).

    IMPORTANTE:
    - Monitor N√ÉO inicia servidor - isso √© responsabilidade do script do sistema
    - Monitor s√≥ ativo em testes marcados como chaos/stress/ddos
    - Monitor apenas verifica e reinicia se servidor cair durante testes perigosos
    - Desabilitado por padr√£o - s√≥ ativa em testes espec√≠ficos
    """

    def __init__(self):
        self.backend_url = "http://localhost:8000"
        self.server_process = None
        self.server_was_down = False
        self.crashed_tests = []
        self.has_e2e_tests = False
        self.startup_metrics = {}  # Rastreia tempo de startup
        self.skip_server_tests = (
            os.environ.get("OMNIMIND_SKIP_SERVER_TESTS", "false").lower() == "true"
        )
        # IMPORTANTE: Monitor desabilitado por padr√£o
        # S√≥ ativa em testes perigosos (chaos, stress, ddos)
        self.enabled = False

        # ========== TIMEOUTS ADAPTATIVOS POR TESTE ==========
        # ALINHADO COM CONFIGURA√á√ÉO GLOBAL (pytest.ini + conftest.py):
        # - Timeout global: 800s m√°ximo por teste individual
        # - Timeout progressivo: come√ßa em 240s, vai at√© 800s
        # - Modo gradual: n√£o falha, continua at√© m√°ximo
        # - N√ÉO √© timeout global acumulativo - cada teste tem seu pr√≥prio or√ßamento
        self.startup_attempt_count = 0

        # Timeouts por tentativa (aumenta progressivamente)
        # ‚è±Ô∏è CADA CONEX√ÉO/TESTE INDIVIDUAL tem estes timeouts:
        # Tentativa 1: 240s  (startup + Orchestrator + SecurityAgent - alinhado com config global)
        # Tentativa 2: 400s  (permite +recovery time para 2+ ciclos)
        # Tentativa 3: 600s  (permite 3+ ciclos completos)
        # Tentativa 4+: 800s (m√°ximo - continua indefinidamente)
        # IMPORTANTE: Respeita configura√ß√£o global de 240s inicial e 800s m√°ximo
        self.timeout_progression = [240, 400, 600, 800, 800]
        self.max_global_timeout = 800  # M√°ximo individual por teste (n√£o global)

    def pytest_configure(self, config):
        """Inicializa monitoring na configura√ß√£o - LAZY INIT."""
        # N√ÉO inicia servidor aqui - deixa para pytest_collection_finish

    def pytest_collection_finish(self, session):
        """
        Ap√≥s coletar testes: verifica se h√° testes perigosos e ativa monitor se necess√°rio.

        IMPORTANTE: Monitor N√ÉO inicia servidor - isso √© responsabilidade do script do sistema.
        Monitor apenas verifica e reinicia se servidor cair durante testes perigosos.
        """
        # ‚ö° OTIMIZA√á√ÉO: Skip durante --collect-only
        if session.config.option.collectonly:
            logger.info("üèÉ Collect-only mode: Pulando verifica√ß√£o de monitor")
            return

        # Verificar se h√° testes perigosos (chaos, stress, ddos)
        dangerous_markers = ["chaos", "stress", "ddos", "load"]
        has_dangerous_tests = False

        for item in session.items:
            # Verificar se teste tem marcador perigoso
            for marker in item.iter_markers():
                if marker.name in dangerous_markers:
                    has_dangerous_tests = True
                    self.enabled = True
                    logger.info(f"‚ö†Ô∏è  Teste perigoso detectado: {item.name} - Monitor ativado")
                    break
            if has_dangerous_tests:
                break

        if has_dangerous_tests:
            logger.info("‚ö†Ô∏è  Monitor ativado para testes perigosos")
            print("‚ö†Ô∏è  Monitor de servidor ativado para testes perigosos (chaos/stress/ddos)")
        else:
            logger.info("‚úÖ Nenhum teste perigoso detectado - Monitor desabilitado")

    def pytest_runtest_setup(self, item):
        """
        Antes de cada teste: verifica se servidor est√° UP (apenas para testes perigosos).

        IMPORTANTE:
        - Monitor s√≥ ativo em testes perigosos (chaos, stress, ddos)
        - Monitor N√ÉO inicia servidor - isso √© responsabilidade do script do sistema
        - Monitor apenas verifica e reinicia se servidor cair durante testes perigosos
        """
        # Monitor desabilitado por padr√£o - s√≥ ativa em testes perigosos
        if not self.enabled:
            return

        # Verificar se teste √© perigoso
        dangerous_markers = ["chaos", "stress", "ddos", "load"]
        is_dangerous = any(item.get_closest_marker(marker) for marker in dangerous_markers)

        if not is_dangerous:
            return  # Monitor n√£o ativo para testes normais

        # Apenas para testes perigosos que precisam de servidor
        if self._needs_server(item):
            if self.skip_server_tests:
                pytest.skip("Servidor skipped via OMNIMIND_SKIP_SERVER_TESTS=true")
                return

            state_manager = get_server_state_manager()

            # Se fixture controla ‚Üí confia na fixture
            if state_manager.owner == "fixture":
                logger.info(f"‚úÖ Fixture controla servidor para {item.name}")
                state_manager.mark_running()
                return

            # Verificar se h√° health check recente em cache (45s)
            # Evita m√∫ltiplos checks durante suite com muitos testes
            if state_manager.has_recent_health_check():
                cached_result = state_manager.get_cached_health_check()
                if cached_result is True:
                    logger.debug("‚úÖ Health check em cache (recente) - servidor UP")
                    return
                # Se cache diz DOWN, tenta reiniciar

            # Sem cache recente: fazer health check
            if not self._is_server_healthy():
                print(f"\n‚ö†Ô∏è  Servidor DOWN antes de {item.name}")
                print(
                    "   üí° Monitor n√£o inicia servidor - inicie manualmente: "
                    "./scripts/start_omnimind_system_sudo.sh"
                )
                logger.warning(
                    f"Servidor n√£o est√° respondendo antes de teste perigoso: {item.name}"
                )
                pytest.skip(
                    "Servidor n√£o est√° respondendo - inicie manualmente com "
                    "./scripts/start_omnimind_system_sudo.sh"
                )

    def pytest_runtest_makereport(self, item, call):
        """
        Detecta se teste perigoso derrubou servidor.

        IMPORTANTE:
        - Monitor s√≥ ativo em testes perigosos (chaos, stress, ddos)
        - Monitor N√ÉO inicia servidor - isso √© responsabilidade do script do sistema
        - Monitor apenas verifica e reinicia se servidor cair durante testes perigosos
        """
        # Monitor desabilitado por padr√£o - s√≥ ativa em testes perigosos
        if not self.enabled:
            return

        # Verificar se teste √© perigoso
        dangerous_markers = ["chaos", "stress", "ddos", "load"]
        is_dangerous = any(item.get_closest_marker(marker) for marker in dangerous_markers)

        if not is_dangerous:
            return  # Monitor n√£o ativo para testes normais

        if call.when == "call" and self._needs_server(item):
            state_manager = get_server_state_manager()

            # Se fixture controla ‚Üí n√£o interferir
            if state_manager.owner == "fixture":
                logger.info("‚ÑπÔ∏è  Fixture controla servidor, plugin n√£o interfere")
                return

            # OTIMIZA√á√ÉO: Se h√° health check recente em cache, confiar nele
            if state_manager.has_recent_health_check():
                cached_result = state_manager.get_cached_health_check()
                if cached_result is True:
                    logger.debug("‚úÖ Cache recente diz servidor UP - n√£o refazer health check")
                    return

            # Sem cache recente: fazer health check
            # Verifica se servidor caiu ap√≥s o teste perigoso
            if not self._is_server_healthy():
                self.crashed_tests.append(item.name)
                self.server_was_down = True
                print(f"\n‚ö†Ô∏è  Servidor DOWN ap√≥s teste perigoso: {item.name}")
                print(
                    "   üí° Monitor n√£o reinicia servidor - reinicie manualmente: "
                    "./scripts/start_omnimind_system_sudo.sh"
                )
                logger.warning(f"Servidor ca√≠do ap√≥s teste perigoso: {item.name}")

                # Emitir alerta para VS Code
                try:
                    import asyncio

                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    async def _emit_alert():
                        alerts = await _get_alert_system()
                        if alerts:
                            await alerts.emit_server_down(
                                reason=f"Derrubado pelo teste perigoso: {item.name}",
                                context={
                                    "test_name": item.name,
                                    "timestamp": time.time(),
                                    "module": (
                                        item.module.__name__
                                        if hasattr(item, "module")
                                        else "unknown"
                                    ),
                                },
                            )

                    loop.run_until_complete(_emit_alert())
                except Exception as e:
                    logger.debug(f"Erro ao emitir alerta de servidor down: {e}")

    def pytest_runtest_teardown(self, item):
        """
        Ap√≥s cada teste: garante servidor UP para pr√≥ximo.

        Apenas interfere se plugin controla servidor (n√£o fixture).
        """
        state_manager = get_server_state_manager()

        # Se fixture controla ‚Üí n√£o interferir no teardown
        if state_manager.owner == "fixture":
            return

        if self._needs_server(item) and self.server_was_down:
            # Aumentar muito o tempo limite para permitir suite completa rodar
            # Sem timeout artificial - deixa tempo cont√≠nuo para recupera√ß√£o real
            self._wait_for_server_with_retry(max_attempts=None, max_wait_seconds=600)
            # Reset flag ap√≥s recupera√ß√£o bem-sucedida
            self.server_was_down = False

    def _is_server_healthy(self) -> bool:
        """
        Verifica se servidor est√° respondendo (SEM retries autom√°ticos).

        Timeout tolerante: 5s (n√£o 1s) porque durante testes lentos,
        servidor pode estar processando e n√£o responder em 1s.

        IMPORTANTE: Timeout ‚â† DOWN. Apenas ConnectionError confirma DOWN.
        """
        try:
            # Usa session com retry=0 (sem retries autom√°ticos)
            # Adicionado trailing slash para evitar 307 Redirect
            # Timeout TOLERANTE: 5s (permite testes lentos em background)
            resp = session.get(f"{self.backend_url}/health/", timeout=5)
            if resp.status_code in (200, 404):
                logger.debug(f"‚úÖ Health check OK: {resp.status_code}")
                return True
        except requests.exceptions.Timeout:
            # Timeout N√ÉO significa DOWN - servidor pode estar lento
            logger.debug("‚è±Ô∏è  Health check timeout (5s) - servidor pode estar ocupado, n√£o √© DOWN")
            return True  # ‚Üê Crucial: assume servidor est√° UP se apenas timeout
        except requests.exceptions.ConnectionError:
            logger.debug("üîå Health check connection refused (servidor genuinamente DOWN)")
        except Exception as e:
            logger.debug(f"‚ùå Health check erro: {type(e).__name__}: {e}")

        # Fallback: tenta endpoint raiz
        try:
            resp = session.get(f"{self.backend_url}/", timeout=5, allow_redirects=False)
            if resp.status_code in (200, 301, 302, 307, 308):
                logger.debug(f"‚úÖ Fallback OK: {resp.status_code}")
                return True
        except requests.exceptions.Timeout:
            # Timeout no fallback tamb√©m = n√£o √© DOWN
            logger.debug("‚è±Ô∏è  Fallback timeout (5s) - servidor pode estar ocupado, n√£o √© DOWN")
            return True  # ‚Üê Crucial: assume servidor est√° UP
        except requests.exceptions.ConnectionError:
            logger.debug("üîå Fallback connection refused - CONFIRMA servidor DOWN")
        except Exception as e:
            logger.debug(f"‚ùå Fallback erro: {type(e).__name__}: {e}")

        return False

    def _ensure_server_up(self):
        """
        Verifica se servidor est√° UP (N√ÉO inicia servidor).

        IMPORTANTE:
        - Monitor N√ÉO inicia servidor - isso √© responsabilidade do script do sistema
        - Monitor apenas verifica se servidor est√° respondendo
        - Se servidor n√£o est√° respondendo, apenas avisa (n√£o tenta iniciar)
        """
        state_manager = get_server_state_manager()

        # Verificar se outro componente controla servidor
        if state_manager.owner == "fixture":
            print(
                "‚ÑπÔ∏è  Servidor est√° sob gerenciamento da fixture E2E "
                "(omnimind_server) - plugin n√£o interfere"
            )
            return

        # Se j√° est√° saud√°vel, apenas avisa
        if self._is_server_healthy():
            print("‚úÖ Servidor backend j√° est√° rodando em http://localhost:8000")
            state_manager.mark_running()
            return

        # Servidor n√£o est√° respondendo - apenas avisa (n√£o tenta iniciar)
        print("‚ö†Ô∏è  Servidor backend n√£o est√° respondendo")
        print("   üí° Inicie o servidor manualmente: ./scripts/start_omnimind_system_sudo.sh")
        logger.warning(
            "Servidor n√£o est√° respondendo - monitor n√£o inicia servidor automaticamente"
        )

    def _needs_server(self, item) -> bool:
        """Verifica se teste precisa de servidor."""
        # Testes E2E s√£o gerenciados por fixture omnimind_server em tests/e2e/conftest.py
        # ou precisam de servidor explicitamente
        item_path = str(item.fspath).lower()
        test_name = str(item.nodeid).lower()

        # Se est√° em tests/e2e/, deixa fixture do conftest.py gerenciar
        if "tests/e2e/" in item_path or "tests\\e2e\\" in item_path:
            return False

        # EXCE√á√ÉO EXPL√çCITA: Lista de arquivos que cont√™m palavras-chave de integra√ß√£o
        # mas s√£o unit√°rios/mockados e N√ÉO devem disparar o servidor real.
        excluded_files = [
            "tests/consciousness/test_integration_loss.py",
            "tests/autopoietic/test_architecture_evolution.py",
            "tests/autopoietic/test_meaning_maker.py",
            "tests/manual/test_ui_integration.py",
            "tests/test_agents_core_integration.py",
            "tests/test_enhanced_agents_integration.py",
            "tests/test_dashboard_ws_auth.py",
            "tests/metrics/test_dashboard_metrics.py",
            "tests/test_enhanced_integrations.py",
            "tests/autopoietic/test_integration_flow_v2.py",
            "tests/test_security_agent_integration.py",
            "tests/swarm/test_swarm_integration.py",
            "tests/consciousness/test_integration_loop.py",
            "tests/test_lacanian_integration_complete.py",
            "tests/test_external_ai_integration.py",
            "tests/test_phase16_full_integration.py",
            "tests/test_phase16_integration.py",
            "tests/test_tools_integration.py",
            "tests/test_dashboard_e2e.py",
            "tests/test_phase3_integration.py",
            "tests/autopoietic/test_advanced_repair.py",
            # REFATORA√á√ÉO 2025-12-08: Testes de composi√ß√£o e sync s√£o unit√°rios
            "tests/agents/test_enhanced_code_agent_composition.py",
            "tests/consciousness/test_integration_loop_sync.py",
        ]

        # Normaliza o caminho do item para compara√ß√£o
        normalized_item_path = item_path.replace("\\", "/")

        for excluded in excluded_files:
            if excluded in normalized_item_path:
                return False

        # Testes que explicitamente marcam que precisam de servidor OmniMind (porta 8000)
        # NOTA: "integration" √© muito amplo - muitos testes unit√°rios t√™m "integration" no nome
        # mas usam mocks. Verificar se realmente usa localhost:8000 antes de iniciar servidor.
        e2e_markers = ["e2e", "endpoint", "dashboard"]

        # Verificar se cont√©m marcadores E2E (mais espec√≠ficos)
        has_e2e_marker = any(marker in item_path or marker in test_name for marker in e2e_markers)

        # Se n√£o tem marcador E2E espec√≠fico, verificar se realmente usa servidor OmniMind
        # (n√£o apenas servi√ßos externos como Ollama/Qdrant)
        if not has_e2e_marker:
            # Verificar se arquivo realmente usa servidor OmniMind (porta 8000)
            # Isso evita iniciar servidor para testes que s√≥ usam servi√ßos externos
            try:
                import os

                test_file_path = str(item.fspath)
                if os.path.exists(test_file_path):
                    with open(test_file_path, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                        # Verificar se realmente usa servidor OmniMind (porta 8000)
                        uses_omnimind_server = (
                            "localhost:8000" in content
                            or "http://localhost:8000" in content
                            or "backend.*8000" in content
                            or "port.*8000" in content
                        )
                        # Se n√£o usa servidor OmniMind, n√£o precisa iniciar
                        if not uses_omnimind_server:
                            return False
            except Exception:
                # Se n√£o conseguir ler arquivo, usar l√≥gica antiga
                pass

        return has_e2e_marker

    def _start_server(self):
        """
        REMOVIDO: Monitor n√£o inicia servidor.

        IMPORTANTE:
        - Monitor N√ÉO inicia servidor - isso √© responsabilidade do script do sistema
        - Para iniciar servidor, use: ./scripts/start_omnimind_system_sudo.sh
        - Monitor apenas verifica e reinicia se servidor cair durante testes perigosos
        """
        logger.warning("Monitor n√£o inicia servidor - use ./scripts/start_omnimind_system_sudo.sh")
        print("‚ö†Ô∏è  Monitor n√£o inicia servidor automaticamente")
        print("   üí° Para iniciar servidor: ./scripts/start_omnimind_system_sudo.sh")
        raise RuntimeError(
            "Monitor n√£o inicia servidor - inicie manualmente com "
            "./scripts/start_omnimind_system_sudo.sh"
        )
        start_time = time.time()
        self.startup_attempt_count += 1

        try:
            # Tenta com script wrapper que detecta necessidade de sudo
            script_path = os.path.join(
                os.path.dirname(__file__), "..", "..", "scripts", "start_omnimind_system_sudo.sh"
            )

            if not os.path.exists(script_path):
                raise FileNotFoundError(f"Script n√£o encontrado: {script_path}")

            print(f"   ‚Üí Executando {script_path}...")
            print("   ‚Üí Mostrando sa√≠da completa do script de inicializa√ß√£o...\n")

            # CORRE√á√ÉO: Mostrar sa√≠da em tempo real para debug
            # Executa SEM sudo direto - o script start_omnimind_system_sudo.sh
            # j√° gerencia a eleva√ß√£o via secure_run.py quando necess√°rio
            # IMPORTANTE: stdout/stderr n√£o capturados para mostrar
            # backend, frontend, cluster, credenciais
            process = subprocess.Popen(
                ["bash", script_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,  # Mesclar stderr em stdout
                text=True,
                bufsize=1,  # Line buffered
                universal_newlines=True,
                cwd=os.path.dirname(__file__) + "/../..",
            )

            # Mostrar sa√≠da em tempo real
            output_lines = []
            try:
                if process.stdout is None:
                    raise RuntimeError("process.stdout is None")
                for line in process.stdout:
                    line = line.rstrip()
                    print(f"   {line}")  # Mostrar cada linha
                    output_lines.append(line)
                    # Log tamb√©m para debug
                    logger.debug(f"Script output: {line}")
            except Exception as e:
                logger.warning(f"Erro ao ler sa√≠da do script: {e}")

            # Aguardar t√©rmino do processo
            returncode = process.wait(timeout=240)  # Timeout aumentado

            if returncode != 0:
                logger.warning(f"Script falhou com returncode {returncode}")
                print(f"   ‚ö†Ô∏è  Script retornou c√≥digo de erro: {returncode}")
                # Mostrar √∫ltimas linhas de sa√≠da para debug
                if output_lines:
                    print("   ‚ö†Ô∏è  √öltimas linhas de sa√≠da:")
                    for line in output_lines[-10:]:
                        print(f"      {line}")

                # IMPORTANTE: Verificar se servidor j√° est√° rodando antes de considerar erro
                # Script pode falhar por v√°rias raz√µes (permiss√µes, depend√™ncias), mas servidor
                # pode j√° estar rodando de uma execu√ß√£o anterior
                if self._is_server_healthy():
                    logger.info(
                        "‚úÖ Servidor j√° est√° rodando apesar do erro do script - "
                        "usando servidor existente"
                    )
                    print("   ‚úÖ Servidor j√° est√° rodando - ignorando erro do script")
                    state_manager = get_server_state_manager()
                    state_manager.mark_running()
                    return  # Servidor est√° UP, n√£o precisa continuar

                # Se servidor n√£o est√° rodando E script falhou, continua para tentar iniciar
                # Continua mesmo com erro - pode ser permiss√£o mas servidor pode estar subindo
            else:
                print("   ‚úÖ Script executado com sucesso")

            # ========== TIMEOUTS ADAPTATIVOS COM RESTART INTERMEDI√ÅRIO ==========
            total_timeout = self._get_adaptive_timeout()
            # Ciclo: aguarda servidor subir (120-150s + buffer para ambiente h√≠brido)
            # Aumentado para 240s para dar margem em ambientes h√≠bridos de desenvolvimento
            cycle_timeout = 240

            logger.info(
                f"Aguardando servidor (tentativa {self.startup_attempt_count}, "
                f"timeout total {total_timeout}s, ciclo {cycle_timeout}s)..."
            )
            print(
                f"\n   ‚è≥ Timeout adaptativo: {total_timeout}s (ciclo de restart: {cycle_timeout}s)"
            )

            # Loop de tentativas com restart intermedi√°rio
            wait_start_time = time.time()
            while True:
                try:
                    # Tenta esperar pelo servidor por 'cycle_timeout' segundos
                    self._wait_for_server_with_retry(
                        max_attempts=None, max_wait_seconds=cycle_timeout
                    )
                    # Se chegou aqui, servidor est√° UP
                    break
                except TimeoutError:
                    # Timeout do ciclo atingido
                    elapsed_total = time.time() - wait_start_time

                    # Se j√° passou do tempo total, lan√ßa erro real
                    if elapsed_total >= total_timeout:
                        raise TimeoutError(f"Timeout total ({total_timeout}s) atingido")

                    print(
                        f"   üîÑ Servidor n√£o subiu em {cycle_timeout}s. "
                        f"Reiniciando processo de startup..."
                    )

                    # IMPORTANTE: N√ÉO matar processos uvicorn existentes
                    # Se servidor j√° est√° rodando (iniciado manualmente ou por outro processo),
                    # n√£o devemos mat√°-lo. Apenas mata processos que o plugin iniciou.
                    # Verificar se plugin iniciou o processo antes de matar
                    if self.server_process is not None:
                        try:
                            # Apenas mata processo que plugin iniciou
                            if self.server_process.poll() is None:
                                # Processo ainda est√° rodando
                                self.server_process.terminate()
                                try:
                                    self.server_process.wait(timeout=5)
                                except subprocess.TimeoutExpired:
                                    self.server_process.kill()
                        except Exception as e:
                            logger.debug(f"Erro ao terminar processo do plugin: {e}")

                    # N√ÉO usar pkill - pode matar processos uvicorn que n√£o foram
                    # iniciados pelo plugin
                    # subprocess.run(["pkill", "-f", "uvicorn"], stderr=subprocess.DEVNULL)
                    # REMOVIDO
                    # subprocess.run(
                    #     ["pkill", "-f", "python web/backend/main.py"],
                    #     stderr=subprocess.DEVNULL
                    # )  # REMOVIDO

                    # Re-executa script de startup
                    print(f"   ‚Üí Re-executando {script_path}...")
                    subprocess.run(
                        ["bash", script_path],
                        capture_output=True,
                        text=True,
                        timeout=240,  # Timeout aumentado para ambiente h√≠brido
                        cwd=os.path.dirname(__file__) + "/../..",
                    )
                    # Continua loop (nova espera de cycle_timeout)

            elapsed = time.time() - start_time
            self.startup_metrics["total_startup_time"] = elapsed

            logger.info(
                f"‚úÖ Servidor iniciado em {elapsed:.1f}s (tentativa {self.startup_attempt_count})"
            )
            print(
                f"‚úÖ Servidor backend iniciado em {elapsed:.1f}s " f"(Backend + eBPF inicializados)"
            )

        except TimeoutError:
            elapsed = time.time() - start_time
            current_timeout = self._get_adaptive_timeout()

            logger.error(
                f"‚ùå Timeout na tentativa {self.startup_attempt_count} "
                f"ap√≥s {elapsed:.1f}s (timeout: {current_timeout:.0f}s)"
            )
            print(f"\n‚ùå Timeout na tentativa {self.startup_attempt_count} ap√≥s {elapsed:.1f}s")

            # Emitir alerta de timeout
            try:
                import asyncio

                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                async def _emit_timeout_alert():
                    alerts = await _get_alert_system()
                    if alerts:
                        await alerts.emit_test_timeout(
                            test_name="SERVER_STARTUP",
                            timeout_seconds=int(current_timeout),
                            context={
                                "attempt": self.startup_attempt_count,
                                "elapsed": elapsed,
                            },
                        )

                loop.run_until_complete(_emit_timeout_alert())
            except Exception as e:
                logger.debug(f"Erro ao emitir alerta de timeout: {e}")

            # Verifica se j√° atingiu timeout m√°ximo (800s)
            if current_timeout >= 800 and self.startup_attempt_count > 5:
                print(
                    f"\nüõë FALHA CR√çTICA: Atingiu timeout m√°ximo por teste (800s) "
                    f"ap√≥s {self.startup_attempt_count} tentativas"
                )
                print("   Poss√≠veis causas:")
                print("   - Orchestrator + SecurityAgent levando >800s")
                print("   - Qdrant n√£o est√° acess√≠vel ou muito lento")
                print("   - Recursos insuficientes (RAM/GPU/Disco)")
                print("   - M√∫ltiplas tentativas de restart n√£o recuperaram servidor")
                raise RuntimeError(
                    f"Servidor backend falhou ap√≥s {self.startup_attempt_count} tentativas, "
                    f"tempo m√°ximo (800s) por teste atingido"
                )

            # Tenta novamente com timeout maior
            print("   üîÑ Tentando novamente com timeout maior...\n")
            self._start_server()

        except Exception as e:
            elapsed = time.time() - start_time

            logger.error(
                f"‚ùå ERRO ao iniciar servidor na tentativa {self.startup_attempt_count} "
                f"ap√≥s {elapsed:.1f}s: {e}"
            )
            print(f"\n‚ùå ERRO ao iniciar servidor: {e}")
            print("‚ö†Ô∏è  ATEN√á√ÉO: Testes que precisam de servidor falhar√£o!")
            raise RuntimeError(f"Servidor backend n√£o conseguiu iniciar: {e}")

    def _get_adaptive_timeout(self) -> float:
        """
        Calcula timeout adaptativo baseado no n√∫mero de tentativas.

        ALINHADO COM CONFIGURA√á√ÉO GLOBAL (pytest.ini + conftest.py):
        - Respeita timeout progressivo: 240s inicial ‚Üí 800s m√°ximo
        - Modo gradual: n√£o falha, continua at√© m√°ximo
        - Cada teste individual tem seu pr√≥prio or√ßamento de tempo

        Estrat√©gia (timeout INDIVIDUAL por teste - PER CONNECTION):
        - Tentativa 1: 240s  (startup + Orchestrator + SecurityAgent - alinhado com config global)
        - Tentativa 2: 400s  (permite +recovery time para m√∫ltiplos ciclos)
        - Tentativa 3: 600s  (permite 3+ ciclos completos de recovery)
        - Tentativa 4+: 800s (m√°ximo - continua indefinidamente sem artificial timeout)

        Retorna o timeout em segundos.
        """
        idx = min(self.startup_attempt_count - 1, len(self.timeout_progression) - 1)
        timeout = self.timeout_progression[idx]

        logger.info(f"Timeout adaptativo (tentativa {self.startup_attempt_count}): {timeout}s")

        return timeout

    def _start_python_server(self):
        """
        Inicia servidor via python -m uvicorn.

        IMPORTANTE: Verifica se servidor j√° est√° rodando antes de tentar iniciar.
        N√£o mata processos uvicorn existentes - apenas verifica se servidor responde.
        """
        # Verificar se servidor j√° est√° rodando antes de tentar iniciar
        if self._is_server_healthy():
            logger.info("‚úÖ Servidor j√° est√° rodando e respondendo - n√£o precisa iniciar")
            print("‚úÖ Servidor j√° est√° rodando - usando servidor existente")
            state_manager = get_server_state_manager()
            state_manager.mark_running()
            return

        # Muda para diret√≥rio raiz do projeto
        project_root = os.path.join(os.path.dirname(__file__), "../..")
        os.chdir(project_root)

        # Define vari√°veis de ambiente necess√°rias
        env = os.environ.copy()
        env.update(
            {
                "QDRANT_URL": "http://localhost:6333",
                # Em testes: usa modo "test" para paralelizar inicializa√ß√£o
                "OMNIMIND_MODE": "test",
                # Logging detalhado para debug de startup
                "OMNIMIND_LOG_LEVEL": "INFO",
            }
        )

        # Inicia uvicorn
        self.server_process = subprocess.Popen(
            [
                sys.executable,
                "-m",
                "uvicorn",
                "web.backend.main:app",
                "--host",
                "0.0.0.0",
                "--port",
                "8000",
                "--workers",
                "1",
                "--log-level",
                "info",
            ],
            env=env,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        print("   ‚úÖ uvicorn iniciado em background (com Orchestrator completo)")

    def _wait_for_server_with_retry(self, max_attempts=None, max_wait_seconds=240):
        """
        Aguarda servidor ficar saud√°vel com retry agressivo.

        Args:
            max_attempts: N√∫mero m√°ximo de tentativas (None = usar max_wait_seconds)
            max_wait_seconds: Tempo m√°ximo em segundos (default 4 min para ambiente h√≠brido)
        """
        # ‚ö° OTIMIZA√á√ÉO: Verifica se j√° est√° UP antes de esperar
        if self._is_server_healthy():
            return

        start_time = time.time()
        attempt = 0

        # ‚è≥ Delay inicial m√≠nimo para estabiliza√ß√£o do processo
        # Removido sleep de 30s hardcoded - agora usa loop de verifica√ß√£o ativa
        time.sleep(2)

        while True:
            if self._is_server_healthy():
                elapsed = time.time() - start_time
                print(f"   ‚úÖ Servidor respondendo na tentativa {attempt + 1} ap√≥s {elapsed:.1f}s")
                logger.info(f"Servidor UP em {elapsed:.1f}s")
                return

            elapsed = time.time() - start_time

            # Verifica limites
            if max_wait_seconds and elapsed > max_wait_seconds:
                logger.error(f"Timeout: servidor n√£o respondeu em {max_wait_seconds}s")
                raise TimeoutError(
                    f"Servidor n√£o ficou saud√°vel em {max_wait_seconds}s " f"({attempt} tentativas)"
                )

            if max_attempts and attempt >= max_attempts:
                logger.error(f"Max attempts: {max_attempts} (time: {elapsed:.1f}s)")
                raise TimeoutError(
                    f"Servidor n√£o ficou saud√°vel em {max_attempts} tentativas " f"({elapsed:.1f}s)"
                )

            attempt += 1

            # Print progress (a cada 10 tentativas ou 30s)
            if attempt % 10 == 1 or (elapsed > 30 and attempt % 5 == 1):
                print(f"   ‚è≥ Tentativa {attempt} ap√≥s {elapsed:.1f}s...")

            time.sleep(1)

    def pytest_sessionfinish(self, session):
        """Ao final: exibe relat√≥rio de servidores derrubados e m√©tricas."""
        if self.crashed_tests:
            print("\n" + "=" * 60)
            print("‚ö†Ô∏è  TESTES QUE DERRUBARAM O SERVIDOR:")
            for test_name in self.crashed_tests:
                print(f"   - {test_name}")
            print("=" * 60)

        # Exibe m√©tricas de startup se dispon√≠vel
        if self.startup_metrics:
            print("\n" + "=" * 60)
            print("üìä M√âTRICAS DE STARTUP DO SERVIDOR:")
            if "total_startup_time" in self.startup_metrics:
                print(f"   ‚è±Ô∏è  Tempo total: {self.startup_metrics['total_startup_time']:.1f}s")
            print("=" * 60)


def pytest_configure(config):
    """Registra plugin de monitoramento."""
    config.pluginmanager.register(ServerMonitorPlugin(), "server_monitor")
