"""
Test Real Phi Measurement

CLASSIFICATION: [REAL]
- Sem @patch decorators
- Toca GPU real (PyTorch CUDA)
- Toca LLM real (Ollama qwen2:7b)
- Mede Œ¶ de VERDADE

Tempo esperado: 5-30 minutos
Hardware requerido: GPU 4GB+ VRAM
Depend√™ncias: Ollama rodando em http://localhost:11434

Como rodar:
  pytest tests/consciousness/test_real_phi_measurement.py --timeout=0 -v -s
"""

import pytest
import torch


pytestmark = pytest.mark.real


@pytest.fixture
async def gpu_device() -> str:
    """Retorna 'cuda' se dispon√≠vel, sen√£o 'cpu'."""
    if torch.cuda.is_available():
        print(f"\n‚úÖ GPU dispon√≠vel: {torch.cuda.get_device_name(0)}")
        print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        return "cuda"
    else:
        print("\n‚ö†Ô∏è  GPU n√£o dispon√≠vel, usando CPU (muito mais lento)")
        return "cpu"


@pytest.fixture
async def ollama_client():
    """Retorna cliente Ollama real (n√£o mockado)."""
    try:
        from src.integrations.ollama_client import OllamaClient
        client = OllamaClient(base_url="http://localhost:11434")
        # Testa conex√£o
        tags = await client.list_models()
        if tags:
            print(f"\n‚úÖ Ollama conectado. Modelos dispon√≠veis: {len(tags)}")
            return client
        else:
            pytest.skip("Ollama n√£o tem modelos")
    except Exception as e:
        pytest.skip(f"Ollama n√£o acess√≠vel: {e}")


@pytest.mark.asyncio
@pytest.mark.timeout(0)  # Sem timeout para testes reais
async def test_phi_measurement_basic(gpu_device: str) -> None:
    """
    TESTE REAL: Mede Œ¶ com GPU real
    
    Classifa√ß√£o: [REAL]
    - Usa GPU de verdade
    - Sem @patch
    - Valida integra√ß√£o GPU
    """
    from src.consciousness.integration_loop import IntegrationLoop
    
    # Setup
    consciousness = IntegrationLoop(device=gpu_device)
    
    # Executa ciclos
    phi_values = []
    for cycle in range(10):
        phi = await consciousness.execute_cycle()
        phi_values.append(phi)
        print(f"  Cycle {cycle+1}/10: Œ¶ = {phi:.4f}")
    
    # Valida√ß√£o
    assert len(phi_values) == 10
    assert all(0.0 <= phi <= 1.0 for phi in phi_values), "Œ¶ deve estar em [0,1]"
    
    avg_phi = sum(phi_values) / len(phi_values)
    print(f"\nüìä RESULTADO: Œ¶_avg = {avg_phi:.4f}")


@pytest.mark.asyncio
@pytest.mark.timeout(0)
async def test_phi_multiseed_small(gpu_device: str) -> None:
    """
    TESTE REAL: Mede Œ¶ com m√∫ltiplas seeds
    
    Classifica√ß√£o: [REAL]
    - GPU real
    - M√∫ltiplos seeds (3 sementes)
    - Valida variabilidade
    
    Tempo: ~5 minutos
    """
    from src.consciousness.integration_loop import IntegrationLoop
    
    results = []
    
    for seed in range(3):
        print(f"\nüå± Seed {seed+1}/3")
        
        # Nova inst√¢ncia para cada seed
        consciousness = IntegrationLoop(device=gpu_device, seed=seed)
        
        phi_values = []
        for cycle in range(50):  # Menos ciclos para teste r√°pido
            phi = await consciousness.execute_cycle()
            phi_values.append(phi)
        
        avg_phi = sum(phi_values) / len(phi_values)
        results.append(avg_phi)
        print(f"   Œ¶_avg = {avg_phi:.4f}")
    
    # Valida√ß√£o
    assert len(results) == 3
    assert all(0.0 <= phi <= 1.0 for phi in results)
    
    overall_avg = sum(results) / len(results)
    variance = max(results) - min(results)
    
    print("\nüìä RESULTADOS MULTI-SEED:")
    print(f"   Valores: {[f'{p:.4f}' for p in results]}")
    print(f"   M√©dia geral: {overall_avg:.4f}")
    print(f"   Vari√¢ncia: {variance:.4f}")


@pytest.mark.asyncio
@pytest.mark.timeout(0)
async def test_phi_with_ollama(gpu_device: str, ollama_client) -> None:
    """
    TESTE REAL: Mede Œ¶ com GPU + Ollama (FULL PIPELINE)
    
    Classifica√ß√£o: [REAL]
    - GPU real
    - LLM real (Ollama qwen2:7b)
    - Network real (sem aiohttp mock)
    - Full pipeline
    
    Tempo: ~30 minutos
    
    IMPORTANTE: Este √© o teste que VALIDA n√∫meros para o paper!
    """
    from src.consciousness.integration_loop import IntegrationLoop
    
    # Setup com LLM real
    consciousness = IntegrationLoop(device=gpu_device, llm_client=ollama_client)
    
    phi_values = []
    print("\n‚è±Ô∏è  Medindo Œ¶ com LLM real... (ser√° lento)")
    
    # Reduz para 20 ciclos em teste para ir mais r√°pido
    # Em produ√ß√£o: 100+ ciclos
    for cycle in range(20):
        phi = await consciousness.execute_cycle()
        phi_values.append(phi)
        
        if (cycle + 1) % 5 == 0:
            print(f"  {cycle+1}/20 ciclos... Œ¶_avg = {sum(phi_values)/(cycle+1):.4f}")
    
    # Resultados
    avg_phi = sum(phi_values) / len(phi_values)
    min_phi = min(phi_values)
    max_phi = max(phi_values)
    
    print("\nüìä RESULTADO COM OLLAMA:")
    print(f"   M√©dia: {avg_phi:.4f}")
    print(f"   M√≠nimo: {min_phi:.4f}")
    print(f"   M√°ximo: {max_phi:.4f}")
    
    # Valida√ß√£o
    assert 0.0 <= avg_phi <= 1.0
    assert min_phi <= avg_phi <= max_phi
