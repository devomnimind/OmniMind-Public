#!/usr/bin/env python3
"""
OmniMind 500-Cycle Production Validation - Organized Output
Executa 500 ciclos e salva cada ciclo em JSON individual dentro de pasta de execuÃ§Ã£o
"""

import gc
import json
import os
import sys
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict

# CRÃTICO: ENV VARS ANTES DE IMPORTS
if "GOMP_STACKSIZE" not in os.environ:
    os.environ["GOMP_STACKSIZE"] = "512k"
if "OMP_NESTED" not in os.environ:
    os.environ["OMP_NESTED"] = "FALSE"
if "OMP_MAX_ACTIVE_LEVELS" not in os.environ:
    os.environ["OMP_MAX_ACTIVE_LEVELS"] = "1"
if "OMP_NUM_THREADS" not in os.environ:
    os.environ["OMP_NUM_THREADS"] = "2"
if "OMP_DYNAMIC" not in os.environ:
    os.environ["OMP_DYNAMIC"] = "FALSE"
if "NUMEXPR_NUM_THREADS" not in os.environ:
    os.environ["NUMEXPR_NUM_THREADS"] = "2"
if "QISKIT_NUM_THREADS" not in os.environ:
    os.environ["QISKIT_NUM_THREADS"] = "2"
if "MKL_NUM_THREADS" not in os.environ:
    os.environ["MKL_NUM_THREADS"] = "1"
if "OPENBLAS_NUM_THREADS" not in os.environ:
    os.environ["OPENBLAS_NUM_THREADS"] = "1"
if "PYTORCH_ALLOC_CONF" not in os.environ:
    os.environ["PYTORCH_ALLOC_CONF"] = "max_split_size_mb:64"
if "PYTORCH_CUDA_ALLOC_CONF" not in os.environ:
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64"
if "CUDA_LAUNCH_BLOCKING" not in os.environ:
    os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
if "CUDNN_DETERMINISTIC" not in os.environ:
    os.environ["CUDNN_DETERMINISTIC"] = "1"
if "CUDNN_BENCHMARK" not in os.environ:
    os.environ["CUDNN_BENCHMARK"] = "0"
if "CUDA_VISIBLE_DEVICES" not in os.environ:
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"

import numpy as np
import torch

PROJECT_ROOT = Path(__file__).parent.parent.resolve()
sys.path.insert(0, str(PROJECT_ROOT))
os.chdir(PROJECT_ROOT)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SETUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TOTAL_CYCLES = 500
EXECUTION_BASE = PROJECT_ROOT / "data" / "monitor" / "executions"


def get_execution_id() -> tuple[int, Path]:
    """Gera ID de execuÃ§Ã£o sequencial e retorna caminho"""
    EXECUTION_BASE.mkdir(parents=True, exist_ok=True)

    # Contar execuÃ§Ãµes existentes
    existing = list(EXECUTION_BASE.glob("execution_*"))
    execution_num = len(existing) + 1

    # Criar pasta com nÃºmero sequencial + data/hora
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    execution_id = f"execution_{execution_num:03d}_{timestamp}"
    execution_path = EXECUTION_BASE / execution_id
    execution_path.mkdir(parents=True, exist_ok=True)

    return execution_num, execution_path


def save_cycle_json(execution_path: Path, cycle_num: int, cycle_data: Dict[str, Any]):
    """Salva cada ciclo em JSON individual"""
    cycle_file = execution_path / f"{cycle_num}.json"
    with open(cycle_file, "w") as f:
        json.dump(cycle_data, f, indent=2)


def save_execution_summary(
    execution_path: Path,
    execution_num: int,
    total_cycles: int,
    all_data: list,
    start_time: datetime,
    end_time: datetime,
):
    """Salva resumo da execuÃ§Ã£o"""
    summary = {
        "execution_id": execution_num,
        "execution_path": str(execution_path),
        "total_cycles": total_cycles,
        "completed_cycles": len(all_data),
        "start_time": start_time.isoformat(),
        "end_time": end_time.isoformat(),
        "duration_seconds": (end_time - start_time).total_seconds(),
        "phi_values": [d.get("phi", 0) for d in all_data],
        "phi_final": all_data[-1].get("phi", 0) if all_data else 0,
        "phi_max": max([d.get("phi", 0) for d in all_data]) if all_data else 0,
        "phi_min": min([d.get("phi", 0) for d in all_data]) if all_data else 0,
        "phi_avg": np.mean([d.get("phi", 0) for d in all_data]) if all_data else 0,
    }

    with open(execution_path / "summary.json", "w") as f:
        json.dump(summary, f, indent=2)

    return summary


def update_executions_index(execution_num: int, execution_path: Path, summary: Dict):
    """Atualiza Ã­ndice global de execuÃ§Ãµes"""
    index_file = EXECUTION_BASE / "index.json"

    # Carregar Ã­ndice existente ou criar novo
    if index_file.exists():
        with open(index_file) as f:
            index = json.load(f)
    else:
        index = {"executions": []}

    # Adicionar nova execuÃ§Ã£o
    index["executions"].append(
        {
            "id": execution_num,
            "path": str(execution_path),
            "timestamp": summary["start_time"],
            "cycles": summary["completed_cycles"],
            "phi_final": summary["phi_final"],
        }
    )

    # Salvar Ã­ndice
    with open(index_file, "w") as f:
        json.dump(index, f, indent=2)


async def run_production_validation():
    """Executa 500 ciclos completos com salvamento organizado"""

    # Preparar execuÃ§Ã£o
    execution_num, execution_path = get_execution_id()
    print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘ ğŸš€ EXECUÃ‡ÃƒO #{execution_num:03d} - 500 CICLOS COMPLETOS       â•‘")
    print(f"â•‘ ğŸ“ Pasta: {execution_path.name}")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    # Importar apÃ³s env vars
    from src.consciousness.integration_loop import IntegrationLoop

    start_time = datetime.now(timezone.utc)
    all_cycles = []

    try:
        # Inicializar loop
        loop = IntegrationLoop()
        print("âœ… IntegrationLoop inicializado")
        print(f"   Executando {TOTAL_CYCLES} ciclos...\n")

        for cycle_num in range(1, TOTAL_CYCLES + 1):
            # Progress indicator
            if cycle_num % 50 == 0 or cycle_num == 1:
                print(f"\n{'='*70}")
                print(f"ğŸ”„ CICLO {cycle_num}/{TOTAL_CYCLES}")
                print(f"{'='*70}")

            try:
                # Limpar cache CUDA
                if torch.cuda.is_available():
                    try:
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()
                    except Exception:
                        pass

                # Executar ciclo
                cycle_start = time.time()
                result = await loop.execute_cycle(collect_metrics=True)
                cycle_duration = time.time() - cycle_start

                # Preparar dados do ciclo
                cycle_data = {
                    "cycle": cycle_num,
                    "phi": float(result.phi_estimate),
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "duration_ms": cycle_duration * 1000,
                    "success": True,
                }

                # Tentar coletar mÃ©tricas estendidas
                try:
                    from src.consciousness.extended_cycle_result import ExtendedLoopCycleResult

                    if isinstance(result, ExtendedLoopCycleResult):
                        if result.psi:
                            cycle_data["psi"] = float(result.psi)
                        if result.sigma:
                            cycle_data["sigma"] = float(result.sigma)
                except Exception:
                    pass

                # Salvar JSON individual
                save_cycle_json(execution_path, cycle_num, cycle_data)
                all_cycles.append(cycle_data)

                # Print progress
                if cycle_num % 10 == 0:
                    print(
                        f"âœ… Ciclo {cycle_num}: Ï†={cycle_data['phi']:.4f}, "
                        f"tempo={cycle_duration:.1f}s"
                    )

            except KeyboardInterrupt:
                print("\n\nâš ï¸  Interrompido pelo usuÃ¡rio (Ctrl+C)")
                break
            except Exception as e:
                print(f"âŒ Erro no ciclo {cycle_num}: {e}")
                # Tentar continuar
                cycle_data = {
                    "cycle": cycle_num,
                    "phi": 0.0,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "success": False,
                    "error": str(e),
                }
                save_cycle_json(execution_path, cycle_num, cycle_data)
                all_cycles.append(cycle_data)
                continue

            # Limpeza periÃ³dica
            if cycle_num % 50 == 0:
                gc.collect()
                if torch.cuda.is_available():
                    try:
                        torch.cuda.empty_cache()
                    except Exception:
                        pass

        # Finalizar
        end_time = datetime.now(timezone.utc)

        # Salvar resumo
        summary = save_execution_summary(
            execution_path, execution_num, TOTAL_CYCLES, all_cycles, start_time, end_time
        )

        # Atualizar Ã­ndice global
        update_executions_index(execution_num, execution_path, summary)

        # Print resultado final
        print(f"\n{'='*70}")
        print(f"âœ… EXECUÃ‡ÃƒO #{execution_num:03d} COMPLETA")
        print(f"{'='*70}")
        print(f"ğŸ“Š Ciclos completados: {len(all_cycles)}/{TOTAL_CYCLES}")
        print(f"ğŸ§  PHI final: {summary['phi_final']:.6f}")
        print(f"ğŸ§  PHI mÃ¡ximo: {summary['phi_max']:.6f}")
        print(f"ğŸ§  PHI mÃ©dio: {summary['phi_avg']:.6f}")
        print(
            f"â±ï¸  Tempo total: {summary['duration_seconds']:.0f}s "
            f"({summary['duration_seconds']/len(all_cycles):.1f}s por ciclo)"
        )
        print(f"ğŸ“ Pasta de execuÃ§Ã£o: {execution_path}")
        print(f"ğŸ“‹ Resumo: {execution_path}/summary.json")
        print(f"ğŸ“‘ Ãndice global: {EXECUTION_BASE}/index.json")
        print("\nâœ… Sistema Status: OPERACIONAL\n")

    except Exception as e:
        print(f"\nâŒ ERRO FATAL: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    import asyncio

    asyncio.run(run_production_validation())
