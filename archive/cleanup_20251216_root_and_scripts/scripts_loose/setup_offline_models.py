#!/usr/bin/env python3
"""
Script para configurar fallback offline para modelos HuggingFace.

Garante que modelos cr√≠ticos estejam dispon√≠veis localmente
e configura vari√°veis de ambiente para modo offline quando apropriado.
"""

import os
from pathlib import Path


def setup_offline_mode():
    """Configura modo offline para evitar requests desnecess√°rios."""
    print("üîß Configurando modo offline para modelos HuggingFace...")

    # Modelos cr√≠ticos que devem estar dispon√≠veis localmente
    critical_models = [
        "sentence-transformers/all-MiniLM-L6-v2",
    ]

    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"

    for model_name in critical_models:
        model_dir_name = f"models--{model_name.replace('/', '--')}"
        model_dir = cache_dir / model_dir_name

        if model_dir.exists():
            print(f"‚úÖ {model_name}: encontrado em cache")

            # Verificar snapshots
            snapshots_dir = model_dir / "snapshots"
            if snapshots_dir.exists():
                snapshots = list(snapshots_dir.glob("*"))
                if snapshots:
                    latest_snapshot = max(snapshots, key=lambda x: x.stat().st_mtime)
                    print(f"   üìÅ Snapshot: {latest_snapshot.name}")

                    # Verificar arquivos essenciais
                    essential_files = ["model.safetensors", "config.json", "tokenizer.json"]
                    missing = []
                    for file in essential_files:
                        if not (latest_snapshot / file).exists():
                            missing.append(file)

                    if missing:
                        print(f"   ‚ö†Ô∏è Arquivos faltando: {missing}")
                    else:
                        print("   ‚úÖ Arquivos completos")
                else:
                    print("   ‚ùå Nenhum snapshot encontrado")
            else:
                print("   ‚ùå Diret√≥rio snapshots n√£o encontrado")
        else:
            print(f"‚ùå {model_name}: n√£o encontrado em cache")
            print(f"   üí° Para baixar: huggingface-cli download {model_name}")

    # Configurar vari√°veis de ambiente para modo offline quando cache estiver dispon√≠vel
    print("\nüîß Configurando vari√°veis de ambiente...")

    # Verificar se podemos operar offline
    can_work_offline = True
    for model_name in critical_models:
        model_dir_name = f"models--{model_name.replace('/', '--')}"
        model_dir = cache_dir / model_dir_name
        if not model_dir.exists():
            can_work_offline = False
            break

    if can_work_offline:
        print("‚úÖ Sistema pode operar offline - modelos cr√≠ticos dispon√≠veis")
        print("üí° Configure HF_HUB_OFFLINE=1 para for√ßar modo offline")
    else:
        print("‚ö†Ô∏è Sistema requer conex√£o para baixar modelos faltantes")

    return can_work_offline


def test_offline_loading():
    """Testa carregamento offline dos modelos."""
    print("\nüß™ Testando carregamento offline...")

    try:
        # For√ßar modo offline
        os.environ["HF_HUB_OFFLINE"] = "1"
        os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"

        from sentence_transformers import SentenceTransformer

        model_path = str(
            Path.home()
            / ".cache"
            / "huggingface"
            / "hub"
            / "models--sentence-transformers--all-MiniLM-L6-v2"
            / "snapshots"
            / "c9745ed1d9f207416be6d2e6f8de32d1f16199bf"
        )

        print("Carregando modelo offline...")
        model = SentenceTransformer(model_path, device="cpu", local_files_only=True)

        # Teste r√°pido
        test_text = "This is a test for offline model loading."
        embedding = model.encode(test_text, normalize_embeddings=True)

        print("‚úÖ Modelo carregado offline com sucesso")
        print(f"   üìè Dimens√£o do embedding: {len(embedding)}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no carregamento offline: {e}")
        return False
    finally:
        # Limpar vari√°veis de ambiente
        os.environ.pop("HF_HUB_OFFLINE", None)
        os.environ.pop("HF_HUB_DISABLE_TELEMETRY", None)


if __name__ == "__main__":
    print("üöÄ Configura√ß√£o de Fallback Offline - OmniMind")
    print("=" * 50)

    # Verificar e configurar
    can_work_offline = setup_offline_mode()

    # Testar se funciona
    if can_work_offline:
        test_offline_loading()

    print("\nüìã Recomenda√ß√µes:")
    if can_work_offline:
        print("‚úÖ Configure 'HF_HUB_OFFLINE=1' no ambiente para evitar requests desnecess√°rios")
        print("‚úÖ O sistema funcionar√° mesmo sem conex√£o com HuggingFace")
    else:
        print("‚ö†Ô∏è Baixe os modelos faltantes antes de operar offline")
        print("üí° Comando: huggingface-cli download sentence-transformers/all-MiniLM-L6-v2")

    print("\n‚ú® Configura√ß√£o conclu√≠da!")
