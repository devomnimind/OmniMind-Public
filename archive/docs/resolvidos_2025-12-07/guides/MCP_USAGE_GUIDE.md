# üß† Guia de Uso: MCPs Priorit√°rios OmniMind

**Data:** 2025-11-21
**Vers√£o:** 1.0.0
**P√∫blico-alvo:** AIs trabalhando no projeto OmniMind

---

## üìã INTRODU√á√ÉO

Este guia explica como utilizar os servidores MCP (Model Context Protocol) priorit√°rios configurados para o projeto OmniMind. Os MCPs facilitam o trabalho de AIs, fornecendo ferramentas estruturadas, auditadas e conformes com as regras do projeto.

### Benef√≠cios para AIs

‚úÖ **Acesso estruturado ao c√≥digo** - Navega√ß√£o e modifica√ß√£o segura
‚úÖ **Mem√≥ria persistente** - Conhecimento mantido entre sess√µes
‚úÖ **Racioc√≠nio audit√°vel** - Chain-of-thought documentado
‚úÖ **Conformidade autom√°tica** - Seguran√ßa e auditoria integradas
‚úÖ **Performance otimizada** - Processamento 100% local

---

## üöÄ QUICK START

### Pr√©-requisitos

```bash
# 1. Python 3.12.8 (OBRIGAT√ìRIO)
python --version  # Deve ser 3.12.x

# 2. Qdrant local (para Memory MCP)
docker run -d -p 6333:6333 qdrant/qdrant:v1.7.3

# 3. Depend√™ncias instaladas
pip install -r requirements.txt
```

### Inicializa√ß√£o dos MCPs

```python
from src.integrations.mcp_orchestrator import MCPOrchestrator

# Inicializar orquestrador
orchestrator = MCPOrchestrator()

# Iniciar todos servidores habilitados
results = orchestrator.start_all_servers()

print(f"Servidores iniciados: {sum(results.values())}/{len(results)}")

# Verificar status
for name, status in orchestrator.get_all_statuses().items():
    print(f"{name}: running={status.running}, healthy={status.healthy}")
```

### Context Manager (Recomendado)

```python
from src.integrations.mcp_orchestrator import MCPOrchestrator

# Uso com context manager (inicia e para automaticamente)
with MCPOrchestrator() as orchestrator:
    # Trabalhar com MCPs
    status = orchestrator.get_all_statuses()
    print(f"MCPs ativos: {sum(s.running for s in status.values())}")
    
# MCPs s√£o parados automaticamente ao sair do contexto
```

---

## üóÇÔ∏è TIER 1: MCPs CR√çTICOS

### 1Ô∏è‚É£ Filesystem MCP

**Prop√≥sito:** Acesso seguro e auditado ao filesystem do projeto.

#### Opera√ß√µes Dispon√≠veis

```python
from src.integrations.mcp_client import MCPClient

# Conectar ao Filesystem MCP
fs_client = MCPClient(endpoint="http://127.0.0.1:4321/filesystem")

# 1. Ler arquivo
content = fs_client.read_file("src/agents/orchestrator_agent.py")
print(f"Arquivo tem {len(content)} caracteres")

# 2. Listar diret√≥rio
files = fs_client.list_dir("src/agents", recursive=False)
print(f"Arquivos encontrados: {files}")

# 3. Obter metadados
metadata = fs_client.stat("README.md")
print(f"Tamanho: {metadata['size']} bytes")
print(f"Modificado: {metadata['modified']}")

# 4. Escrever arquivo (com auditoria autom√°tica)
result = fs_client.write_file(
    path="docs/temp/nota.md",
    content="# Nota\n\nConte√∫do da nota."
)
print(f"Escrita conclu√≠da: {result}")
```

#### Caminhos Permitidos

‚úÖ **Permitidos:**
- `src/` - C√≥digo-fonte
- `tests/` - Testes
- `docs/` - Documenta√ß√£o
- `config/` - Configura√ß√µes
- `scripts/` - Scripts
- `web/` - Frontend/Backend web

‚ùå **Proibidos:**
- `.git/` - Diret√≥rio Git (usar Git MCP)
- `.venv/` - Ambiente virtual
- `logs/` - Logs (somente leitura via Logging MCP)
- `__pycache__/` - Cache Python
- `.omnimind/hsm/` - Secrets management

#### Melhores Pr√°ticas

1. **Sempre validar paths antes de escrever**
   ```python
   path = "src/new_feature/module.py"
   # Verificar se path √© permitido
   if not path.startswith(tuple(["src/", "tests/", "docs/"])):
       raise ValueError(f"Path n√£o permitido: {path}")
   ```

2. **Usar read antes de write para evitar sobrescrever**
   ```python
   # Ler conte√∫do existente
   try:
       existing = fs_client.read_file(path)
       # Decidir se pode sobrescrever
   except FileNotFoundError:
       # Arquivo n√£o existe, seguro criar
       pass
   ```

3. **Auditoria √© autom√°tica** - Todas opera√ß√µes s√£o logadas

---

### 2Ô∏è‚É£ Memory MCP

**Prop√≥sito:** Mem√≥ria persistente baseada em grafo sem√¢ntico com Qdrant.

#### Armazenar Conhecimento

```python
from src.integrations.mcp_memory_client import MemoryMCPClient

# Conectar ao Memory MCP
memory = MemoryMCPClient()

# Armazenar conhecimento sobre c√≥digo
memory.store_memory(
    content="O OrchestratorAgent usa an√°lise psicoanal√≠tica (Freud/Lacan) para delega√ß√£o de tarefas",
    metadata={
        "category": "code_knowledge",
        "source_file": "src/agents/orchestrator_agent.py",
        "confidence": 0.95,
        "tags": ["psicoan√°lise", "delega√ß√£o", "agentes"]
    },
    category="code_knowledge"
)

# Armazenar decis√£o de design
memory.store_memory(
    content="Decidimos usar Qdrant local em vez de cloud para garantir 100% privacidade de dados",
    metadata={
        "category": "decisions",
        "date": "2025-11-21",
        "reason": "compliance_lgpd",
        "impact": "high"
    },
    category="decisions"
)

# Armazenar padr√£o identificado
memory.store_memory(
    content="Padr√£o: Todos os agentes herdam de AgentProtocol e implementam execute_task()",
    metadata={
        "category": "patterns",
        "pattern_type": "architecture",
        "files": ["src/agents/*.py"]
    },
    category="patterns"
)
```

#### Buscar Conhecimento

```python
# Busca sem√¢ntica
results = memory.retrieve_memory(
    query="Como funciona a delega√ß√£o de tarefas no orquestrador?",
    top_k=5,
    filters={"category": "code_knowledge"}
)

for result in results:
    print(f"Score: {result.score:.2f}")
    print(f"Conte√∫do: {result.content}")
    print(f"Metadata: {result.metadata}")
    print("---")

# Buscar decis√µes anteriores sobre um tema
decisions = memory.retrieve_memory(
    query="decis√µes sobre privacidade e armazenamento de dados",
    top_k=3,
    filters={"category": "decisions"}
)
```

#### Criar Associa√ß√µes (Grafo de Conhecimento)

```python
# Obter IDs dos memories relacionados
orchestrator_id = "mem_123abc"
psych_analyst_id = "mem_456def"

# Criar rela√ß√£o
memory.create_association(
    id1=orchestrator_id,
    id2=psych_analyst_id,
    relation_type="uses"  # "uses", "extends", "implements", "requires", etc.
)

# Navegar grafo
graph = memory.get_memory_graph(
    start_id=orchestrator_id,
    depth=2  # Profundidade de navega√ß√£o
)

print(f"N√≥s relacionados: {len(graph['nodes'])}")
print(f"Rela√ß√µes: {len(graph['edges'])}")
```

#### Consolida√ß√£o de Mem√≥rias

```python
# Consolidar mem√≥rias similares (evitar duplica√ß√£o)
consolidation_report = memory.consolidate_memories(
    category="code_knowledge",
    strategy="semantic_similarity",  # ou "temporal", "frequency"
    threshold=0.9  # Similaridade m√≠nima para mesclar
)

print(f"Mem√≥rias antes: {consolidation_report['before_count']}")
print(f"Mem√≥rias depois: {consolidation_report['after_count']}")
print(f"Mescladas: {consolidation_report['merged_count']}")
```

#### Cole√ß√µes Dispon√≠veis

1. **code_knowledge** - Conhecimento sobre o c√≥digo
2. **decisions** - Decis√µes de design/implementa√ß√£o
3. **patterns** - Padr√µes identificados
4. **errors** - Erros e suas solu√ß√µes
5. **ai_sessions** - Mem√≥ria de sess√µes de trabalho

---

### 3Ô∏è‚É£ Sequential Thinking MCP

**Prop√≥sito:** Racioc√≠nio sequencial estruturado e audit√°vel (chain-of-thought).

#### Iniciar Sess√£o de Racioc√≠nio

```python
from src.integrations.mcp_thinking_client import ThinkingMCPClient

# Conectar ao Sequential Thinking MCP
thinking = ThinkingMCPClient()

# Iniciar nova sess√£o
session_id = thinking.start_thinking_session(
    task_description="Implementar valida√ß√£o de tipos para novo m√≥dulo de mem√≥ria"
)

print(f"Sess√£o iniciada: {session_id}")
```

#### Adicionar Etapas de Racioc√≠nio

```python
# Etapa 1: Observa√ß√£o
thinking.add_thought_step(
    session_id=session_id,
    content="O m√≥dulo atual n√£o valida tipos de entrada, causando erros em runtime",
    step_type="observation"
)

# Etapa 2: Hip√≥tese
thinking.add_thought_step(
    session_id=session_id,
    content="Adicionar type hints e usar mypy pode prevenir esses erros",
    step_type="hypothesis"
)

# Etapa 3: An√°lise
thinking.add_thought_step(
    session_id=session_id,
    content="""
    Op√ß√µes analisadas:
    1. Type hints + mypy (leve, integrado com CI)
    2. Pydantic (robusto, mas overhead)
    3. Runtime validation manual (trabalhoso)
    
    Recomenda√ß√£o: Type hints + mypy (alinhado com padr√µes do projeto)
    """,
    step_type="analysis"
)

# Etapa 4: Decis√£o
thinking.add_thought_step(
    session_id=session_id,
    content="Decis√£o: Implementar type hints completos e configurar mypy strict",
    step_type="decision"
)

# Etapa 5: A√ß√£o
thinking.add_thought_step(
    session_id=session_id,
    content="Adicionando type hints em src/memory/episodic_memory.py",
    step_type="action"
)

# Etapa 6: Reflex√£o
thinking.add_thought_step(
    session_id=session_id,
    content="Type hints adicionados. mypy --strict passou. Solu√ß√£o efetiva e alinhada com projeto.",
    step_type="reflection"
)
```

#### Branching (M√∫ltiplas Hip√≥teses)

```python
# Criar branch para explorar alternativa
branch_id = thinking.branch_thinking(
    session_id=session_id,
    branch_name="alternative_pydantic"
)

# Adicionar pensamentos na branch
thinking.add_thought_step(
    session_id=branch_id,
    content="Explorando Pydantic como alternativa...",
    step_type="hypothesis"
)

# Comparar branches e escolher melhor
main_quality = thinking.evaluate_thinking_quality(session_id)
alt_quality = thinking.evaluate_thinking_quality(branch_id)

print(f"Qualidade main: {main_quality}")
print(f"Qualidade alternativa: {alt_quality}")

# Mesclar branch vencedora (se necess√°rio)
if alt_quality > main_quality:
    thinking.merge_thinking_branches(
        session_id=session_id,
        branches=[branch_id]
    )
```

#### Recuperar Hist√≥rico

```python
# Obter hist√≥rico completo da sess√£o
history = thinking.get_thinking_history(session_id)

print(f"Total de etapas: {len(history['steps'])}")

for step in history['steps']:
    print(f"[{step['step_type']}] {step['content'][:50]}...")
```

#### Exportar para Auditoria

```python
# Exportar chain-of-thought para auditoria
export_path = thinking.export_thinking_chain(
    session_id=session_id,
    format="markdown"  # ou "json", "html"
)

print(f"Chain-of-thought exportado para: {export_path}")
# Arquivo √© automaticamente adicionado ao sistema de auditoria
```

#### Retomar Sess√£o Anterior

```python
# Retomar sess√£o interrompida
thinking.resume_thinking_session(session_id)

# Continuar adicionando etapas
thinking.add_thought_step(
    session_id=session_id,
    content="Retomando trabalho ap√≥s interrup√ß√£o...",
    step_type="observation"
)
```

---

## ü•à TIER 2: MCPs ALTA PRIORIDADE

### 4Ô∏è‚É£ Context Management MCP

**Prop√≥sito:** Gerenciar contexto hier√°rquico em 7 n√≠veis.

```python
from src.integrations.mcp_context_client import ContextMCPClient

context = ContextMCPClient()

# Adicionar contexto de projeto (n√≠vel 1 - permanente)
context.push_context(
    level="project",
    data={
        "name": "OmniMind",
        "version": "1.0.0",
        "python_version": "3.12.8",
        "architecture": "multi-agent psychoanalytic"
    }
)

# Adicionar contexto de sess√£o (n√≠vel 2)
context.push_context(
    level="session",
    data={
        "session_id": "sess_2025_11_21_001",
        "goal": "Implementar MCPs priorit√°rios",
        "started_at": "2025-11-21T10:00:00Z"
    }
)

# Adicionar contexto de tarefa (n√≠vel 3)
context.push_context(
    level="task",
    data={
        "task_id": "task_123",
        "description": "Criar Filesystem MCP wrapper",
        "priority": "critical"
    }
)

# Obter contexto completo (hier√°rquico)
full_context = context.get_full_context()
print(f"Contexto total: {len(full_context)} n√≠veis")

# Comprimir contexto se muito grande
if context.get_token_count() > 80000:
    compressed = context.compress_context(strategy="semantic")
    print(f"Contexto comprimido: {compressed['tokens_saved']} tokens economizados")
```

---

### 5Ô∏è‚É£ Git MCP

**Prop√≥sito:** Opera√ß√µes Git auditadas e seguras.

```python
from src.integrations.mcp_git_client import GitMCPClient

git = GitMCPClient()

# Ver status
status = git.git_status()
print(f"Branch atual: {status['branch']}")
print(f"Arquivos modificados: {len(status['modified'])}")

# Ver diff
diff = git.git_diff(path="src/integrations/mcp_orchestrator.py")
print(diff)

# Adicionar arquivos
git.git_add(["src/integrations/mcp_orchestrator.py"])

# Commit (auditado automaticamente)
result = git.git_commit(
    message="feat: Adicionar MCP Orchestrator",
    files=["src/integrations/mcp_orchestrator.py"]
)
print(f"Commit: {result['commit_hash']}")

# Listar branches
branches = git.git_branch_list()
print(f"Branches: {branches}")

# Ver hist√≥rico
log = git.git_log(n=5)
for commit in log:
    print(f"{commit['hash'][:7]} - {commit['message']}")
```

---

### 6Ô∏è‚É£ Python Environment MCP

**Prop√≥sito:** Executar c√≥digo Python com isolamento e valida√ß√£o.

```python
from src.integrations.mcp_python_client import PythonMCPClient

python = PythonMCPClient()

# Executar c√≥digo (isolado)
result = python.execute_code(
    code="""
import sys
print(f"Python: {sys.version}")
print(f"Executando em ambiente isolado")
""",
    timeout=5
)

print(result['stdout'])

# Lint c√≥digo
lint_result = python.lint_code(
    code="def func(x,y): return x+y",
    linter="flake8"
)
print(f"Lint issues: {lint_result['issues']}")

# Type check
type_result = python.type_check(
    code="""
def add(x: int, y: int) -> int:
    return x + y

result: str = add(1, 2)  # Erro de tipo
"""
)
print(f"Type errors: {type_result['errors']}")

# Formatar c√≥digo
formatted = python.format_code(
    code="def func( x , y ): return x + y",
    formatter="black"
)
print(formatted)
```

---

## ü•â TIER 3: MCPs COMPLEMENTARES

### 7Ô∏è‚É£ SQLite MCP

```python
from src.integrations.mcp_sqlite_client import SQLiteMCPClient

db = SQLiteMCPClient()

# Executar query
results = db.execute_query(
    db_name="cache",
    query="SELECT * FROM computation_cache WHERE key = ?",
    params=["feature_embeddings_v1"]
)

# Inserir dados
db.execute_query(
    db_name="metrics",
    query="INSERT INTO performance_metrics (name, value, timestamp) VALUES (?, ?, ?)",
    params=["mcp_latency", 45.2, time.time()]
)
```

---

### 8Ô∏è‚É£ System Info MCP

```python
from src.integrations.mcp_system_info_client import SystemInfoMCPClient

sysinfo = SystemInfoMCPClient()

# Obter info da GPU
gpu_info = sysinfo.get_gpu_info()
print(f"GPU: {gpu_info['name']}")
print(f"VRAM dispon√≠vel: {gpu_info['vram_available_mb']} MB")

# Info da CPU
cpu_info = sysinfo.get_cpu_info()
print(f"CPU load: {cpu_info['load_percent']}%")

# Mem√≥ria
mem_info = sysinfo.get_memory_info()
print(f"RAM dispon√≠vel: {mem_info['available_gb']} GB")
```

---

## üîí SEGURAN√áA E AUDITORIA

### Auditoria Autom√°tica

Todas as opera√ß√µes nos MCPs s√£o automaticamente auditadas:

```python
from src.audit.immutable_audit import get_audit_system

audit = get_audit_system()

# Ver logs recentes de MCPs
logs = audit.query_logs(
    category="filesystem_mcp",
    limit=10
)

for log in logs:
    print(f"[{log['timestamp']}] {log['action']}: {log['data']}")
```

### Valida√ß√£o de Integridade

```python
# Verificar integridade da cadeia de auditoria
integrity_ok = audit.verify_chain_integrity()
print(f"Integridade da auditoria: {'OK' if integrity_ok else 'FALHA'}")
```

---

## üìä MONITORAMENTO E M√âTRICAS

### Exportar M√©tricas

```python
from src.integrations.mcp_orchestrator import MCPOrchestrator

orchestrator = MCPOrchestrator()
metrics = orchestrator.export_metrics()

print(f"Servidores rodando: {metrics['running_servers']}/{metrics['total_servers']}")
print(f"Servidores saud√°veis: {metrics['healthy_servers']}")

for name, server_metrics in metrics['servers'].items():
    print(f"\n{name}:")
    print(f"  Requests: {server_metrics['total_requests']}")
    print(f"  Error rate: {server_metrics['error_rate']:.2%}")
    print(f"  Avg response: {server_metrics['avg_response_time_ms']:.2f}ms")
```

---

## üõ†Ô∏è TROUBLESHOOTING

### Servidor n√£o inicia

```python
# Verificar logs de erro
status = orchestrator.get_server_status("filesystem")
if status.error_message:
    print(f"Erro: {status.error_message}")

# Tentar reiniciar
success = orchestrator.restart_server("filesystem")
print(f"Rein√≠cio: {'sucesso' if success else 'falha'}")
```

### Performance lenta

```python
# Verificar m√©tricas
metrics = orchestrator.export_metrics()
for name, m in metrics['servers'].items():
    if m['avg_response_time_ms'] > 100:
        print(f"ALERTA: {name} com lat√™ncia alta: {m['avg_response_time_ms']}ms")
```

---

## üìö EXEMPLOS PR√ÅTICOS

### Workflow Completo: Implementar Nova Feature

```python
from src.integrations.mcp_orchestrator import MCPOrchestrator
from src.integrations.mcp_thinking_client import ThinkingMCPClient
from src.integrations.mcp_memory_client import MemoryMCPClient
from src.integrations.mcp_client import MCPClient

# 1. Iniciar MCPs
with MCPOrchestrator() as orchestrator:
    thinking = ThinkingMCPClient()
    memory = MemoryMCPClient()
    fs = MCPClient(endpoint="http://127.0.0.1:4321/filesystem")
    
    # 2. Iniciar sess√£o de racioc√≠nio
    session_id = thinking.start_thinking_session(
        task_description="Implementar novo m√≥dulo de analytics"
    )
    
    # 3. Buscar conhecimento relevante
    relevant_knowledge = memory.retrieve_memory(
        query="padr√µes de implementa√ß√£o de m√≥dulos",
        top_k=3
    )
    
    thinking.add_thought_step(
        session_id=session_id,
        content=f"Conhecimento recuperado: {len(relevant_knowledge)} mem√≥rias relevantes",
        step_type="observation"
    )
    
    # 4. Analisar c√≥digo existente
    existing_modules = fs.list_dir("src/", recursive=True)
    analytics_exists = any("analytics" in f for f in existing_modules)
    
    thinking.add_thought_step(
        session_id=session_id,
        content=f"M√≥dulo analytics existe: {analytics_exists}",
        step_type="observation"
    )
    
    # 5. Tomar decis√£o
    thinking.add_thought_step(
        session_id=session_id,
        content="Decis√£o: Criar novo m√≥dulo src/analytics/ seguindo padr√£o do projeto",
        step_type="decision"
    )
    
    # 6. Implementar
    code = '''"""
M√≥dulo de analytics do OmniMind.
"""

def analyze_performance():
    pass
'''
    
    fs.write_file("src/analytics/__init__.py", code)
    
    thinking.add_thought_step(
        session_id=session_id,
        content="M√≥dulo criado com sucesso",
        step_type="action"
    )
    
    # 7. Armazenar conhecimento
    memory.store_memory(
        content="Criado m√≥dulo src/analytics/ seguindo padr√£o do projeto",
        metadata={
            "category": "code_knowledge",
            "date": "2025-11-21",
            "files": ["src/analytics/__init__.py"]
        },
        category="code_knowledge"
    )
    
    # 8. Reflex√£o
    thinking.add_thought_step(
        session_id=session_id,
        content="Feature implementada com sucesso. Conhecimento armazenado para futuras refer√™ncias.",
        step_type="reflection"
    )
    
    # 9. Exportar chain-of-thought
    thinking.export_thinking_chain(session_id, format="markdown")
    
print("Workflow completo executado com sucesso!")
```

---

## ‚úÖ CHECKLIST PARA AIs

Antes de come√ßar a trabalhar no projeto:

- [ ] MCPs iniciados (`orchestrator.start_all_servers()`)
- [ ] Qdrant rodando (para Memory MCP)
- [ ] Auditoria verificada (`audit.verify_chain_integrity()`)
- [ ] Contexto de projeto carregado
- [ ] Conhecimento relevante recuperado da mem√≥ria

Durante o trabalho:

- [ ] Usar Sequential Thinking para racioc√≠nio estruturado
- [ ] Armazenar decis√µes importantes na mem√≥ria
- [ ] Validar paths antes de opera√ß√µes de filesystem
- [ ] Commitar com mensagens descritivas (via Git MCP)
- [ ] Exportar chain-of-thought ao final

Ao finalizar:

- [ ] Consolidar mem√≥rias (evitar duplica√ß√£o)
- [ ] Verificar m√©tricas dos MCPs
- [ ] Exportar relat√≥rio final
- [ ] Parar MCPs gracefully

---

## üìñ REFER√äNCIAS

- **An√°lise de MCPs:** `docs/architecture/MCP_PRIORITY_ANALYSIS.md`
- **Configura√ß√£o:** `config/mcp_servers.json`
- **MCP Orchestrator:** `src/integrations/mcp_orchestrator.py`
- **Auditoria:** `src/audit/immutable_audit.py`

---

**Guia criado por:** GitHub Copilot Agent
**Para:** AIs trabalhando no projeto OmniMind
**Data:** 2025-11-21
