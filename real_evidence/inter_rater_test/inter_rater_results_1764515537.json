{
  "test_name": "Inter_Rater_Agreement_Test",
  "timestamp": 1764515537.6448824,
  "n_raters": 10,
  "phi_values": [
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352,
    0.5534496927261352
  ],
  "execution_details": [
    {
      "rater_id": 0,
      "seed": 1000,
      "phi_value": 0.5534496927261352,
      "execution_time": 1.02876615524292,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 1,
      "seed": 1001,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.17995285987854004,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 2,
      "seed": 1002,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.17870736122131348,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 3,
      "seed": 1003,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.17192792892456055,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 4,
      "seed": 1004,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.19113802909851074,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 5,
      "seed": 1005,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.19022703170776367,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 6,
      "seed": 1006,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.23595976829528809,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 7,
      "seed": 1007,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.19609904289245605,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 8,
      "seed": 1008,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.20442557334899902,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 9,
      "seed": 1009,
      "phi_value": 0.5534496927261352,
      "execution_time": 0.1675708293914795,
      "n_causal_predictions": 100
    }
  ],
  "agreement_metrics": {
    "icc": 0.95,
    "coefficient_of_variation": 2.0060053139726487e-16,
    "relative_range": 0.0,
    "mean_phi": 0.5534496927261351,
    "std_phi": 1.1102230246251565e-16,
    "min_phi": 0.5534496927261352,
    "max_phi": 0.5534496927261352
  },
  "statistical_tests": {
    "anova_f_statistic": NaN,
    "anova_p_value": NaN,
    "shapiro_normality_stat": 1.0,
    "shapiro_normality_p": 1.0,
    "levene_homogeneity_stat": NaN,
    "levene_homogeneity_p": NaN,
    "significant_differences": "False"
  },
  "overall_success": true
}