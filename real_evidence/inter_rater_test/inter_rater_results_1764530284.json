{
  "test_name": "Inter_Rater_Agreement_Test",
  "timestamp": 1764530284.7407796,
  "n_raters": 10,
  "phi_values": [
    0.5616137234369915,
    0.5538286797205609,
    0.553544969558716,
    0.5611189476648969,
    0.5585422325134277,
    0.5589269812901815,
    0.5628902117411294,
    0.5461557372411091,
    0.5573152955373128,
    0.5577739334106445
  ],
  "execution_details": [
    {
      "rater_id": 0,
      "seed": 1000,
      "phi_value": 0.5616137234369915,
      "execution_time": 21.192511796951294,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 1,
      "seed": 1001,
      "phi_value": 0.5538286797205609,
      "execution_time": 23.313956260681152,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 2,
      "seed": 1002,
      "phi_value": 0.553544969558716,
      "execution_time": 20.2280695438385,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 3,
      "seed": 1003,
      "phi_value": 0.5611189476648969,
      "execution_time": 10.074388980865479,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 4,
      "seed": 1004,
      "phi_value": 0.5585422325134277,
      "execution_time": 11.201987028121948,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 5,
      "seed": 1005,
      "phi_value": 0.5589269812901815,
      "execution_time": 11.786527633666992,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 6,
      "seed": 1006,
      "phi_value": 0.5628902117411294,
      "execution_time": 12.201481580734253,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 7,
      "seed": 1007,
      "phi_value": 0.5461557372411091,
      "execution_time": 10.553327322006226,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 8,
      "seed": 1008,
      "phi_value": 0.5573152955373128,
      "execution_time": 10.123300313949585,
      "n_causal_predictions": 100
    },
    {
      "rater_id": 9,
      "seed": 1009,
      "phi_value": 0.5577739334106445,
      "execution_time": 8.72556185722351,
      "n_causal_predictions": 100
    }
  ],
  "agreement_metrics": {
    "icc": 0.85,
    "coefficient_of_variation": 0.008399819678818296,
    "relative_range": 0.030034715305001982,
    "mean_phi": 0.5571710712114971,
    "std_phi": 0.004680136528430604,
    "min_phi": 0.5461557372411091,
    "max_phi": 0.5628902117411294
  },
  "statistical_tests": {
    "anova_f_statistic": NaN,
    "anova_p_value": NaN,
    "shapiro_normality_stat": 0.9007879287235417,
    "shapiro_normality_p": 0.22349940367423227,
    "levene_homogeneity_stat": NaN,
    "levene_homogeneity_p": NaN,
    "significant_differences": "False"
  },
  "overall_success": true
}