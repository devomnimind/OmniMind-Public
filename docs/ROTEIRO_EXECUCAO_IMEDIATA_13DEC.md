# üöÄ ROTEIRO PR√ÅTICO: Executar & Diagnosticar (13 DEC)

**Objetivo**: Confirmar subutiliza√ß√£o GPU e preparar paraleliza√ß√£o
**Tempo**: ~30 minutos (script roda em background)

---

## ‚úÖ PASSO 1: Preparar Ambiente (2 min)

```bash
cd /home/fahbrain/projects/omnimind

# Ativar venv
source .venv/bin/activate

# Validar scripts
bash -n scripts/recovery/03_run_integration_cycles_optimized.sh
bash -n scripts/diagnostics/monitor_gpu_utilization_realtime.sh
```

**Esperado:**
```
‚úÖ Syntax OK
(sem erros)
```

---

## ‚úÖ PASSO 2: Iniciar 3 Terminais

### Terminal 1Ô∏è‚É£: Script de Ciclos (Principal)
```bash
cd /home/fahbrain/projects/omnimind
bash scripts/recovery/03_run_integration_cycles_optimized.sh
```

**O que esperar:**
```
üîÑ Step 3: Integration Cycles OTIMIZADO (13 DEC)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéØ Configuration:
   ‚Ä¢ Project: /home/fahbrain/projects/omnimind
   ‚Ä¢ Qiskit GPU: ENABLED ‚úÖ
   ‚Ä¢ Aer Simulator: GPU mode
   ‚Ä¢ Python: python3
   ‚Ä¢ OTIMIZA√á√ïES: Savepoints a cada 100 ciclos + Œ¶ base corrigida

üìä Running 500 integration cycles (OTIMIZADO)...

‚úÖ Cycle 1/500 [EXPECTATION] | Œ¶=0.XXXX (avg=0.XXXX) | Duration: XXms
```

---

### Terminal 2Ô∏è‚É£: Monitor GPU (Real-time)
```bash
cd /home/fahbrain/projects/omnimind
bash scripts/diagnostics/monitor_gpu_utilization_realtime.sh
```

**O que esperar:**
```
üîç GPU UTILIZATION MONITOR - REAL TIME
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö†Ô∏è  [45.2%] GPU Mem: 25.3% | Clock: 1524 MHz | Memory: 5001 MHz | Power: 28 W
‚ö†Ô∏è  [46.1%] GPU Mem: 25.1% | Clock: 1512 MHz | Memory: 5001 MHz | Power: 29 W
‚ö†Ô∏è  [45.8%] GPU Mem: 25.4% | Clock: 1520 MHz | Memory: 5001 MHz | Power: 28 W

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìä STATS (√∫ltimos 60s):
   ‚Ä¢ SM Utilization: 45.7% ‚Üí ‚ùå GPU SUBUTILIZADA (script problem)
   ‚Ä¢ Memory Usage: 25.3%
   ‚Ä¢ Samples: 30
   ‚Ä¢ CSV: /home/fahbrain/projects/omnimind/data/reports/gpu_utilization_20251213_XXXXXX.csv
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

### Terminal 3Ô∏è‚É£: Monitoramento do Sistema
```bash
# Option A: Simples (recomendado)
watch -n 2 nvidia-smi

# Option B: Detalhado
nvidia-smi -l 2  # update a cada 2 segundos
```

**O que esperar:**
```
+-------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|=========================|======================|======================|
|   0  NVIDIA GeForce GTX 1650     Off  | 00:1F.0     Off |                  N/A |
|  0%   45C    P2    28W / 50W |   1024MiB /  4096MiB |     45%      Default |
+-------------------------+----------------------+----------------------+

‚ö†Ô∏è Observe que GPU-Util fica entre 45-55% (√© o esperado para sincronismo)
‚úÖ Memory est√° OK (~25-30%)
‚úÖ Temperature est√° OK (~45-50C)
```

---

## üìä FASE DE OBSERVA√á√ÉO (20 min)

Deixar os 3 terminais rodando. **N√ÉO interrompa o script principal!**

### O Que Procurar

#### ‚úÖ Sinais de Que Tudo Est√° Bem
```
‚úÖ SM Utilization: 40-60% (normal para 1 thread)
‚úÖ Memory: 20-35% (n√£o cresce constantemente)
‚úÖ Temperature: 40-55C (OK para trabalho)
‚úÖ Clock: 1.5-1.8 GHz (varia, normal)
‚úÖ Power: 25-35W (consistente)
```

#### ‚ö†Ô∏è Sinais de Problemas
```
‚ùå SM Util > 90%: GPU pode estar limitada por outro fator
‚ùå Memory crescendo (25‚Üí35‚Üí45%): Vazamento de mem√≥ria
‚ùå Temperature > 65C: Thermal throttling come√ßou
‚ùå Power drops abruptamente: Falha de pot√™ncia ou thermal
‚ùå SM Util oscila muito (10%‚Üí90%): GPU contexts switching
```

---

## üìà AN√ÅLISE P√ìS-EXECU√á√ÉO (5 min)

Quando o script terminar (ou ap√≥s 20 min):

### 1. Verificar Arquivo de Resultado

```bash
# JSON com todos os ciclos
cat data/reports/integration_cycles_qiskit_phase3.json | python3 -m json.tool | head -50
```

**Esperado:**
```json
{
  "phase": 3,
  "timestamp": "2025-12-13T15:33:16.764664",
  "total_cycles": 500,
  "elapsed_time_seconds": 11070.344812631607,
  "qiskit_gpu_enabled": true,
  "metrics": {
    "phi": {
      "values": [0.1455, 0.7154, 0.6086, ...],
      "min": 0.1455,
      "max": 1.0,
      "mean": 0.6344
    }
  }
}
```

### 2. Verificar Log GPU

```bash
tail -100 data/reports/gpu_utilization_*.csv
```

**Esperado:**
```
timestamp,sm_util,mem_util,sm_clock,mem_clock,power_draw,context_switches
1702478400,45.2,25.3,1524,5001,28,N/A
1702478402,46.1,25.1,1512,5001,29,N/A
1702478404,45.8,25.4,1520,5001,28,N/A
...
```

### 3. Estat√≠sticas GPU

```bash
# Calcular m√©dias
python3 << 'EOF'
import csv

csv_file = "data/reports/gpu_utilization_*.csv"  # find latest

with open(csv_file, 'r') as f:
    reader = csv.DictReader(f)
    sm_values = []
    mem_values = []

    for row in reader:
        if row['sm_util'] != 'N/A':
            sm_values.append(float(row['sm_util']))
            mem_values.append(float(row['mem_util']))

    print(f"SM Utilization:")
    print(f"  ‚Ä¢ Min: {min(sm_values):.1f}%")
    print(f"  ‚Ä¢ Max: {max(sm_values):.1f}%")
    print(f"  ‚Ä¢ Avg: {sum(sm_values)/len(sm_values):.1f}%")
    print(f"\nMemory Utilization:")
    print(f"  ‚Ä¢ Min: {min(mem_values):.1f}%")
    print(f"  ‚Ä¢ Max: {max(mem_values):.1f}%")
    print(f"  ‚Ä¢ Avg: {sum(mem_values)/len(mem_values):.1f}%")
EOF
```

**Esperado:**
```
SM Utilization:
  ‚Ä¢ Min: 40.2%
  ‚Ä¢ Max: 60.1%
  ‚Ä¢ Avg: 48.7%

Memory Utilization:
  ‚Ä¢ Min: 24.8%
  ‚Ä¢ Max: 32.1%
  ‚Ä¢ Avg: 27.3%
```

---

## üéØ INTERPRETA√á√ÉO DOS RESULTADOS

### Cen√°rio A: GPU Bem Utilizada ‚úÖ (improv√°vel)
```
SM Utilization: 75-85%
‚Üí Script pode estar rodando paralelizado
‚Üí CUDA Graphs n√£o √© t√£o cr√≠tico
‚Üí Apenas otimize savepoints (j√° feito)
```

### Cen√°rio B: GPU Subutilizada ‚ö†Ô∏è (ESPERADO)
```
SM Utilization: 40-60%
‚Üí Confirma problema de paraleliza√ß√£o
‚Üí Script roda s√≠ncrono (1 thread)
‚Üí GPU "espera" CPU processar Python
‚Üí CUDA Graphs podia ajudar 40%
```

### Cen√°rio C: GPU Muito Subutilizada ‚ùå (poss√≠vel problema)
```
SM Utilization: < 30%
Memory: < 15%
‚Üí Poss√≠vel problema:
   ‚îú‚îÄ VS Code rodando (competi√ß√£o)
   ‚îú‚îÄ Script n√£o est√° otimizado corretamente
   ‚îú‚îÄ Qiskit GPU n√£o foi inicializado
   ‚îî‚îÄ Python GIL severamente limitando

‚Üí A√ß√£o: Verificar logs do script
```

---

## üìã CHECKLIST FINAL

- [ ] Terminal 1: Script rodou sem erros at√© ciclo 100?
- [ ] Terminal 2: Monitor mostrou SM 45-60%?
- [ ] Terminal 3: nvidia-smi mostrou Memory 25-35%?
- [ ] Temperatura < 55C durante execu√ß√£o?
- [ ] CSV foi criado em data/reports/?
- [ ] JSON com ciclos foi salvo?
- [ ] Nenhum erro de CUDA em logs?

---

## üöÄ PR√ìXIMOS PASSOS (Se Tudo OK)

### Op√ß√£o 1: Rodar Fase 4 (Valida√ß√£o)
```bash
bash scripts/recovery/04_init_persistent_state.sh
```

### Op√ß√£o 2: Implementar CUDA Graphs (Paraleliza√ß√£o)
Criado documento: `docs/CUDA_GRAPHS_IMPLEMENTATION_PLAN.md`

### Op√ß√£o 3: Apenas Documentar Resultado
Gerar relat√≥rio final da Phase 3

---

## üÜò Se Algo Der Errado

### Script Parou Abruptamente
```bash
# Ver √∫ltimas linhas do log
tail -50 logs/integration_cycles_optimized_*.log

# Erros comuns:
# ‚Üí "OOM Killer": Aumentar savepoint interval (agora 100, testar 200)
# ‚Üí "Qiskit not available": pip install qiskit qiskit-aer
# ‚Üí "GPU out of memory": Reduzir batch size no c√≥digo
```

### Monitor Deu Erro
```bash
# Ver se nvidia-smi funciona
nvidia-smi

# Se n√£o:
sudo apt-get install nvidia-utils
```

### JSON Incompleto
```bash
# Verificar se script rodou todos os ciclos
jq '.metrics.phi.values | length' data/reports/integration_cycles_qiskit_phase3.json
# Esperado: 500
```

---

## üìû RESUMO DO COMANDO FINAL

**Execute isto agora:**

```bash
cd /home/fahbrain/projects/omnimind

# Terminal 1
bash scripts/recovery/03_run_integration_cycles_optimized.sh

# Terminal 2 (em paralelo)
bash scripts/diagnostics/monitor_gpu_utilization_realtime.sh

# Terminal 3 (em paralelo)
nvidia-smi -l 2
```

**Tempo**: ~3 horas (500 ciclos √ó 22s/ciclo)
**Resultado**: Confirma√ß√£o se GPU est√° subutilizada conforme esperado

---

**Status**: üü¢ PRONTO PARA EXECUTAR
