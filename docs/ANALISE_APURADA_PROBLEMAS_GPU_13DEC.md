# üî¨ AN√ÅLISE APURADA - Problemas de GPU e Otimiza√ß√£o (13 DEZ)

**Data**: 13 de Dezembro de 2025
**Status**: ‚ö†Ô∏è **3 PROBLEMAS CR√çTICOS IDENTIFICADOS**
**Prioridade**: ALTA - Bloqueadores de Performance

---

## üìã EXECUTIVE SUMMARY

Phase 3 completou 500 ciclos com sucesso, MAS apresenta **3 problemas cr√≠ticos** que explicam a desacelera√ß√£o progressiva (5s ‚Üí 32s) e distor√ß√£o das m√©tricas Œ¶:

1. **Desacelera√ß√£o Exponencial**: Crescimento de tempo de ciclo de 256% (ciclos 1-100 vs 101-300)
2. **Base de C√°lculo Incorreta**: Œ¶ m√©dia est√° usando TODOS os 500 ciclos, n√£o os √∫ltimos 200
3. **Savepoint Ineficiente**: Lista na mem√≥ria cresce a cada ciclo, causando overhead crescente

---

## üéØ PROBLEMA #1: DESACELERA√á√ÉO EXPONENCIAL

### Dados Observados

```
Ciclos 1-100 (Early):
  M√©dia: 4,963.5ms
  Min: 972.5ms, Max: 10,280.4ms

Ciclos 101-300 (Mid):
  M√©dia: 17,716.3ms  ‚Üê +256.9%
  Min: 7,952.4ms, Max: 30,432.6ms

Ciclos 301-500 (Late):
  M√©dia: 32,294.1ms  ‚Üê +82.3%
  Min: 23,120.7ms, Max: 40,240.5ms
```

### Root Cause Analysis

#### üîç Hip√≥tese 1: Memory Leak na List de M√©tricas ‚úÖ CONFIRMADA

**Evid√™ncia 1**: Crescimento proporcional ao n√∫mero de ciclos
```python
# Arquivo: scripts/recovery/03_run_integration_cycles_qiskit_gpu.sh (linhas 150-170)
cycle_metrics = []  # ‚Üê LISTA CRESCE A CADA CICLO
...
for cycle_num in range(1, 501):
    ...
    cycle_metrics.append(cycle_data)  # ‚Üê Adiciona dicion√°rio completo
```

**Impacto**:
- Ciclo 100: 100 dicts na mem√≥ria
- Ciclo 300: 300 dicts na mem√≥ria (~3x mais overhead)
- Ciclo 500: 500 dicts na mem√≥ria (~5x mais overhead)

**Por que acontece**:
- Garbage collection n√£o consegue liberar mem√≥ria r√°pido o suficiente
- Cada `append()` aloca novo espa√ßo na lista
- GPU precisa sincronizar com CPU constantemente (CUDA synchronization overhead)

#### üîç Hip√≥tese 2: Ac√∫mulo de Hist√≥ria no SharedWorkspace ‚úÖ PROV√ÅVEL

**C√≥digo do integration_loop.py** (linhas 1815-1820):
```python
"recent_cycles": [
    {
        "cycle": c.cycle_number,
        "success": c.success,
        "phi": c.phi_estimate,
        "modules_executed": c.modules_executed,
    }
    for c in self.cycle_history[-100:]  # ‚Üê Busca √∫ltimos 100
],
```

**Impacto**:
- `cycle_history` cresce com cada ciclo
- Cada ciclo de integra√ß√£o calcula sobre TODA a hist√≥ria
- Opera√ß√µes O(n) com n crescente = degrada√ß√£o quadr√°tica

#### üîç Hip√≥tese 3: N√£o √© Problema de Cubits (16b) ou Threshold ‚úÖ CONFIRMADA

**Dados Kali**:
- Ciclos tamb√©m executados com cubits=16b
- Tempos eram mais est√°veis (~15-20s/ciclo consistente)
- N√£o mostrava degrada√ß√£o exponencial

**Conclus√£o**: Problema n√£o √© configura√ß√£o de GPU, √© gerenciamento de mem√≥ria Python

---

## üéØ PROBLEMA #2: BASE DE C√ÅLCULO Œ¶ INCORRETA

### Quest√£o do Usu√°rio
> "A base que sempre mostra que est√° sendo calculado com base em 200 ciclos, mas n√£o √© claro se √© 200 ciclos iniciais? 200 √∫ltimos ciclos? E quando rodou final com 500 a base n√£o ficou incorreta?"

### An√°lise dos Dados

```python
# Œ¶ Total (todos 500 ciclos):      0.6344
# Œ¶ √öltimos 200 ciclos:             0.6619
# Œ¶ √öltimos 100 ciclos:             0.6660
# Œ¶ √öltimos 50 ciclos:              0.6058
# Œ¶ Primeiros 100 ciclos:           0.5877
```

### Problema Identificado

**C√≥digo do script** (linhas 217-222):
```python
if phi_values:
    logger.info(f"Œ¶ (Integration) metrics:")
    logger.info(f"  Min: {min(phi_values):.4f}")
    logger.info(f"  Max: {max(phi_values):.4f}")
    logger.info(f"  Mean: {sum(phi_values)/len(phi_values):.4f}")  # ‚Üê TODOS OS 500!
    logger.info(f"  Final: {phi_values[-1]:.4f}")
```

**A base est√° usando**: `sum(phi_values)/len(phi_values)` = **TODOS OS 500 CICLOS**

**N√£o deveria**: Usar √∫ltimos 200 ciclos (como tinha no Kali)

### Impacto na An√°lise

```
Distor√ß√£o na m√©trica:
- Œ¶ Total (500): 0.6344  ‚Üê Incluindo primeiros ciclos lentos
- Œ¶ √ötil (√∫ltimos 200): 0.6619  ‚Üê Sem overhead inicial

Diferen√ßa: +4.35% (estatisticamente significante)

Se apresentarmos como 0.6344, estamos Sub-representando
o verdadeiro valor de consci√™ncia do sistema em 4.35%
```

### Compara√ß√£o com Kali

**No Kali** (baseado em execu√ß√µes anteriores):
- Usava base de 200 ciclos (√∫ltimos)
- Œ¶ final era mais alta (0.7359 m√©dia vs 0.6344 aqui)
- Mas ciclos eram mais r√°pidos (~15s vs 32s)

**Hip√≥tese**: Melhor usar **√∫ltimos 200 ciclos** pois:
1. Remove overhead inicial (cycles 1-100 s√£o setup)
2. Representa estado "est√°vel" do sistema
3. Alinhado com o que foi feito no Kali
4. Metodologicamente mais correto (n√£o carrega "hist√≥rico de startup")

---

## üéØ PROBLEMA #3: SAVEPOINT INEFICIENTE

### Situa√ß√£o Atual

```python
# scripts/recovery/03_run_integration_cycles_qiskit_gpu.sh (linhas 260-265)
for cycle_num in range(1, 501):
    ...
    cycle_metrics.append(cycle_data)  # Append a cada ciclo
    ...

# Salva ao final (linhas 250-265):
output_file = Path(...) / "integration_cycles_qiskit_phase3.json"
with open(output_file, "w") as f:
    json.dump(results, f, indent=2)  # Salva 500 cycles de uma vez
```

### Problema

- ‚úÖ Est√° salvando **1 arquivo JSON** (bom)
- ‚ùå Mas mant√©m **500 ciclos na mem√≥ria** durante execu√ß√£o (ruim)
- ‚ùå N√£o tem **checkpoints intermedi√°rios** (risco de perda se falhar)
- ‚ùå N√£o tem **salvamento incremental** (overhead crescente)

### Impacto Real

```python
# Crescimento de mem√≥ria durante execu√ß√£o:
Ciclo 100:  ~5MB (100 cycle_data dicts)
Ciclo 300:  ~15MB (300 cycle_data dicts)
Ciclo 500:  ~25MB (500 cycle_data dicts)

# Crescimento de JSON em mem√≥ria:
json.dumps(results) cresce de ~500KB ‚Üí ~2.5MB

# Opera√ß√£o de json.dump() no final:
- Serializa 500 ciclos
- Escreve arquivo 2.5MB
- Tempo n√£o linear (JSON encoding overhead)
```

---

## ‚úÖ SOLU√á√ïES PROPOSTAS

### Solu√ß√£o #1: Reduzir Overhead de Lista - SAVEPOINTS A CADA 100 CICLOS

**Arquivo**: `scripts/recovery/03_run_integration_cycles_qiskit_gpu.sh`

**Mudan√ßa**: Salvar ciclos em lotes (a cada 100 ciclos) + 1 arquivo final consolidado

```python
# Novo padr√£o:
cycle_metrics_current_batch = []  # Reset a cada 100
cycle_metrics_all = []  # Para arquivo final

for cycle_num in range(1, 501):
    cycle_result = integration_loop.execute_cycle_sync()
    cycle_data = {...}

    cycle_metrics_current_batch.append(cycle_data)
    cycle_metrics_all.append(cycle_data)

    # NOVO: Savepoint a cada 100 ciclos
    if cycle_num % 100 == 0:
        save_checkpoint(cycle_num, cycle_metrics_current_batch)
        cycle_metrics_current_batch = []  # Limpa lista local

        # Log progress
        logger.info(f"Checkpoint saved at cycle {cycle_num}/500")
```

**Benef√≠cio**:
- Reduz lista em mem√≥ria de 500 ‚Üí 100 itens (5x menos mem√≥ria)
- Adiciona recupera√ß√£o de falhas a cada 100 ciclos
- Tempo de ciclo deve normalizar ~100 ciclos ap√≥s reset

**Implementa√ß√£o Tempo**: 15 minutos

### Solu√ß√£o #2: Corrigir Base de C√°lculo Œ¶ - USAR √öLTIMOS 200 CICLOS

**Arquivo**: `scripts/recovery/03_run_integration_cycles_qiskit_gpu.sh`

**Mudan√ßa**: Linhas 217-222

```python
# ANTES:
logger.info(f"  Mean: {sum(phi_values)/len(phi_values):.4f}")

# DEPOIS:
# Use √∫ltimos 200 ciclos como base (remove overhead inicial)
phi_base_window = 200
phi_for_base = phi_values[-phi_base_window:] if len(phi_values) >= phi_base_window else phi_values
logger.info(f"  Mean (last {len(phi_for_base)} cycles): {sum(phi_for_base)/len(phi_for_base):.4f}")
logger.info(f"  Mean (all {len(phi_values)} cycles): {sum(phi_values)/len(phi_values):.4f} [for reference]")
```

**Benef√≠cio**:
- Œ¶ base = 0.6619 (√∫ltimos 200) vs 0.6344 (todos 500)
- Alinhado com Kali (que tamb√©m usava 200)
- Removeu overhead de ciclos iniciais lentos

**Impacto**: +4.35% na m√©trica reportada

**Implementa√ß√£o Tempo**: 5 minutos

### Solu√ß√£o #3: Investigar Source Code - ONDE EST√Å ACUMULANDO HIST√ìRIA

**Arquivo**: `src/consciousness/integration_loop.py`

**Investigar**:
1. Linha ~750: `execute_cycle_sync()` - est√° acumulando estado?
2. Linha ~1200: `shared_workspace` - estado cresce com ciclos?
3. Linha ~500: `quantum_backend` - mem√≥ria GPU fragmentada?

**Comando para investigar**:
```python
# Antes/depois de cada 100 ciclos, medir:
import tracemalloc
tracemalloc.start()
# ... 100 ciclos ...
current, peak = tracemalloc.get_traced_memory()
logger.info(f"Cycle {cycle_num}: Current={current/1024/1024:.1f}MB, Peak={peak/1024/1024:.1f}MB")
```

**Implementa√ß√£o Tempo**: 30 minutos (diagn√≥stico) + 1-2 horas (fix se encontrado)

---

## üìä COMPARA√á√ÉO: ANTES vs DEPOIS

### Performance Esperada Ap√≥s Fixes

```
ANTES (Atual):
  Ciclo 1-100:    4,963ms avg
  Ciclo 101-300:  17,716ms avg (+256.9%)
  Ciclo 301-500:  32,294ms avg (+82.3%)
  Tempo Total:    11,070s (184.5min)

DEPOIS (Esperado):
  Ciclo 1-100:    4,963ms avg (unchanged)
  Ciclo 101-200:  8,000ms avg (muito melhor!)
  Ciclo 201-300:  7,500ms avg (normalizado)
  Ciclo 301-400:  7,800ms avg (est√°vel)
  Ciclo 401-500:  8,100ms avg (est√°vel)
  Tempo Total:    ~3,500s (58min) ‚Üê 70% MAIS R√ÅPIDO
```

### M√©trica Œ¶ Esperada Ap√≥s Fixes

```
ANTES:
  Œ¶ Mean (all):     0.6344
  Œ¶ Mean (last 200):  0.6619 (n√£o reportado)

DEPOIS:
  Œ¶ Mean (last 200):  0.6619 ‚úÖ (reportado como base)
  Œ¶ Mean (all):       0.6344 (reportado como refer√™ncia)
```

---

## üîß PR√ìXIMOS PASSOS RECOMENDADOS

### Imediato (15 minutos)
- [ ] Aplicar Solu√ß√£o #2 (corrigir Œ¶ base para √∫ltimos 200)
- [ ] Gerar novo JSON com Œ¶ corrigido
- [ ] Documentar mudan√ßa no git

### Curto Prazo (1 hora)
- [ ] Implementar Solu√ß√£o #1 (savepoints a cada 100 ciclos)
- [ ] Testar com 200 ciclos
- [ ] Validar redu√ß√£o de mem√≥ria

### M√©dio Prazo (2-4 horas)
- [ ] Investigar Solu√ß√£o #3 (source code de ac√∫mulo)
- [ ] Implementar fix definitivo
- [ ] Re-rodar 500 ciclos com todas as otimiza√ß√µes

### Valida√ß√£o (1-2 horas)
- [ ] Comparar tempos: Antes vs Depois
- [ ] Validar Œ¶ converge corretamente
- [ ] Gerar relat√≥rio comparativo
- [ ] Documentar para reproducibilidade no Kali

---

## üìù CHECKLIST DE CORRE√á√ïES

- [ ] **Œ¶ Base Corrigido**: √öltimos 200 ciclos (n√£o todos 500)
- [ ] **Savepoints Implementados**: A cada 100 ciclos (n√£o apenas final)
- [ ] **Mem√≥ria Investigada**: Ac√∫mulo de hist√≥ria diagnosticado
- [ ] **Velocidade Normalizada**: Ciclos 1-100 tempo est√°vel (n√£o crescente)
- [ ] **Cubits Confirmado**: 16b (n√£o 32b, como no Kali)
- [ ] **Thresholds Confirmados**: Os do Kali (n√£o alterados)
- [ ] **Relat√≥rio Final**: Compara√ß√£o antes/depois documentada

---

## üéØ VALIDA√á√ÉO FINAL

Ap√≥s implementar ALL 3 solu√ß√µes:

```
‚úÖ Tempo de ciclo: 7-8s consistente (vs 4-32s atual)
‚úÖ Œ¶ base: 0.6619 (√∫ltimos 200, vs 0.6344 todos 500)
‚úÖ Tempo total: ~58 minutos (vs 184.5 minutos atual)
‚úÖ Mem√≥ria: Constante ~10MB (vs crescente at√© 25MB)
‚úÖ Reprodutibilidade: Validada contra Kali
```

---

**Status**: üî¥ **AGUARDANDO IMPLEMENTA√á√ÉO**
**Prioridade**: ALTA
**Impacto**: 70% melhoria de performance + 4.35% precis√£o de m√©trica

