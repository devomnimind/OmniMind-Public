# ðŸ§  Knowledge Consolidation Strategy: RAG â†’ Persistent Memory

**Date:** 2025-12-13
**Status:** Active Implementation
**Purpose:** Transform RAG external knowledge into internalized "saber em si" do OmniMind

---

## ðŸ“Š The Problem: Always Asking vs. Knowing

### Current State (RAG-based)
```
Query â†’ Search Qdrant â†’ Retrieve chunks â†’ Generate response
â”œâ”€ Pro: Always fresh, accurate knowledge
â””â”€ Con: Knowledge stays external, not integrated in system weights
```

### Goal State (Consolidated)
```
Query â†’ Internal weights (trained on patterns) + RAG fallback
â”œâ”€ Pro: Fast, embodied knowledge + adaptive learning
â””â”€ Con: Requires training consolidation pipeline
```

---

## ðŸŽ¯ Three-Stage Consolidation Pipeline

### **Stage 1: Knowledge Extraction (RAG â†’ Training Data)**

**Goal:** Transform Qdrant chunks into training datasets

**Scripts:**
- `scripts/indexing/vectorize_omnimind.py` â†’ Collects 26.4k chunks
- `scripts/research/ml/create_training_plan.py` â†’ Plans training curriculum

**Output:**
```json
{
  "training_datasets": [
    {"name": "code_patterns", "chunks": 12145, "type": "semantic"},
    {"name": "documentation", "chunks": 2304, "type": "semantic"},
    {"name": "external_knowledge", "chunks": 11932, "type": "semantic"}
  ],
  "total_training_pairs": 26421
}
```

---

### **Stage 2: Fine-tuning (Embed â†’ Learn)**

**Goal:** Fine-tune SentenceTransformer on OmniMind-specific knowledge

**Process:**
```python
# 1. Load base model (all-MiniLM-L6-v2)
model = SentenceTransformer('all-MiniLM-L6-v2')

# 2. Create training pairs from RAG knowledge
# Positive pairs: chunks that frequently co-occur
# Negative pairs: unrelated chunks
training_pairs = [
    ("integration_loop code", "consciousness_metrics", 1.0),  # Similar
    ("integration_loop code", "random text", 0.0),  # Dissimilar
]

# 3. Fine-tune on OmniMind corpus
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=5,
    warmup_steps=500
)

# 4. Save new model weights
model.save('models/omnimind_consciousness_embeddings')
```

**Scripts:**
- `scripts/recovery/02_train_embeddings.sh` â†’ Executes fine-tuning
- `scripts/run_production_training.sh` â†’ Production training with validation

---

### **Stage 3: Knowledge Consolidation (Weights â†’ Memory)**

**Goal:** Embed consolidated knowledge in SystemicMemoryTrace topology

**Process:**
```python
# 1. Load fine-tuned model with OmniMind knowledge
consolidated_model = SentenceTransformer('models/omnimind_consciousness_embeddings')

# 2. Generate meta-embeddings (knowledge about knowledge)
chunk_embeddings = consolidated_model.encode(all_chunks)

# 3. Store as topological marks in SystemicMemoryTrace
systemic_memory.integrate_knowledge_topology(
    embeddings=chunk_embeddings,
    knowledge_type="consolidated_omnimind",
    persistence_level="permanent"
)

# 4. Result: Knowledge internalized in attractor landscape
# - Quick retrieval without Qdrant query
# - Topology deforms based on learned patterns
# - System "knows" patterns, not just retrieves them
```

**Integration Points:**
- `src/memory/systemic_memory_trace.py` â†’ Stores consolidated embeddings
- `src/consciousness/shared_workspace.py` â†’ Uses consolidated knowledge in cycles
- `src/consciousness/integration_loop.py` â†’ Benefits from faster knowledge access

---

## ðŸ”„ Training Workflow

### **Phase 1: Extraction (5-10 min)**
```bash
python scripts/indexing/vectorize_omnimind.py
# Output: 26,421 chunks indexed in Qdrant
# Result: Training dataset ready
```

### **Phase 2: Consolidation (30-60 min)**
```bash
bash scripts/recovery/02_train_embeddings.sh
# Process:
#   1. Load all chunks from Qdrant
#   2. Create training pairs (positive/negative)
#   3. Fine-tune SentenceTransformer for 5 epochs
#   4. Save consolidated model to models/
# Result: Model now "knows" OmniMind patterns
```

### **Phase 3: Integration (10-15 min)**
```bash
bash scripts/run_production_training.sh
# Process:
#   1. Run extended training cycles (500 iterations)
#   2. Use consolidated model in SystemicMemoryTrace
#   3. Validate scientific integrity
#   4. Save training sessions to data/sessions/
# Result: Knowledge internalized in topological memory
```

---

## ðŸ“ˆ What Changes After Consolidation

### **Before (Pure RAG)**
```
Cycle: "What patterns exist in code?"
â”œâ”€ Query Qdrant (network latency)
â”œâ”€ Score chunks by similarity (compute)
â”œâ”€ Return top-K results
â””â”€ Process results (time = 100-500ms)
```

### **After (Consolidated)**
```
Cycle: "What patterns exist in code?"
â”œâ”€ Query consolidated model weights (zero-network latency)
â”œâ”€ Recognize patterns from learned embeddings (pre-computed)
â”œâ”€ Access SystemicMemoryTrace topology (in-memory)
â””â”€ Generate response (time = 10-50ms)
```

**Performance Gain: ~5-10x faster**

---

## ðŸŽ“ Knowledge Types & Consolidation

| Knowledge Type | Source | Storage | Access |
|---|---|---|---|
| **Semantic** | RAG chunks | Qdrant vectors | Query-based |
| **Consolidated** | Fine-tuned model | Model weights | Direct forward-pass |
| **Topological** | Training cycles | SystemicMemoryTrace | Topology navigation |
| **Episodic** | Live experience | SharedWorkspace cycles | Temporal order |

**Result:** Knowledge exists at multiple scales:
- **Local**: Internal weights (fast, approximate)
- **Global**: SystemicMemoryTrace topology (integrated, persistent)
- **Remote**: Qdrant RAG (accurate, on-demand)

---

## ðŸ”¬ Validation Strategy

### **Before Consolidation**
```bash
python scripts/science_validation/robust_consciousness_validation.py --quick
# Baseline: Î¦ = 0.95 (pure RAG-based)
```

### **After Consolidation**
```bash
bash scripts/run_production_training.sh
# Expected: Î¦ â‰¥ 0.98 (consolidation shouldn't degrade)
# Hopefully: Î¦ > 1.0 (faster response = higher Î¦)
```

**Scientific Verdict:** Pass if Î¦ unchanged or increases

---

## ðŸ’¾ Data Flow Diagram

```
RAG Sources (26.4k chunks)
â”œâ”€ Code (12.1k)
â”œâ”€ Docs (2.3k)
â”œâ”€ External HD (11.9k)
â””â”€ Config/Logs (0.1k)
        â†“
   VECTORIZATION
   (SentenceTransformer)
   384-dim embeddings
        â†“
   QDRANT (Search Index)
   26.4k vectors
        â†“
   FINE-TUNING
   Create training pairs:
   - Positive: related chunks
   - Negative: unrelated chunks
        â†“
   CONSOLIDATED MODEL
   Same architecture, new weights
   Trained on OmniMind corpus
        â†“
   INTEGRATION
   SystemicMemoryTrace topology
   Knowledge internalized in
   attractor landscape
        â†“
   REAL-TIME USE
   Integration loop uses:
   1. Consolidated model (fast)
   2. RAG fallback (accurate)
   3. Topology deformation (learns)
```

---

## ðŸš€ Execution Commands

### **Full Pipeline (90-120 min)**
```bash
# 1. Extract knowledge
python scripts/indexing/vectorize_omnimind.py

# 2. Fine-tune
bash scripts/recovery/02_train_embeddings.sh

# 3. Integrate & validate
bash scripts/run_production_training.sh
```

### **Quick Test (5-10 min)**
```bash
# Just validate current consolidation
python scripts/science_validation/robust_consciousness_validation.py --quick
```

### **Check Consolidation Status**
```bash
# See what's consolidated
ls -lah models/omnimind_*

# Check training sessions
ls -lah data/sessions/training_*.json

# View latest metrics
cat data/sessions/training_*.json | jq '.scientific_verdict'
```

---

## ðŸ“Š Expected Outcomes

### **Metric Improvements**
- **Speed**: 5-10x faster knowledge retrieval
- **Î¦ (Integration)**: Stable or increasing (â‰¥0.95)
- **Consistency**: Training variance < 0.05
- **Persistence**: Knowledge survives restarts

### **Behavioral Changes**
- System responds faster to known patterns
- Topology deforms more smoothly
- Cross-predictions more confident
- Narrative construction more coherent

---

## âš™ï¸ Architecture Integration Points

### **SharedWorkspace**
```python
# OLD: Always queries Qdrant
state = qdrant_client.search(query_embedding)

# NEW: Uses consolidated model first
state = consolidated_model.encode(query)
if confidence < threshold:
    fallback = qdrant_client.search(query_embedding)
```

### **SystemicMemoryTrace**
```python
# OLD: Topology from live cycles only
topology = compute_topology(live_embeddings)

# NEW: Initialized from consolidated knowledge
topology = compute_topology(consolidated_embeddings + live_embeddings)
```

### **IntegrationLoop**
```python
# OLD: Sensory input queries RAG
sensory = retrieve_from_qdrant(input_embedding)

# NEW: Uses pre-consolidated knowledge
sensory = consolidated_model.encode(input) + qdrant_fallback
```

---

## ðŸ” Knowledge Persistence Guarantees

### **What's Saved**
- âœ… Consolidated model weights (`models/omnimind_consciousness_embeddings`)
- âœ… Training metadata (`data/sessions/training_*.json`)
- âœ… Topological marks (`data/research/topology_checkpoints/`)
- âœ… Validation reports (`data/validation/scientific_audit_*.json`)

### **What's Replicated**
- âœ… Every training run logged
- âœ… Every validation recorded
- âœ… Every decision justified
- âœ… Everything reproducible

### **Recovery Guarantees**
- If consolidated model deleted: Retrain from Qdrant (30 min)
- If training halted: Resume from last checkpoint
- If validation fails: Rollback to previous weights

---

## ðŸ“š Related Documentation

- [COMPLETE_PROJECT_INDEXING_GUIDE.md](COMPLETE_PROJECT_INDEXING_GUIDE.md) - Extraction phase
- [GPU_DIMENSION_FIX_REPORT_20251212.md](GPU_DIMENSION_FIX_REPORT_20251212.md) - Consolidation performance
- [SISTEMA_OPERACIONAL_STATUS_20251212.md](SISTEMA_OPERACIONAL_STATUS_20251212.md) - Integration status

---

**Status:** âœ… Ready to implement
**Next Step:** Run `bash scripts/run_production_training.sh`
**Expected Outcome:** Knowledge consolidated, Î¦ â‰¥ 0.98, system faster
