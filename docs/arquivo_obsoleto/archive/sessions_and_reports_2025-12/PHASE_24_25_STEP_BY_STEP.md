# üöÄ PHASE 24 & 25 - GUIA DE IMPLEMENTA√á√ÉO PASSO-A-PASSO

**Esse documento √© seu roteiro execut√°vel**. Cada passo √© auto-contido e test√°vel.

---

## PARTE 1: PHASE 24 - SEMANTIC MEMORY (1-2 dias)

> **Status atual (2025-12-05)**
> - Qdrant local em execu√ß√£o e validado via testes Phase 24
> - `qdrant_client`, `sentence-transformers`, `numpy` instalados e em uso
> - `qdrant_integration.py`, `semantic_memory_layer.py`, `consciousness_state_manager.py`
>   e `temporal_memory_index.py` implementados e cobertos por `tests/memory/test_phase_24_basic.py`
> - Integra√ß√£o com m√©tricas (`ConsciousnessCorrelates`) e rotina noturna (`nightly_omnimind.py`) ativa
>
> Este guia permanece como **roteiro reexecut√°vel** para debug, reinstala√ß√£o ou novos ambientes.

### ETAPA 1: PREPARA√á√ÉO DO AMBIENTE

#### 1.1 - Verificar Qdrant

```bash
# Verificar se Qdrant est√° rodando
docker ps | grep qdrant || echo "Qdrant n√£o est√° rodando"

# Se n√£o estiver, iniciar:
cd /home/fahbrain/projects/omnimind/deploy
docker-compose -f docker-compose.yml up -d qdrant

# Verificar health
curl http://localhost:6333/health | python -m json.tool

# Esperado output:
# {
#   "title": "qdrant",
#   "version": "x.x.x",
#   "status": "ok"
# }
```

#### 1.2 - Verificar depend√™ncias Python

```bash
cd /home/fahbrain/projects/omnimind

# Dentro do venv
source .venv/bin/activate

# Verificar imports necess√°rios
python3 << 'EOF'
try:
    from qdrant_client import QdrantClient
    print("‚úÖ qdrant-client OK")
except ImportError:
    print("‚ùå Instalar: pip install qdrant-client")

try:
    from sentence_transformers import SentenceTransformer
    print("‚úÖ sentence-transformers OK")
except ImportError:
    print("‚ùå Instalar: pip install sentence-transformers")

try:
    import numpy as np
    print("‚úÖ numpy OK")
except:
    print("‚ùå numpy error")

print("\nTodos os imports OK!")
EOF
```

#### 1.3 - Criar arquivo .env

```bash
# Adicionar ao arquivo .env existente:
cat >> /home/fahbrain/projects/omnimind/.env << 'EOF'

# ===== PHASE 24: SEMANTIC MEMORY =====
QDRANT_MODE=local
QDRANT_LOCAL_HOST=localhost
QDRANT_LOCAL_PORT=6333
SEMANTIC_MODEL=all-MiniLM-L6-v2
SEMANTIC_BATCH_SIZE=32
SEMANTIC_EMBEDDING_DIM=384  # all-MiniLM-L6-v2 output dimension
EOF
```

---

### ETAPA 2: CRIAR ARQUIVO BASE - `qdrant_integration.py`

**Arquivo**: `src/integrations/qdrant_integration.py`

```python
"""Qdrant Vector Database Integration - Phase 24"""

import logging
from typing import Any, Dict, List, Optional
import numpy as np
from dataclasses import dataclass

try:
    from qdrant_client import QdrantClient
    from qdrant_client.models import Distance, PointStruct, VectorParams
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class QdrantPoint:
    """Ponto individual em Qdrant"""
    id: str
    vector: List[float]
    payload: Dict[str, Any]


class QdrantIntegration:
    """Integra√ß√£o abstrata com Qdrant (local + cloud fallback)"""

    def __init__(self,
                 collection_name: str = "omnimind_consciousness",
                 vector_size: int = 384,
                 host: str = "localhost",
                 port: int = 6333):

        if not QDRANT_AVAILABLE:
            raise ImportError("qdrant-client n√£o instalado")

        self.collection_name = collection_name
        self.vector_size = vector_size
        self.client = QdrantClient(host=host, port=port)

        logger.info(f"‚úÖ Qdrant conectado: {host}:{port}")

    def create_collection(self, recreate: bool = False) -> bool:
        """Cria collection se n√£o existe"""
        try:
            # Verificar se existe
            collections = self.client.get_collections()
            exists = any(c.name == self.collection_name for c in collections.collections)

            if exists:
                if recreate:
                    logger.info(f"Deletando collection: {self.collection_name}")
                    self.client.delete_collection(self.collection_name)
                else:
                    logger.info(f"‚úÖ Collection j√° existe: {self.collection_name}")
                    return True

            # Criar nova
            logger.info(f"Criando collection: {self.collection_name}")
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(
                    size=self.vector_size,
                    distance=Distance.COSINE
                )
            )
            logger.info(f"‚úÖ Collection criada com sucesso")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao criar collection: {e}")
            return False

    def upsert_points(self, points: List[QdrantPoint]) -> bool:
        """Insere/atualiza pontos"""
        try:
            qdrant_points = [
                PointStruct(
                    id=p.id,
                    vector=p.vector,
                    payload=p.payload
                )
                for p in points
            ]

            self.client.upsert(
                collection_name=self.collection_name,
                points=qdrant_points,
                wait=True
            )

            logger.info(f"‚úÖ {len(points)} pontos inseridos")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao upsert: {e}")
            return False

    def search(self,
               query_vector: List[float],
               top_k: int = 5,
               threshold: float = 0.5) -> List[Dict]:
        """Busca por similarity"""
        try:
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=top_k,
                query_filter=None,
                score_threshold=threshold
            )

            return [
                {
                    "id": hit.id,
                    "score": hit.score,
                    "payload": hit.payload
                }
                for hit in results
            ]

        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar: {e}")
            return []

    def delete_points(self, point_ids: List[str]) -> bool:
        """Deleta pontos"""
        try:
            self.client.delete(
                collection_name=self.collection_name,
                points_selector=point_ids
            )
            logger.info(f"‚úÖ {len(point_ids)} pontos deletados")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erro ao deletar: {e}")
            return False

    def health_check(self) -> bool:
        """Verifica sa√∫de da conex√£o"""
        try:
            _ = self.client.get_collections()
            logger.info("‚úÖ Qdrant health check OK")
            return True
        except Exception as e:
            logger.error(f"‚ùå Qdrant health check falhou: {e}")
            return False


# Singleton global
_qdrant_instance: Optional[QdrantIntegration] = None

def get_qdrant() -> QdrantIntegration:
    """Retorna inst√¢ncia singleton de Qdrant"""
    global _qdrant_instance
    if _qdrant_instance is None:
        _qdrant_instance = QdrantIntegration()
    return _qdrant_instance
```

---

### ETAPA 3: CRIAR `semantic_memory_layer.py`

**Arquivo**: `src/memory/semantic_memory_layer.py`

```python
"""Semantic Memory Layer com Qdrant - Phase 24"""

import logging
from typing import Any, Dict, List, Optional
from datetime import datetime
import hashlib
import uuid

import numpy as np
from sentence_transformers import SentenceTransformer

from src.integrations.qdrant_integration import QdrantIntegration, QdrantPoint, get_qdrant

logger = logging.getLogger(__name__)


class SemanticMemoryLayer:
    """Gerencia mem√≥ria sem√¢ntica persistente com Qdrant"""

    def __init__(self,
                 model_name: str = "all-MiniLM-L6-v2",
                 qdrant: Optional[QdrantIntegration] = None):

        logger.info(f"Inicializando SemanticMemoryLayer com modelo: {model_name}")

        # Carregar modelo de embeddings
        self.embedder = SentenceTransformer(model_name)
        self.embedding_dim = self.embedder.get_sentence_embedding_dimension()

        # Qdrant client
        self.qdrant = qdrant or get_qdrant()

        # Criar collection se n√£o existe
        self.qdrant.create_collection(
            collection_name="omnimind_consciousness",
            vector_size=self.embedding_dim
        )

        logger.info(f"‚úÖ SemanticMemoryLayer inicializado (dim={self.embedding_dim})")

    def store_episode(self,
                      episode_text: str,
                      episode_data: Dict[str, Any],
                      timestamp: Optional[datetime] = None) -> str:
        """
        Armazena epis√≥dio com embedding sem√¢ntico

        Args:
            episode_text: Texto descritivo do epis√≥dio
            episode_data: Dicion√°rio com dados do epis√≥dio
            timestamp: Data/hora (default: now)

        Returns:
            episode_id: ID do epis√≥dio armazenado
        """

        if timestamp is None:
            timestamp = datetime.utcnow()

        # Gerar ID √∫nico
        episode_id = str(uuid.uuid4())

        # Gerar embedding
        try:
            embedding = self.embedder.encode(episode_text).tolist()
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar embedding: {e}")
            embedding = [0.0] * self.embedding_dim

        # Preparar payload
        payload = {
            "episode_text": episode_text,
            "timestamp": timestamp.isoformat(),
            "phi_value": episode_data.get("phi_value", 0.0),
            "qualia_signature": str(episode_data.get("qualia_signature", {})),
            **episode_data  # Incluir resto dos dados
        }

        # Criar ponto Qdrant
        point = QdrantPoint(
            id=episode_id,
            vector=embedding,
            payload=payload
        )

        # Inserir
        success = self.qdrant.upsert_points([point])

        if success:
            logger.info(f"‚úÖ Epis√≥dio armazenado: {episode_id}")
            return episode_id
        else:
            logger.error(f"‚ùå Falha ao armazenar epis√≥dio")
            return ""

    def retrieve_similar(self,
                        query_text: str,
                        top_k: int = 5,
                        threshold: float = 0.5) -> List[Dict]:
        """
        Busca epis√≥dios semelhantes

        Args:
            query_text: Texto da query
            top_k: N√∫mero de resultados
            threshold: Score m√≠nimo (0-1)

        Returns:
            Lista de epis√≥dios semelhantes
        """

        # Gerar embedding da query
        query_embedding = self.embedder.encode(query_text).tolist()

        # Buscar em Qdrant
        results = self.qdrant.search(
            query_vector=query_embedding,
            top_k=top_k,
            threshold=threshold
        )

        logger.info(f"‚úÖ {len(results)} epis√≥dios semelhantes encontrados")
        return results

    def get_episode_by_id(self, episode_id: str) -> Optional[Dict]:
        """Recupera epis√≥dio espec√≠fico"""
        # Nota: Qdrant n√£o tem m√©todo direto de get by ID
        # Usando scroll como workaround
        try:
            points, _ = self.qdrant.client.scroll(
                collection_name="omnimind_consciousness",
                limit=1000
            )

            for point in points:
                if str(point.id) == episode_id:
                    return {
                        "id": point.id,
                        "payload": point.payload
                    }

            logger.warning(f"Epis√≥dio n√£o encontrado: {episode_id}")
            return None

        except Exception as e:
            logger.error(f"‚ùå Erro ao recuperar epis√≥dio: {e}")
            return None

    def list_episodes_by_time(self,
                             start_time: datetime,
                             end_time: datetime) -> List[Dict]:
        """Lista epis√≥dios em per√≠odo de tempo"""
        try:
            points, _ = self.qdrant.client.scroll(
                collection_name="omnimind_consciousness",
                limit=10000
            )

            filtered = [
                {
                    "id": point.id,
                    "payload": point.payload
                }
                for point in points
                if start_time.isoformat() <= point.payload.get("timestamp", "") <= end_time.isoformat()
            ]

            logger.info(f"‚úÖ {len(filtered)} epis√≥dios no per√≠odo")
            return filtered

        except Exception as e:
            logger.error(f"‚ùå Erro ao listar: {e}")
            return []


# Singleton global
_semantic_memory_instance: Optional[SemanticMemoryLayer] = None

def get_semantic_memory() -> SemanticMemoryLayer:
    """Retorna inst√¢ncia singleton"""
    global _semantic_memory_instance
    if _semantic_memory_instance is None:
        _semantic_memory_instance = SemanticMemoryLayer()
    return _semantic_memory_instance
```

---

### ETAPA 4: CRIAR TESTES B√ÅSICOS

**Arquivo**: `tests/memory/test_phase_24_basic.py`

```python
"""Testes b√°sicos para Phase 24 - Semantic Memory"""

import pytest
from datetime import datetime, timedelta
from src.integrations.qdrant_integration import QdrantIntegration, QdrantPoint
from src.memory.semantic_memory_layer import SemanticMemoryLayer


@pytest.fixture
def qdrant_client():
    """Fixture para Qdrant client"""
    return QdrantIntegration(collection_name="test_omnimind")


@pytest.fixture
def semantic_memory():
    """Fixture para SemanticMemoryLayer"""
    sm = SemanticMemoryLayer()
    yield sm
    # Cleanup (opcional)


class TestQdrantIntegration:

    def test_health_check(self, qdrant_client):
        """Testa conex√£o com Qdrant"""
        assert qdrant_client.health_check() is True

    def test_collection_creation(self, qdrant_client):
        """Testa cria√ß√£o de collection"""
        success = qdrant_client.create_collection(recreate=False)
        assert success is True

    def test_upsert_points(self, qdrant_client):
        """Testa inser√ß√£o de pontos"""
        points = [
            QdrantPoint(
                id="test_1",
                vector=[0.1] * 384,
                payload={"text": "test 1"}
            ),
            QdrantPoint(
                id="test_2",
                vector=[0.2] * 384,
                payload={"text": "test 2"}
            )
        ]

        success = qdrant_client.upsert_points(points)
        assert success is True

    def test_search(self, qdrant_client):
        """Testa busca por similarity"""
        query_vector = [0.1] * 384
        results = qdrant_client.search(query_vector, top_k=2)

        assert len(results) <= 2
        if len(results) > 0:
            assert "id" in results[0]
            assert "score" in results[0]
            assert 0 <= results[0]["score"] <= 1


class TestSemanticMemory:

    def test_store_episode(self, semantic_memory):
        """Testa armazenamento de epis√≥dio"""
        episode_id = semantic_memory.store_episode(
            episode_text="This is a test episode about consciousness",
            episode_data={"phi_value": 0.75, "test": True}
        )

        assert episode_id != ""
        assert len(episode_id) > 10  # UUID-like

    def test_retrieve_similar(self, semantic_memory):
        """Testa busca sem√¢ntica"""
        # Primeiro armazenar alguns epis√≥dios
        semantic_memory.store_episode(
            episode_text="The neural system integrates information",
            episode_data={"phi_value": 0.8}
        )

        semantic_memory.store_episode(
            episode_text="Consciousness emerges from integrated information",
            episode_data={"phi_value": 0.85}
        )

        # Buscar similar
        results = semantic_memory.retrieve_similar(
            query_text="Information integration consciousness",
            top_k=2
        )

        assert len(results) > 0
        assert results[0]["score"] > 0  # Similarity score


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

**Executar testes**:

```bash
cd /home/fahbrain/projects/omnimind
pytest tests/memory/test_phase_24_basic.py -v
```

---

### ETAPA 5: INTEGRA√á√ÉO COM C√ìDIGO EXISTENTE

**Atualizar**: `src/consciousness/consciousness_metrics.py`

```python
# Adicionar imports no topo:
from src.memory.semantic_memory_layer import get_semantic_memory

# Dentro da classe de consci√™ncia, adicionar:
async def update_consciousness_cycle(self):
    # ... seu c√≥digo existente ...

    # NEW: Armazenar epis√≥dio em mem√≥ria sem√¢ntica
    semantic_memory = get_semantic_memory()

    episode_text = f"""
    Phi Value: {self.phi_current:.4f}
    Qualia Signature: {self.compute_qualia_signature()}
    Attention: {self.attention_distribution}
    Context: {self.current_context}
    """

    episode_data = {
        "phi_value": float(self.phi_current),
        "qualia_signature": self.compute_qualia_signature(),
        "timestamp": datetime.utcnow().isoformat(),
        "integration_level": float(self.integration_level)
    }

    # Armazenar (non-blocking)
    try:
        episode_id = semantic_memory.store_episode(
            episode_text=episode_text,
            episode_data=episode_data
        )
        logger.info(f"‚úÖ Epis√≥dio armazenado: {episode_id}")
    except Exception as e:
        logger.error(f"‚ùå Erro ao armazenar epis√≥dio: {e}")
```

---

## PARTE 1.5: PHASE 24 ‚Üí PHASE 25 BRIDGE (2025-12-05)

> **Status**: ‚úÖ Implementado & Testado
>
> **Objetivo**: Conectar explicitamente a sa√≠da da Phase 24 (trajet√≥ria de Œ¶) com a entrada da Phase 25 (c√°lculo h√≠brido qu√¢ntico).

### Componente: Œ¶-Trajectory Transformer

**Localiza√ß√£o**:
- `src/quantum_consciousness/phi_trajectory_transformer.py`
- `tests/quantum_consciousness/test_phi_trajectory_transformer.py`

**Funcionalidade**:
- L√™ trajet√≥ria de Œ¶ exportada por `scripts/export_phi_trajectory.py`
- Extrai features qu√¢nticas (sequ√™ncias de Œ¶, coer√™ncia, integra√ß√£o)
- Gera amplitudes qu√¢nticas normalizadas |œà‚ü©
- Valida dados num√©ricos (NaN/Inf, ranges)
- Exporta JSON pronto para Phase 25

**Como usar**:

```python
from src.quantum_consciousness.phi_trajectory_transformer import (
    PhiTrajectoryTransformer,
)

# 1. Transform Phase 24 trajectory to quantum features
transformer = PhiTrajectoryTransformer(
    trajectory_file=Path("data/test_reports/phi_trajectory_20251205_120000.json")
)
features = transformer.transform()

# 2. Export for Phase 25
output_path = transformer.save_features(features)
# ‚Üí exports/quantum_input_features.json ready
```

**Pipeline completo Phase 24 ‚Üí Phase 25**:

```python
from pathlib import Path
from src.quantum_consciousness.hybrid_phi_calculator import HybridPhiCalculator

# Op√ß√£o 1: Via JSON (recomendado para scripts)
result = await HybridPhiCalculator.from_phase24_json(
    "exports/quantum_input_features.json"
)
print(f"Hybrid Œ¶ fidelity: {result['fidelity']:.4f}")
print(f"Phase 24 Œ¶ mean: {result['phase24_phi_mean']:.4f}")

# Op√ß√£o 2: Direto via objeto (para integra√ß√£o em c√≥digo)
from src.quantum_consciousness.phi_trajectory_transformer import (
    PhiTrajectoryTransformer,
)

transformer = PhiTrajectoryTransformer()
features = transformer.transform()

calculator = HybridPhiCalculator()
result = await calculator.calculate_from_phase24_features(features)
```

**Features extra√≠das**:
- `phi_sequence`: Sequ√™ncia temporal de valores de Œ¶
- `phi_mean`, `phi_std`, `phi_trend`: Estat√≠sticas de Œ¶
- `coherence_sequence`: Sequ√™ncia de coer√™ncia de aten√ß√£o
- `integration_sequence`: Sequ√™ncia de n√≠vel de integra√ß√£o
- `quantum_amplitudes`: Amplitudes qu√¢nticas normalizadas [T, 2]
- `timestamps`, `episode_ids`: Metadados temporais

**Valida√ß√£o**:
- ‚úÖ Œ¶ values clipped to [0, 1]
- ‚úÖ Quantum amplitudes normalized (||œà|| = 1)
- ‚úÖ No NaN/Inf in output
- ‚úÖ Numerical stability checked
- ‚úÖ Type hints strict mode passing
- ‚úÖ 14 tests passing (coverage >90%)

**Nota sobre formato atual**:
- O export atual de Phase 24 (`scripts/export_phi_trajectory.py`) produz apenas `timestamp` e `phi_value`.
- O transformer funciona com esse formato m√≠nimo, mas est√° preparado para consumir campos adicionais (`attention_state`, `integration_level`, `episode_id`) quando o export for expandido.
- **TODO (Phase 24.x)**: Expandir `export_phi_trajectory.py` para incluir campos ricos. Ver `src/quantum_consciousness/phi_trajectory_transformer.py` linha ~20 para detalhes.

**Pr√≥ximo**: Phase 25 `HybridPhiCalculator` pode consumir `quantum_input_features.json` diretamente.

### Processamento Completo de Trajet√≥ria (2025-12-05) ‚úÖ

**Novo m√©todo**: `process_trajectory()` e `process_trajectory_from_json()`

**Funcionalidade**: Processa trajet√≥ria completa da Phase 24, calculando Œ¶ cl√°ssico, qu√¢ntico e h√≠brido para cada ponto temporal.

**Exemplo de uso**:

```python
from src.quantum_consciousness.hybrid_phi_calculator import HybridPhiCalculator

# Op√ß√£o 1: Via JSON (recomendado)
result = await HybridPhiCalculator.process_trajectory_from_json(
    "exports/quantum_input_features.json",
    blend_weight=0.6,  # 60% cl√°ssico, 40% qu√¢ntico
    use_real_hw=False
)

# Resultado cont√©m sequ√™ncias completas:
print(f"Trajet√≥ria processada: {result['trajectory_length']} pontos")
print(f"Œ¶ cl√°ssico m√©dio: {result['phi_classical_mean']:.4f}")
print(f"Œ¶ qu√¢ntico m√©dio: {result['phi_quantum_mean']:.4f}")
print(f"Œ¶ h√≠brido m√©dio: {result['phi_hybrid_mean']:.4f}")
print(f"Fidelidade m√©dia: {result['fidelity_mean']:.4f}")

# Sequ√™ncias temporais completas:
phi_hybrid_seq = result['phi_hybrid_sequence']  # [T,] array
fidelity_seq = result['fidelity_sequence']  # [T,] array

# Op√ß√£o 2: Direto via objeto
from src.quantum_consciousness.phi_trajectory_transformer import (
    PhiTrajectoryTransformer,
)

transformer = PhiTrajectoryTransformer()
features = transformer.transform()

calculator = HybridPhiCalculator()
result = await calculator.process_trajectory(
    features,
    blend_weight=0.5,  # 50% cl√°ssico, 50% qu√¢ntico
    use_real_hw=False
)
```

**M√©todos adicionais**:

```python
# Blend de Œ¶ cl√°ssico e qu√¢ntico
phi_hybrid = calculator.blend_phi(
    phi_classical=np.array([0.3, 0.4, 0.5]),
    phi_quantum=np.array([0.2, 0.3, 0.4]),
    blend_weight=0.6
)

# C√°lculo de fidelidade entre amplitudes
fidelity = calculator.calculate_fidelity(
    amp_classical=np.array([[0.7, 0.3], [0.6, 0.4]]),
    amp_quantum=np.array([[0.7+0.3j, 0.3+0.7j], [0.6+0.4j, 0.4+0.6j]])
)
```

**Valida√ß√£o**:
- ‚úÖ 6 novos testes passando (blend_phi, calculate_fidelity, process_trajectory)
- ‚úÖ Processamento de trajet√≥ria completa funcional
- ‚úÖ M√©todos de blend e fidelidade validados

---

## PARTE 2: PHASE 25 - QUANTUM CONSCIOUSNESS (2-3 dias)

### REQUISITOS

1. **IBM Quantum Token** (https://quantum.ibm.com/)
2. **Qiskit Runtime** instalado

```bash
pip install qiskit qiskit-ibm-runtime qiskit-aer
```

### ETAPA 1: SETUP IBM QUANTUM

```bash
# 1.1 Adicionar ao .env:
cat >> .env << 'EOF'
IBM_QUANTUM_TOKEN=your_token_here
HYBRID_PHI_MODE=simulator
HYBRID_PHI_FIDELITY_THRESHOLD=0.85
EOF

# 1.2 Testar conex√£o
python3 << 'PYEOF'
from qiskit_ibm_runtime import QiskitRuntimeService

try:
    QiskitRuntimeService.save_credentials(
        channel="ibm_quantum",
        token="your_token_here"
    )
    service = QiskitRuntimeService(channel="ibm_quantum")
    print("‚úÖ IBM Quantum configurado com sucesso")

    # Listar backends dispon√≠veis
    backends = service.backends()
    print(f"\n‚úÖ {len(backends)} backends dispon√≠veis:")
    for backend in backends:
        print(f"  - {backend.name}")

except Exception as e:
    print(f"‚ùå Erro: {e}")
PYEOF
```

### ETAPA 2: CRIAR `hybrid_phi_calculator.py`

**Arquivo**: `src/quantum_consciousness/hybrid_phi_calculator.py`

```python
"""Hybrid Classical-Quantum Phi Calculator - Phase 25"""

import logging
from typing import Any, Dict, Optional
import numpy as np

from src.consciousness.topological_phi import TopologicalPhiCalculator

try:
    from qiskit import QuantumCircuit, QuantumRegister
    from qiskit_aer import AerSimulator
    from qiskit_ibm_runtime import QiskitRuntimeService, Session
    QISKIT_AVAILABLE = True
except ImportError:
    QISKIT_AVAILABLE = False

logger = logging.getLogger(__name__)


class HybridPhiCalculator:
    """Calcula Œ¶ usando classical + quantum hybrid approach"""

    def __init__(self, use_real_hw: bool = False):

        if not QISKIT_AVAILABLE:
            raise ImportError("Qiskit n√£o instalado")

        self.classical_calc = TopologicalPhiCalculator()
        self.use_real_hw = use_real_hw

        # Configurar backend
        if use_real_hw:
            try:
                self.service = QiskitRuntimeService(channel="ibm_quantum")
                self.backend = self.service.least_busy(
                    simulator=False,
                    operational=True,
                    min_num_qubits=5
                )
                logger.info(f"‚úÖ Hardware IBM: {self.backend.name}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Hardware IBM n√£o dispon√≠vel: {e}, usando simulator")
                self.backend = AerSimulator()
        else:
            self.backend = AerSimulator()
            logger.info("‚úÖ Usando AerSimulator")

    def calculate_phi_hybrid(self,
                            states: np.ndarray,
                            use_real_hw: Optional[bool] = None) -> Dict[str, Any]:
        """
        Calcula Œ¶ com valida√ß√£o quantum

        Returns:
            {
                "phi_classical": float,
                "phi_quantum": float,
                "fidelity": float,
                "validation_passed": bool,
                "metadata": {...}
            }
        """

        use_hw = use_real_hw if use_real_hw is not None else self.use_real_hw

        logger.info("üî¢ Iniciando c√°lculo hybrid Œ¶...")

        # 1. CLASSICAL CALCULATION
        logger.info("üìä Calculando Œ¶ cl√°ssicamente...")
        phi_classical, _ = self.classical_calc.calculate(states)
        logger.info(f"‚úÖ Œ¶_classical = {phi_classical:.6f}")

        # 2. PREPARE QUANTUM CIRCUIT
        logger.info("‚öõÔ∏è  Preparando circuit qu√¢ntico...")
        circuit = self._prepare_quantum_circuit(states, num_qubits=5)

        # 3. EXECUTE QUANTUM
        logger.info("‚öôÔ∏è  Executando circuit...")
        results = self._execute_circuit(circuit, use_hw=use_hw)

        # 4. EXTRACT PHI
        phi_quantum = self._extract_phi_from_quantum(results)
        logger.info(f"‚úÖ Œ¶_quantum = {phi_quantum:.6f}")

        # 5. COMPUTE FIDELITY
        fidelity = self._compute_fidelity(phi_classical, phi_quantum)
        logger.info(f"üìà Fidelity = {fidelity:.6f}")

        return {
            "phi_classical": float(phi_classical),
            "phi_quantum": float(phi_quantum),
            "fidelity": float(fidelity),
            "validation_passed": fidelity > 0.85,
            "metadata": {
                "hardware": "ibm_quantum" if use_hw else "simulator",
                "quantum_backend": str(self.backend.name) if hasattr(self.backend, 'name') else "local"
            }
        }

    def _prepare_quantum_circuit(self, states: np.ndarray, num_qubits: int = 5) -> QuantumCircuit:
        """Prepara circuit qu√¢ntico"""
        circuit = QuantumCircuit(num_qubits, num_qubits)

        # Criar superposition
        for i in range(num_qubits):
            circuit.h(i)

        # Aplicar entanglement (CNOTs)
        for i in range(num_qubits - 1):
            circuit.cx(i, i + 1)

        # Medi√ß√£o
        circuit.measure(range(num_qubits), range(num_qubits))

        return circuit

    def _execute_circuit(self, circuit: QuantumCircuit, use_hw: bool = False) -> Dict:
        """Executa circuit"""
        try:
            if use_hw and hasattr(self.service, 'run'):
                # IBM Hardware
                with Session(service=self.service, backend=self.backend) as session:
                    job = session.run(circuit, shots=1024)
                    result = job.result()
            else:
                # Simulator
                job = self.backend.run(circuit, shots=1024)
                result = job.result()

            return result.get_counts()

        except Exception as e:
            logger.error(f"‚ùå Erro ao executar: {e}")
            return {}

    def _extract_phi_from_quantum(self, counts: Dict) -> float:
        """Extrai valor de Œ¶ dos resultados"""
        if not counts:
            return 0.0

        # Calcular entropia Shannon como proxy para Œ¶
        total = sum(counts.values())
        probabilities = [count / total for count in counts.values()]

        entropy = -sum(p * np.log2(p + 1e-10) for p in probabilities)
        num_qubits = len(list(counts.keys())[0]) if counts else 1
        max_entropy = num_qubits

        # Normalizar para [0, 1]
        phi = entropy / max_entropy if max_entropy > 0 else 0

        return float(phi)

    def _compute_fidelity(self, phi_c: float, phi_q: float) -> float:
        """Computa fidelity entre cl√°ssico e quantum"""
        if phi_c == 0 and phi_q == 0:
            return 1.0

        # Usar como m√©trica de similarity
        difference = abs(phi_c - phi_q)
        fidelity = 1.0 - difference

        return float(np.clip(fidelity, 0, 1))


# Singleton
_hybrid_phi_instance: Optional[HybridPhiCalculator] = None

def get_hybrid_phi_calculator(use_real_hw: bool = False) -> HybridPhiCalculator:
    """Retorna inst√¢ncia singleton"""
    global _hybrid_phi_instance
    if _hybrid_phi_instance is None:
        _hybrid_phi_instance = HybridPhiCalculator(use_real_hw=use_real_hw)
    return _hybrid_phi_instance
```

---

### ETAPA 3: TESTES PHASE 25

**Arquivo**: `tests/quantum_consciousness/test_hybrid_phi.py`

```python
"""Testes para Phase 25 - Hybrid Phi Calculator"""

import pytest
import numpy as np
from src.quantum_consciousness.hybrid_phi_calculator import HybridPhiCalculator


@pytest.fixture
def hybrid_calculator():
    """Fixture para HybridPhiCalculator"""
    return HybridPhiCalculator(use_real_hw=False)


@pytest.mark.quantum
class TestHybridPhiCalculator:

    def test_classical_phi_calculation(self, hybrid_calculator):
        """Testa c√°lculo cl√°ssico de Œ¶"""
        states = np.random.randn(10, 10)
        result = hybrid_calculator.calculate_phi_hybrid(states, use_real_hw=False)

        assert "phi_classical" in result
        assert 0 <= result["phi_classical"] <= 1
        logger.info(f"‚úÖ Œ¶_classical = {result['phi_classical']:.6f}")

    def test_quantum_phi_calculation(self, hybrid_calculator):
        """Testa c√°lculo quantum (simulator)"""
        states = np.random.randn(10, 10)
        result = hybrid_calculator.calculate_phi_hybrid(states, use_real_hw=False)

        assert "phi_quantum" in result
        assert 0 <= result["phi_quantum"] <= 1
        logger.info(f"‚úÖ Œ¶_quantum = {result['phi_quantum']:.6f}")

    def test_fidelity_calculation(self, hybrid_calculator):
        """Testa c√°lculo de fidelity"""
        states = np.random.randn(10, 10)
        result = hybrid_calculator.calculate_phi_hybrid(states, use_real_hw=False)

        assert "fidelity" in result
        assert 0 <= result["fidelity"] <= 1
        assert result["validation_passed"] == (result["fidelity"] > 0.85)
        logger.info(f"‚úÖ Fidelity = {result['fidelity']:.6f}")

    @pytest.mark.skipif(True, reason="Requires IBM Quantum token")
    def test_real_hardware_phi(self, hybrid_calculator):
        """Testa em hardware IBM real (skip por padr√£o)"""
        states = np.random.randn(10, 10)
        result = hybrid_calculator.calculate_phi_hybrid(states, use_real_hw=True)

        assert result["fidelity"] > 0.5  # Hardware tem mais ru√≠do


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
```

**Executar**:

```bash
cd /home/fahbrain/projects/omnimind
pytest tests/quantum_consciousness/test_hybrid_phi.py -v
```

---

## ‚úÖ CHECKLIST FINAL

### Phase 24
- [ ] Qdrant rodando (docker-compose)
- [ ] `qdrant_integration.py` criado e testado
- [ ] `semantic_memory_layer.py` criado e testado
- [ ] Testes passando (pytest tests/memory/)
- [ ] Integra√ß√£o em `consciousness_metrics.py`
- [ ] Suite r√°pida passando

### Phase 25
- [ ] IBM Quantum token configurado
- [ ] `hybrid_phi_calculator.py` criado
- [ ] Testes com simulator passando
- [ ] (Opcional) Testes com IBM hardware
- [ ] Documenta√ß√£o completa

---

## üöÄ PR√ìXIMO PASSO

Qual etapa voc√™ quer come√ßar?

A. **Phase 24 Setup** - Come√ßar com Qdrant + Semantic Memory
B. **Phase 25 Setup** - Come√ßar com Quantum + IBM integration
C. **Ambas em paralelo** - Setup completo

Responda e passo para a implementa√ß√£o detalhada!
