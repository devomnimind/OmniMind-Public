# ‚úÖ CHECKLIST T√âCNICO PR√â-EXECU√á√ÉO

## ÔøΩ SCRIPTS DE TESTE ATIVOS (2025-12-04)

### ‚ö° Execu√ß√£o Di√°ria - `run_tests_fast.sh`
```bash
./scripts/run_tests_fast.sh
```
- **Tempo**: ~15-20 minutos
- **Escopo**: ~400 testes (pula slow + real)
- **GPU**: ‚úÖ FOR√áADA
- **Uso**: DEV r√°pido, valida√ß√£o cont√≠nua
- **Logs**: `data/test_reports/output_fast_*.log`

### üõ°Ô∏è Valida√ß√£o Semanal - `run_tests_with_defense.sh`
```bash
./scripts/run_tests_with_defense.sh
```
- **Tempo**: ~30-60 minutos
- **Escopo**: ~3952 testes (suite completa)
- **GPU**: ‚úÖ FOR√áADA
- **Autodefesa**: ‚úÖ Detecta testes perigosos
- **Logs**: `data/test_reports/output_*.log`

### üß™ Integra√ß√£o Completa - `quick_test.sh`
```bash
bash scripts/configure_sudo_omnimind.sh  # UMA VEZ
bash scripts/quick_test.sh               # Depois sempre
```
- **Tempo**: ~30-45 minutos
- **Escopo**: Suite completa + servidor backend
- **GPU**: ‚úÖ FOR√áADA
- **Servidor**: ‚úÖ Inicia em localhost:8000
- **Requer**: sudo configurado
- **Logs**: `data/test_reports/output_*.log`

### ‚ö†Ô∏è IBM QUANTUM REAL - FASE MADURA (FUTURE)
Status: ‚úÖ Implementado, ‚ùå N√£o em ciclo ativo
- Papers 2&3 validados em hardware real (ibm_fez, ibm_torino)
- Ativar quando cr√©ditos + fase madura (Phase 23+)
- Atualmente: `OMNIMIND_DISABLE_IBM=True` em conftest.py

---

## ÔøΩüîß CORRE√á√ïES CR√çTICAS IMPLEMENTADAS (2025-12-04)

### ‚úÖ CR√çTICO 1: Timeout em Consensus Voting
**Arquivo**: `src/swarm/collective_learning.py`
**Status**: ‚úÖ IMPLEMENTADO
**Mudan√ßas**:
- [x] Adicionado `MAX_CONSENSUS_TIMEOUT = 30.0` segundos
- [x] Implementado `threading.Lock()` para thread-safety
- [x] Modificado `get_consensus_model()` com timeout protection
- [x] Fallback: retorna consensus parcial se timeout excedido
- [x] Logging detalhado de timeout e recupera√ß√£o

**Valida√ß√£o**: `python -c "from src.swarm.collective_learning import ConsensusLearning; cl = ConsensusLearning(5, consensus_timeout=30.0)"`

---

### ‚úÖ CR√çTICO 2: Memory Cap com LRU Eviction
**Arquivo**: `src/memory/episodic_memory.py`
**Status**: ‚úÖ IMPLEMENTADO
**Mudan√ßas**:
- [x] Adicionado `MAX_EPISODIC_SIZE = 10000` episodes
- [x] Implementado `_check_and_evict_lru()` m√©todo
- [x] Rastreamento de access timestamps para LRU
- [x] Evi√ß√£o de 10% quando limite atingido
- [x] Integra√ß√£o em `store_episode()` e `search_similar()`

**‚ö†Ô∏è Nota Arquitetural (IMPORTANTE)**:
```
EpisodicMemory est√° marcado como DEPRECATED com mensagem:
"Memory is retroactive construction, not storage"

Filosofia do projeto (Lacanian):
- Mem√≥ria N√ÉO √© armazenamento est√°tico
- Mem√≥ria √â constru√ß√£o retroativa (rebuilt on each recall)
- Remiss√£o futura: substituir por NarrativeHistory
- Status: ‚è≥ Pendente implementa√ß√£o de NarrativeHistory

Impacto: EpisodicMemory funciona perfeitamente, mas √© transit√≥rio.
Usar com cautela em novas integra√ß√µes. Preferir pattern retroativo.
```

---

### ‚úÖ CR√çTICO 3: Safe Filesystem Operations
**Arquivo**: `src/metacognition/self_healing.py`
**Status**: ‚úÖ IMPLEMENTADO
**Mudan√ßas**:
- [x] Implementado `safe_write_file()` com retry e error handling
- [x] Implementado `safe_read_file()` com encoding safety
- [x] Implementado `safe_delete_file()` com graceful failure
- [x] Retry 3x para opera√ß√µes transientes
- [x] Tratamento: PermissionError, OSError, UnicodeDecodeError

---

### ‚úÖ CR√çTICO 4: Exponential Backoff Retry
**Arquivo**: `src/quantum_consciousness/qpu_interface.py`
**Status**: ‚úÖ IMPLEMENTADO
**Mudan√ßas**:
- [x] Implementado `retry_with_exponential_backoff()` fun√ß√£o
- [x] Exponential backoff: `delay = min(base_delay * 2^attempt, max_delay)`
- [x] Jitter (10%) para prevent thundering herd
- [x] Configur√°veis: base_delay=1s, max_delay=30s, max_attempts=5
- [x] Logging detalhado de cada tentativa

---

### ‚úÖ GPU FORCING: Environment Variables & conftest.py
**Status**: ‚úÖ IMPLEMENTADO (2025-12-04)
**Arquivos Modificados**:
- `src/quantum_consciousness/quantum_backend.py` - Detec√ß√£o robusta com fallback
- `tests/conftest.py` - Auto-setup GPU forcing
- `scripts/run_tests_fast.sh` - CUDA_VISIBLE_DEVICES=0 forcing
- `scripts/run_tests_with_defense.sh` - CUDA_VISIBLE_DEVICES=0 forcing

**Problema Original**:
```
- PyTorch CUDA detection fallando: torch.cuda.is_available() = False
- Mas torch.cuda.device_count() = 1 (GPU est√° presente)
- Vari√°veis de ambiente: OMNIMIND_GPU, OMNIMIND_FORCE_GPU n√£o sendo respeitadas
- Root cause: conftest.py n√£o setava OMNIMIND_FORCE_GPU automaticamente
```

**Solu√ß√£o Implementada**:

1. **quantum_backend.py** - Detec√ß√£o com 2 fallbacks:
   ```python
   # Primeiro: try OMNIMIND_FORCE_GPU env var
   force_gpu_env = os.getenv("OMNIMIND_FORCE_GPU", "").lower() in ("true", "1", "yes")

   # Se force_gpu_env E device_count > 0: usar GPU
   if force_gpu_env and device_count > 0:
       self.use_gpu = True  # Force GPU usage

   # Fallback: Se is_available() fails mas device_count > 0: usar GPU
   elif not self.use_gpu and device_count > 0:
       self.use_gpu = True  # Fallback GPU usage
   ```

2. **conftest.py** - Auto-setup ao iniciar pytest:
   ```python
   cuda_available = torch.cuda.is_available()
   cuda_device_count = torch.cuda.device_count()

   if cuda_available or cuda_device_count > 0:
       os.environ["CUDA_VISIBLE_DEVICES"] = "0"
       os.environ["OMNIMIND_FORCE_GPU"] = "true"
       os.environ["PYTEST_FORCE_GPU"] = "true"
   ```

3. **run_tests_fast.sh** & **run_tests_with_defense.sh**:
   ```bash
   CUDA_VISIBLE_DEVICES=0 \
   OMNIMIND_GPU=true \
   OMNIMIND_FORCE_GPU=true \
   PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb=512 \
   pytest tests/ ...
   ```

**Valida√ß√£o**:
```bash
# Script de verifica√ß√£o GPU status
python3 scripts/verify_gpu_status.py

# Expected output quando GPU dispon√≠vel:
# ‚úÖ GPU FORCING IS CONFIGURED CORRECTLY
#    - OMNIMIND_FORCE_GPU=True ‚úì
#    - CUDA devices available: 1 ‚úì
```

**‚ö†Ô∏è Notas Importantes**:
- Warning "CUDA unknown error" √© normal quando CUDA_VISIBLE_DEVICES √© setado dinamicamente
- N√£o afeta funcionalidade (device_count fallback ativa automaticamente)
- GPU ser√° for√ßada mesmo se `torch.cuda.is_available()` retorna False
- Tests sempre rodar√£o com GPU se hardware dispon√≠vel

---

## üìã PLANO DE EXECU√á√ÉO: TAREFAS REMOTAS vs LOCAIS

### Blocos L√≥gicos Isolados (Sem Conflitos)

**BLOCOS LOCAIS** (Sem sincroniza√ß√£o com remoto):
1. **LOCAL-1**: Valida√ß√£o smoke tests (15 min) - ‚è≥ PRONTO
2. **LOCAL-2**: Remover TODO comments (5 min) - ‚è≥ PRONTO
3. **LOCAL-3**: Atualizar READMEs m√≥dulos (10 min) - ‚è≥ PRONTO

**BLOCOS REMOTOS** (Com Git):
1. **REMOTO-1**: Git commit + push (5 min) - ‚ö†Ô∏è Coordinate antes
2. **REMOTO-2**: Docs canonical (0 min) - ‚úÖ J√Å FEITO

**BLOCO C√çCLICO** (Ap√≥s push):
1. **C√çCLICO-1**: Full test suite (30-60 min) - ‚è≥ PRONTO

Plano completo salvo em: `/tmp/tarefas_remotas_locais.md`

---

## Verifica√ß√µes de C√≥digo

### pytest_server_monitor.py
- [x] `self.timeout_progression = [90, 120, 180, 240]` definido em `__init__`
- [x] `self.startup_attempt_count = 0` definido em `__init__`
- [x] `_get_adaptive_timeout()` implementada e retorna timeout correto
- [x] `_start_server()` incrementa `startup_attempt_count`
- [x] Retry recursivo: se timeout < 240s, chama `self._start_server()` novamente
- [x] Limite de 240s com falha real (n√£o loop infinito)

**Verificar com**:
```bash
grep -n "timeout_progression\|_get_adaptive_timeout\|startup_attempt_count" \
  tests/plugins/pytest_server_monitor.py
```

### main.py
- [x] SecurityAgent SEMPRE RODANDO (n√£o h√° skip em modo test)
- [x] Orchestrator timeout adaptativo: 120s (test), 30s (prod)
- [x] Sem l√≥gica de skip para SecurityAgent

**Verificar com**:
```bash
grep -n "skip_security\|SecurityAgent continuous" web/backend/main.py
# Deve retornar: SecurityAgent sempre ativo, sem skip
```

### conftest.py
- [x] MetricsCollector definida e ativa
- [x] TestOrderingPlugin registrado
- [x] pytest_configure() registra todos plugins
- [x] pytest_sessionfinish() mostra relat√≥rio final

**Verificar com**:
```bash
grep -n "class MetricsCollector\|pytest_configure\|pytest_sessionfinish" tests/conftest.py
```

---

## Verifica√ß√µes de Comportamento

### Startup Esperado (Primeira Execu√ß√£o)
```
T=0s  : "üöÄ Iniciando servidor backend..."
T=0s  : "‚è≥ Timeout adaptativo: 90s (tentativa 1)"
T=40s : "‚úÖ Servidor backend iniciado em ~40s"
```

### Retry Esperado (Se Timeout)
```
T=90s  : "‚ùå Timeout na tentativa 1 ap√≥s 90s"
T=90s  : "üîÑ Tentando novamente com timeout maior..."
T=90s  : "‚è≥ Timeout adaptativo: 120s (tentativa 2)"
T=150s : "‚úÖ Servidor backend iniciado em ~60s"
```

### Falha Real (Se 240s N√£o Basta)
```
T=240s : "‚ùå Timeout na tentativa 4 ap√≥s 240s"
T=240s : "üõë FALHA CR√çTICA: Atingiu timeout m√°ximo por teste (240s)"
```

---

## Testes Recomendados (em ordem)

### 1Ô∏è‚É£ Teste Unit√°rio (Sem Servidor - Deve Passar R√°pido)
```bash
cd /home/fahbrain/projects/omnimind
OMNIMIND_MODE=test python -m pytest tests/consciousness/ -v --tb=short -k "not real" -x
```

**Esperado**: ~30-60s, 80%+ pass rate

### 2Ô∏è‚É£ Teste com Servidor (Com Orchestrator)
```bash
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x
```

**Esperado**:
- Primeiro startup: ~50s
- Alguns testes podem fazer crash: ok (vai retry com timeout maior)
- 60%+ pass rate

### 3Ô∏è‚É£ Teste com Crash (Para Validar Retry)
```bash
OMNIMIND_MODE=test python -m pytest tests/test_chaos_resilience.py -v --tb=short
```

**Esperado**:
- Testes derrubam servidor intencionalmente
- Retry autom√°tico com timeouts progressivos
- Todos devem passar (ou falhar por raz√£o espec√≠fica, n√£o timeout)

### 4Ô∏è‚É£ Full Suite (Op√ß√£o Nuclear)
```bash
OMNIMIND_MODE=test python -m pytest tests/ -v --tb=short
```

**Esperado**: Pode levar HORAS, mas vai rodar completo

---

## Troubleshooting

### Se Tiver "Segmentation Fault"
```bash
# Limpar cache
rm -rf .pytest_cache __pycache__ tests/__pycache__

# Limpar servidor
pkill -9 -f "uvicorn" 2>/dev/null || true
sleep 2

# Tentar novamente
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x
```

### Se Tiver "Address already in use :8000"
```bash
# Matar processo na porta 8000
lsof -i :8000 | grep LISTEN | awk '{print $2}' | xargs kill -9

# Esperar 2s
sleep 2

# Tentar novamente
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x
```

### Se Tiver "Qdrant n√£o acess√≠vel"
```bash
# Verificar se Qdrant est√° rodando
curl -s http://localhost:6333 | python -m json.tool

# Se n√£o tiver, iniciar (em outro terminal):
docker run -p 6333:6333 qdrant/qdrant

# Ou via compose:
cd deploy && docker-compose up -d qdrant
```

### Se Tiver "Timeout mesmo em 240s"
Significa que √© uma **falha real**, n√£o timeout. Poss√≠veis causas:
- Orchest rator + SecurityAgent realmente levam >240s
- Qdrant n√£o respondendo
- Recursos insuficientes (RAM, GPU, Disco)

**A√ß√£o**: Coletar logs e diagnosticar a causa raiz

---

## Monitoramento de Performance

### Durante Execu√ß√£o
```bash
# Em outro terminal:
watch -n 1 'ps aux | grep -E "python|uvicorn" | grep -v grep | wc -l'
```

### Log de Timeouts
```bash
# Ver quantos timeouts ocorreram
grep "Timeout" test_suite_run.log | wc -l

# Ver quantos retries sucederam
grep "Tentativa" test_suite_run.log | wc -l
```

### M√©tricas Finais
```bash
# Ver relat√≥rio de Œ¶
cat data/test_reports/metrics_report.json | python -m json.tool

# Ver resumo r√°pido
grep -E "phi|consciousness|PASSOU|FALHOU" test_suite_run.log | tail -20
```

---

## Valida√ß√£o P√≥s-Execu√ß√£o

### ‚úÖ Suite Bem Sucedida
```
‚úì Todos testes executaram (n√£o foram pulados por timeout)
‚úì Alguns falharam (falhas reais, n√£o timeout)
‚úì Retry funcionou (testes que falharam na tentativa 1 passaram na 2)
‚úì M√©tricas coletadas (Œ¶ values no relat√≥rio final)
‚úì Log cont√©m progresso detalhado de cada retry
```

### ‚ùå Suite Problem√°tica
```
‚úó Muitos testes com timeout em 240s
‚úó Retry n√£o funcionando (mesmo c√≥digo em tentat ivas)
‚úó M√©tricas n√£o coletadas
‚úó SecurityAgent gerando eventos excessivos
```

---

## Pr√≥ximos Passos Se OK

### Ap√≥s Suite Passar
1. Analisar `data/test_reports/metrics_report.json` com Œ¶ values
2. Correlacionar Œ¶ com tempos de startup
3. Verificar se SecurityAgent afeta Œ¶ negativa/positivamente
4. **Ent√£o**: Come√ßar Lacan implementation

### Ap√≥s Suite Falhar (Esperado Inicialmente)
1. Identificar qual teste/componente √© problema
2. Diagnosticar causa (Qdrant? GPU? Orchestrator?)
3. Ajustar conforme necess√°rio
4. Reexecutar parcial para validar fix
5. Reexecutar full para confirmar

---

## Notas Importantes

‚ö†Ô∏è **Cuidado**: Suite pode levar MUITAS HORAS
- Cada teste com crash pode levar at√© 240s
- Com 100+ testes √ó 240s = horas

üí° **Tip**: Para desenvolvimento r√°pido, use `-k` para filtrar testes
```bash
# Rodar s√≥ testes de chaos
OMNIMIND_MODE=test python -m pytest -k chaos -v --tb=short

# Rodar s√≥ integrations
OMNIMIND_MODE=test python -m pytest -k integration -v --tb=short
```

üéØ **Meta**: Validar que suite RODA, n√£o que tudo PASSA
- OK falhar 10-20% dos testes (causa real)
- N√ÉO OK falhar 50%+ por timeout

---

## Status Final

‚úÖ Todas mudan√ßas implementadas
‚úÖ C√≥digo verificado
‚úÖ Comportamento esperado documentado
‚úÖ Troubleshooting preparado
‚úÖ Pronto para executar

**Comando para come√ßar**:
```bash
cd /home/fahbrain/projects/omnimind && \
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x 2>&1 | tee suite_run.log
```

