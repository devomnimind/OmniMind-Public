# ğŸ¤– TASK: Corrigir 25 Falhas de Teste + Aumentar Cobertura para 90%

**Status:** ğŸŸ¡ BLOQUEANTE | **Prioridade:** ğŸ”´ CRÃTICA  
**Estimativa:** 6-8 horas | **Deadline:** Hoje  
**Assignee:** Copilot Remote Agent

---

## ğŸ“Š SITUAÃ‡ÃƒO ATUAL

```
âœ… Testes Passando:      2489 (99.01%)
âŒ Testes Falhando:      25 (0.99%) â† BLOQUEANTE
ğŸ“ˆ Cobertura:            79% (meta: 90%)
â±ï¸  Tempo Suite:          770 segundos
```

**25 Falhas em 3 MÃ³dulos:**
- `security/test_security_monitor.py`: 12 falhas (interface mismatch)
- `tools/test_omnimind_tools.py`: 11 falhas (type/signature mismatch)
- `test_audit.py`: 2 falhas (missing exports)

---

## âœ… PRÃ‰-REQUISITOS (Executar ANTES de comeÃ§ar)

### 1. Validar Ambiente
```bash
python --version  # Deve ser 3.12.8
pytest --version  # Deve ser instalado
mypy --version    # Deve ser instalado
cd /home/fahbrain/projects/omnimind
pwd  # Confirmar que estÃ¡ na raiz
```

### 2. Revisar DocumentaÃ§Ã£o de ReferÃªncia
- **Arquivo:** `data/test_reports/FAILURES_DETAILED_ANALYSIS.md`
  - SeÃ§Ã£o: "Cada falha analisada em detalho"
  - ContÃ©m: Causa raiz, tipo de fix, exemplos de cÃ³digo

- **Arquivo:** `data/test_reports/COVERAGE_ANALYSIS.md`
  - SeÃ§Ã£o: "24 mÃ³dulos com <60% cobertura"
  - Foco: MÃ³dulos crÃ­ticos

### 3. Entender a Estrutura
```
src/
â”œâ”€â”€ audit/              â† Falhas: missing exports
â”œâ”€â”€ security/           â† Falhas: interface SecurityMonitor (12)
â”‚   â””â”€â”€ security_monitor.py
â”œâ”€â”€ tools/              â† Falhas: type/signature mismatch (11)
â”‚   â””â”€â”€ omnimind_tools.py
â””â”€â”€ [outros mÃ³dulos]

tests/
â”œâ”€â”€ test_audit.py       â† 2 falhas
â”œâ”€â”€ security/
â”‚   â””â”€â”€ test_security_monitor.py  â† 12 falhas
â””â”€â”€ tools/
    â””â”€â”€ test_omnimind_tools.py    â† 11 falhas
```

---

## ğŸ¯ TAREFAS PRINCIPAIS

### FASE 1: Corrigir 25 Falhas (Bloqueante)

#### 1.1 Audit Exports (30 minutos) â†’ +2 testes
**Arquivo:** `src/audit/__init__.py`

**Checklist:**
- [ ] Verificar se `ImmutableAuditSystem` Ã© importado
- [ ] Verificar se `get_audit_system` Ã© importado
- [ ] Adicionar ambos ao `__all__`
- [ ] Executar: `pytest tests/test_audit.py::TestModuleInterface -v`
- [ ] Esperado: 2 PASSED

**ValidaÃ§Ã£o:**
```bash
# Antes
python -c "from audit import ImmutableAuditSystem"  # Deve falhar

# Depois
python -c "from audit import ImmutableAuditSystem"  # Deve passar
python -c "from audit import get_audit_system"      # Deve passar
```

---

#### 1.2 Tools Signatures (1-1.5 horas) â†’ +11 testes
**Arquivo Principal:** `src/tools/omnimind_tools.py`

**AnÃ¡lise NecessÃ¡ria:**
- [ ] Revisar assinatura de cada mÃ©todo `execute()`
- [ ] Mapear parÃ¢metros reais vs esperados nos testes
- [ ] Mapear tipos de retorno

**Falhas Conhecidas:**
```python
# Problema 1: ArgumentError mismatch
# âŒ Teste chama: tool.execute(task="...")
# âœ… Deve ser:   tool.execute(description="...")
# Archivos: PlanTaskTool, NewTaskTool

# Problema 2: ArgumentError mismatch
# âŒ Teste chama: tool.execute(content="...")
# âœ… Deve ser:   tool.execute(data="...")
# Arquivo: EpisodicMemoryTool

# Problema 3: Return type mismatch
# âŒ Teste espera: str (resultado de comando)
# âœ… Retorna:      dict {'stdout': '...', 'stderr': '...', 'return_code': 0}
# Arquivo: ExecuteCommandTool
```

**Checklist:**
- [ ] Ler `FAILURES_DETAILED_ANALYSIS.md` SeÃ§Ã£o 2 (11 falhas detalhadas)
- [ ] Documentar cada assinatura real (executar no Python interativo)
- [ ] Atualizar testes para corresponder
- [ ] Executar: `pytest tests/tools/test_omnimind_tools.py -v`
- [ ] Esperado: 12 PASSED (dos 12 testes, 11 relacionados a tools)

**ValidaÃ§Ã£o:**
```bash
# Rodar testes especÃ­ficos
pytest tests/tools/test_omnimind_tools.py::TestWriteFileTool -v
pytest tests/tools/test_omnimind_tools.py::TestExecuteCommandTool -v
pytest tests/tools/test_omnimind_tools.py::TestPlanTaskTool -v
pytest tests/tools/test_omnimind_tools.py::TestEpisodicMemoryTool -v
pytest tests/tools/test_omnimind_tools.py::TestAuditSecurityTool -v
```

---

#### 1.3 SecurityMonitor Interface (1-1.5 horas) â†’ +12 testes
**Arquivo Principal:** `src/security/security_monitor.py`

**AnÃ¡lise NecessÃ¡ria:**
- [ ] Identificar quais mÃ©todos sÃ£o privados (_method_name)
- [ ] Identificar quais mÃ©todos sÃ£o pÃºblicos (method_name)
- [ ] Decidir: Expor como pÃºblico ou criar wrappers?

**Falhas Conhecidas:**
```python
# Problema 1: MÃ©todos privados mas testes chamam como pÃºblicos
# Privados encontrados:
#   - _is_suspicious_process
#   - _handle_security_event
#   - _monitor_system_resources
# Testes esperam: is_suspicious_process, create_security_event, monitor_system_resources

# Problema 2: Assertion rÃ­gida
# âŒ assert monitor.suspicious_processes == set()
# âœ… Precisa: assert isinstance(monitor.suspicious_processes, set)
# âœ… Porque: constructor carrega processos conhecidos
```

**Checklist:**
- [ ] Ler `FAILURES_DETAILED_ANALYSIS.md` SeÃ§Ã£o 1 (12 falhas detalhadas)
- [ ] Revisar `src/security/security_monitor.py` linha por linha
- [ ] Documentar interface pÃºblica vs privada
- [ ] DecisÃ£o 1: Expor mÃ©todos privados como pÃºblicos? (criar wrappers)
- [ ] DecisÃ£o 2: Alterar testes para usar interface privada corretamente?
- [ ] Implementar escolha
- [ ] Executar: `pytest tests/security/test_security_monitor.py -v`
- [ ] Esperado: 12 PASSED

**ValidaÃ§Ã£o:**
```bash
# Rodar todos os testes do mÃ³dulo
pytest tests/security/test_security_monitor.py -v

# Rodar testes especÃ­ficos
pytest tests/security/test_security_monitor.py::TestSecurityMonitor -v
pytest tests/security/test_security_monitor.py::TestSecurityMonitorEdgeCases -v
```

---

### FASE 2: ValidaÃ§Ã£o das CorreÃ§Ãµes

**Checklist:**
- [ ] Executar suite completa
  ```bash
  pytest tests/ -v --tb=short
  # Esperado: 2514 PASSED, 0 FAILED
  ```

- [ ] Verificar cobertura
  ```bash
  pytest tests/ --cov=src --cov-report=term-missing --cov-fail-under=80
  # Esperado: â‰¥ 80% (deve passar)
  ```

- [ ] Verificar lint
  ```bash
  black --check src/ tests/
  flake8 src/ tests/ --max-line-length=100
  ```

- [ ] Verificar type hints
  ```bash
  mypy src/ --ignore-missing-imports
  ```

---

### FASE 3: Aumentar Cobertura de 79% para 90%

**EstratÃ©gia:**

1. **Identificar MÃ³dulos CrÃ­ticos <60%**
   ```bash
   # Usar: data/test_reports/COVERAGE_ANALYSIS.md
   # Focar em mÃ³dulos de business logic (nÃ£o __init__.py)
   # Prioridade:
   #   1. security/security_monitor (30% â†’ 85%+)
   #   2. tools/* (se houver gaps)
   #   3. Outros mÃ³dulos crÃ­ticos
   ```

2. **Para Cada MÃ³dulo <60%:**
   - [ ] Analisar linhas nÃ£o cobertas (ver htmlcov/index.html)
   - [ ] Criar testes para casos faltantes
   - [ ] Testar condiÃ§Ãµes extremas (None, '', 0, [], etc.)
   - [ ] Testar paths de erro (try/except)
   - [ ] Garantir compatibilidade com testes existentes

3. **Estrutura de Novo Teste:**
   ```python
   # PadrÃ£o obrigatÃ³rio:
   # âœ… Use pytest.approx() para float
   # âœ… Use pytest.mark.asyncio para async
   # âœ… Use fixtures para setup/teardown
   # âœ… Mock dependÃªncias externas
   # âœ… Type hints em todas as funÃ§Ãµes
   # âœ… Docstring Google-style
   ```

4. **Validar Conforme AvanÃ§a:**
   ```bash
   pytest tests/ --cov=src --cov-report=html
   # Abrir: htmlcov/index.html no navegador
   # Procurar por linhas vermelhas (nÃ£o cobertas)
   ```

5. **Meta Final:**
   ```bash
   pytest tests/ --cov=src --cov-report=term-missing --cov-fail-under=90
   # Esperado: PASSED (90%+ cobertura)
   ```

---

## ğŸ” VERIFICAÃ‡Ã•ES CRÃTICAS ANTES DE CADA COMMIT

### 1. Compatibilidade com Testes Existentes
```bash
# Rodar toda a suite
pytest tests/ -v

# Se falhar, analisar:
# - Seus testes novos quebram testes antigos?
# - HÃ¡ conflito de fixtures?
# - HÃ¡ side effects nÃ£o isolados?
```

### 2. Type Hints 100%
```bash
# Verificar seu arquivo novo
mypy src/meu_arquivo.py

# Sem erros!
```

### 3. Lint Clean
```bash
black src/
flake8 src/ --max-line-length=100

# Sem erros!
```

### 4. Docstrings Completas
- [ ] Toda funÃ§Ã£o tem docstring
- [ ] Docstring inclui: resumo, args, returns, raises
- [ ] Formato: Google-style

### 5. Dados Reais, NÃ£o Mocks
- [ ] Testes de security usam dados reais de processos? (NÃƒO - use mocks!)
- [ ] Testes de tools usam os commands reais? (SIM - ou use mock para seguranÃ§a)
- [ ] Se mock, estÃ¡ bem documentado?

---

## ğŸ“‹ CHECKLIST FINAL (Antes de submeter)

### Fase 1: Corrigir 25 Falhas
- [ ] Audit exports adicionados
- [ ] Tools signatures sincronizadas
- [ ] SecurityMonitor interface resolvida
- [ ] `pytest tests/ -v` â†’ 2514 PASSED

### Fase 2: ValidaÃ§Ã£o
- [ ] `black src/ tests/` â†’ PASSED
- [ ] `flake8 src/ tests/` â†’ PASSED
- [ ] `mypy src/` â†’ PASSED
- [ ] Cobertura â‰¥ 80% (obrigatÃ³rio)

### Fase 3: Aumentar Cobertura 90%
- [ ] Novos testes criados
- [ ] Cobertura â‰¥ 90%
- [ ] Testes compatÃ­veis com existentes
- [ ] Sem regressions

### SubmissÃ£o
- [ ] Todos os checks PASSED
- [ ] Pronto para produÃ§Ã£o

---

## âš ï¸ ARMADILHAS COMUNS (Evitar)

| Armadilha | Como Evitar |
|-----------|------------|
| Type mismatch | Use mypy strict |
| Testes isolados falhando | Rodar suite completa, nÃ£o testes individuais |
| Dados mock invÃ¡lidos | Usar fixtures pytest, documentar |
| Sem tratamento de erro | Try/except obrigatÃ³rio em produÃ§Ã£o |
| Imports circulares | Verificar antes de commitar |
| Hard-coded values | Usar variÃ¡veis de ambiente, config files |

---

## ğŸ“ REFERÃŠNCIAS

- Detalhes de cada falha: `data/test_reports/FAILURES_DETAILED_ANALYSIS.md`
- Cobertura por mÃ³dulo: `data/test_reports/COVERAGE_ANALYSIS.md`
- Log completo: `data/test_reports/pytest_output.log`
- RelatÃ³rio HTML: `data/test_reports/htmlcov/index.html`

---

## ğŸš€ PRÃ“XIMAS ETAPAS (ApÃ³s conclusÃ£o)

1. âœ… Commit com mensagem: "Fix: corrigir 25 falhas de teste + aumentar cobertura para 90%"
2. âœ… Deploy em staging
3. âœ… Smoke tests
4. âœ… Deploy em produÃ§Ã£o

---

**Status:** ğŸŸ¡ PRONTO PARA IMPLEMENTAÃ‡ÃƒO  
**Tempo Estimado:** 6-8 horas  
**Deadline:** Hoje  
**Start:** Agora!

